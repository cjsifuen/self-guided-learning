[
  {
    "objectID": "domain-specific-series.html",
    "href": "domain-specific-series.html",
    "title": "Domain-Specific Series",
    "section": "",
    "text": "Hands-on tutorials created for members of the Neurodegeneration Challenge Network (NDCN), and taught at NDCN Office Hours. Past series materials will be added here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Unix Shell\n\n\nLearn the basics of the Unix Shell\n\n\n\nChristopher Sifuentes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to R for Data Analysis and Visualization\n\n\nLearn how to use R for basic data analysis and visualization.\n\n\n\nChristopher Sifuentes\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "A resource for self-guided learning",
    "section": "",
    "text": "MIT License\nCopyright (c) 2023 Christopher Sifuentes\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "——",
    "section": "",
    "text": "Resources\n\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Resource List\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Installs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain-Specific Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "Not sure where to get started? We’ve put together this “Getting Started” section to provide you with a needed foundations to continue your computational biology journey. As you progress, you’ll find more advanced topics and resources available on our website. Good luck and happy learning!\n\nIntroduction to Unix and Command Line Interface\n\nThe Unix Workbench - A website (book) for those new to Unix-like operating systems and working at the command-line. This book covers unix and command-line basics, as well as introductory bash programming concepts (math, variables, loops, input/output, arrays, pbraces, functions), and writing programs. As a nice bonus, it also gives brief introductions to Git, GitHub, and Cloud Computing.\n\n\n\nProgramming Basics\n\nGetting Started with Python - A terrific free course by the University of Michigan to learn the basics of programming in Python, with no prerequisites.\nR for Data Science - A website for the R for Data Science book, with a focus on how to perform data science with R, from data exploration (visualization, workflow, working with tidy data, scripting), wrangling, modeling, and communicating results (R markdown).\n\n\n\nVersion Control with Git and Github\n\nIntroduction to Using Github - Learn the basics of Git and GitHub for version control and collaboration in scientific projects.\n\n\n\nData Formats and Databases in Biology\n\nUnderstanding Biological Data Formats - Learn about common file formats in bioinformatics, such as FASTA, FASTQ, SAM/BAM, VCF, GFF, and GTF.\nNCBI Resources - Explore the National Center for Biotechnology Information’s databases and tools for biological research.\n\n\n\nProject Organization and Reproducibility\n\nTen Simple Rules for Reproducible Computational Research - Learn best practices for organizing bioinformatics projects, managing data, and enabling reproducibility."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "1-Reproducibility/series-introduction.html",
    "href": "1-Reproducibility/series-introduction.html",
    "title": "Series Introduction",
    "section": "",
    "text": "Goals and Topics\nWhile intended for those with prior coding experience (either in R, python, or bash), this first several sections of this training can be very helpful for beginners. The concepts introduced and covered here are meant to help one move toward computational reproducibility.\n\n\nCode of Conduct\nWe are dedicated to supporting a safe, productive, and harassment-free environment for everyone. Harassment includes offensive comments and behavior related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion, technology choices, sexual images, deliberate intimidation, stalking, or inappropriate or unwelcome sexual attention. All communication should be appropriate for a professional audience including people of many different backgrounds.\nIn general:\n\nBe kind to others.\nBe open, supportive, and constructive.\nDo not insult or put down others.\nBehave professionally.\nHarassment and sexist, racist, or exclusionary jokes are not appropriate and will not be tolerated.\n\nThank you for helping make this a welcoming, friendly community for all.\n\n\nSchedule\n\n\n\n\n\n\n\nSession\nLesson\n\n\n\n\nSession 1\nIntroduction to Bioinformatic Reproducibility\n\n\nSession 2\nGood Enough Practices\n\n\nSession 3\nPlan for Reproducibility\n\n\nSession 4\nTutorial: A Practical Introduction to Reproducible Computational Workflows\n\n\nSession 5\nSnakemake\n\n\n\n\n\nCitations\n\nTen simple rules for writing and sharing computational analyses in Jupyter Notebooks. Rule A, Birmingham A, Zuniga C, Altintas I, Huang SC, Knight R, Moshiri N, Nguyen MH, Rosenthal SB, Pérez F, Rose PW. PLoS Comput Biol. 2019 Jul 25;15(7):e1007007. doi: https://doi.org/10.1371/journal.pcbi.1007007\nReproducibility, Research Objects, and Reality. Gable C. 2016 Nov 24. https://www.slideshare.net/carolegoble/reproducibility-research-objects-and-reality-leiden-2016\nBaker M. 1,500 scientists lift the lid on reproducibility. Nature. 2016 May 26;533(7604):452-4. doi: https://10.1038/533452a. PMID: 27225100.\nYang-Min Kim, Jean-Baptiste Poline, Guillaume Dumas, Experimenting with reproducibility: a case study of robustness in bioinformatics, GigaScience, Volume 7, Issue 7, July 2018, giy077, https://doi.org/10.1093/gigascience/giy077\nWilson G., Bryan J., Cranston K., Kitzes J., Nederbragt L., Teal T.K. (2017) Good enough practices in scientific computing.PLoS Comput Biol 13(6):e1005510. https://doi.org/10.1371/journal.pcbi.1005510\nWickham, H. Tidy Data. Journal of Statistical Software 59 (10). DOI: https://10.18637/jss.v059.i10\nGuo, Danny. Make a README, https://www.makeareadme.com/.\nCham, J. Piled Higher and Deeper\nEvan, W. “What Is Version Control?” University of Idaho Library. 1-Why, https://uidaholib.github.io/get-git/1why.html"
  },
  {
    "objectID": "1-Reproducibility/good-enough-practices.html",
    "href": "1-Reproducibility/good-enough-practices.html",
    "title": "Good Enough Practices",
    "section": "",
    "text": "Deciding on a place to start\nComputational reproducibility is not “solved”, because it’s a difficult problem. So where should we start? We can start by working toward “good enough practices” (see the publication below), which map to our barriers.\n\n\n\n\n\nFigure 1: Good enough practices in scientific computing. [1]\n\n\nLet’s revisit those barriers from before and see how these good enough practices map to them.\n\n\n\n\n\n\n\nBarrier\nGood Enough Practice\n\n\n\n\nOrganization\nData management Software Project organization\n\n\nDocumentation\nTracking changes\n\n\nAutomation\nData management Software\n\n\nDissemination\nCollaboration Manuscripts\n\n\n\nBelow, we dig into each of these a bit further.\n\n\n\nData Management\nIn data management, we want to ask ourselves\n  Who will be using these data?\n  What would others need to rerun this from scratch?\nIn answering these questions, the practices listed below become quite clear. The real trick is remembering to do it.\n\n\n\n\n\n\n\nPractice\nReason\n\n\n\n\nSave raw data\nEssential to rerun complete analysis\n\n\nSave intermediate data\nAllows for rerunnning portions of the analysis Allows for comparing discrepancies at each step\n\n\nBackup data\nPrevents data loss\n\n\nDocument all steps\nExact commands, parameters, input, and output are required for reproduction A shell script for each step, for example, would help achieve this Hand-written documentation may not fully reflect each step\n\n\nAutomate analysis\nManual data manipulation is more difficult to document faithfully\n\n\nUse meaningful names\nVariables, functions, and files should have meaningful, unique names\n\n\nOpen data practices\nProvides others with data to validate your work, earning trust Placing in a reputable DOI-issuing repository improves reach of your work Allows others to build upon your work, opening the door for collaboration\n\n\nUse “tidy” data\nSimplifies the analysis\n\n\n\n\nStep documentation\nTo have a chance at reproducing your work, one needs the entire command as executed. Imagine we wanted to do the_thing to each item in a specific directory location, ${DIR}. What would someone need to run this effectively?\n\nCommandNeeded Information\n\n\n\nfor ITEM in ${DIR}/*\ndo \n  the_thing -f ${PARAM1} -n ${PARAM2} ${ITEM}\ndone\n\n\n\nI need to know\n\nthe value of the inputs: ${DIR}\nthe value of the parameters for the options/flags: ${PARAM1} and {$PARAM2}\nany errors\n\n\n\n\nWe can do this in several ways (we can discuss later)\n\nRun each step in a script with information encoded\nPrint the command to the screen\nLog the command with something like tee\nOther ways\n\nAn example of doing this with a bash script is shown below:\n\n#!/usr/bin/env bash\nDIR=\"/Users/csifuentes\"\nPARAM1=\"blah\"\nPARAM2=5\nLOG=\"/Users/csifuentes/good_log_file_name.txt\"\n\nfor ITEM in ${DIR}/*\ndo \n  COMMAND=$(the_thing -f ${PARAM1} -n ${PARAM2} ${ITEM})\n  echo ${COMMAND}\n  ${COMMAND} 2>&1 | tee -a ${LOG}\ndone\n\n\n\nAutomation\nAutomating code output (like above can help with documentation). Workflow managers, like Snakemake and Nextflow can allow one to log code and document at steps beyond this. We will talk about this in later sessions.\n\n\nUse meaningful names\nTo make is easier for others (and yourself), care should be taken to use meaninful names for any of the files, variables, or functions used in your work.\n\n\n\n\n\n\n\n\nNames should\nNot meaningful\nMore meaningful\n\n\n\n\nTell what they are/do, or reveal intention\nsample1.fastq.gz\nHs-sample1-treated-ATGATA.trim.fastq.gz\n\n\nBe different enough to tell apart easily\nmultiOmicWithInput, multiOmicFromInput\nmultiOmic_SampleA, multiOmic_SampleB\n\n\nEasy to read/pronounc\nsfns\nsuperFileNames\n\n\nBe unique and searchable\nd\ncell_type_holder\n\n\nNot be a “keyword” used anywhere else by computers/languages\nfor, in, list\ncell_type\n\n\n\n\n\nQuick introduction to tidy data\n\n\n\n\n\nFigure 2: Rules to form tidy data. [2]\n\n\nBelow are examples of the same data, represented in two different formats. On the left, we have what is commonly called “wide format” data. On the right, we have the same data in “tidy format”.\n\n\n\n\n\nFigure 3: Wide-format data (left) and tidy data (right). [1]\n\n\n\n\nQuiz Time\n\n1. Identifying tidy data\n\nQ&A: Which of the following are tidy data?\n\n\n\n\nState\nYear-Month\nHigh Temperature\nLow Temperature\n\n\n\n\nNew Jersey\n2020-01\n41\n23\n\n\nNew Jersey\n2020-02\n45\n23\n\n\nNew Jersey\n2020-03\n55\n32\n\n\nTexas\n2020-01\n62\n42\n\n\nTexas\n2020-02\n65\n45\n\n\nTexas\n2020-03\n72\n51\n\n\n\n\n\n\nState\nYear\nMonth\nHigh Temperature\nLow Temperature\n\n\n\n\nNew Jersey\n2020\n01\n41\n23\n\n\nNew Jersey\n2020\n02\n45\n23\n\n\nNew Jersey\n2020\n03\n55\n32\n\n\nTexas\n2020\n01\n62\n42\n\n\nTexas\n2020\n02\n65\n45\n\n\nTexas\n2020\n03\n72\n51\n\n\n\nBoth\nNeither\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nNeither.\n\nTidy data rules:\n\nEach variable forms a column\nEach observation forms a row\nEach cell is a single measurement\n\nOption A violates\n\nRule 1: Year-Month should be 2 columns because this is combination of the Year and Month variables\nRule 2: Each row represents multiple measurements, high and low temperatures\n\nOption B violates\n\nRule 2: Each row represents multiple measurements, high and low temperatures\n\n\n\n\n\n\n\n\n\n\nAdditional Reading\n\nTen Simple Rules for Reproducible Computational Research\nBest Practices for Scientific Computing\nGood Enough Practices in Scientific Computing\nA Practical Introduction to Reproducible Computational Workflows Workshop by ISMB/EECB\nReproducible Bioinformatics blog post by Dave Tang\n\n\n\n\nCitations\n\nTen simple rules for writing and sharing computational analyses in Jupyter Notebooks. Rule A, Birmingham A, Zuniga C, Altintas I, Huang SC, Knight R, Moshiri N, Nguyen MH, Rosenthal SB, Pérez F, Rose PW. PLoS Comput Biol. 2019 Jul 25;15(7):e1007007. doi: https://doi.org/10.1371/journal.pcbi.1007007\nReproducibility, Research Objects, and Reality. Gable C. 2016 Nov 24. https://www.slideshare.net/carolegoble/reproducibility-research-objects-and-reality-leiden-2016\nBaker M. 1,500 scientists lift the lid on reproducibility. Nature. 2016 May 26;533(7604):452-4. doi: https://10.1038/533452a. PMID: 27225100.\nYang-Min Kim, Jean-Baptiste Poline, Guillaume Dumas, Experimenting with reproducibility: a case study of robustness in bioinformatics, GigaScience, Volume 7, Issue 7, July 2018, giy077, https://doi.org/10.1093/gigascience/giy077"
  },
  {
    "objectID": "1-Reproducibility/introduction-to-bioinformatic-reproducibility.html",
    "href": "1-Reproducibility/introduction-to-bioinformatic-reproducibility.html",
    "title": "Introduction to Bioinformatic Reproducibility",
    "section": "",
    "text": "What is reproducibility?\nObtaining consistent results using the same data, computational methods, steps, code, and parameters.[1]\n\n\n\n\n\n\nTip\n\n\n\nReproducibility is NOT the same as “repeatability” and “reusability”, which are also quite important (See the table below).\n\n\n\n\n\nFigure 1: Repeatability, replicatability, reproducibility, and reusability in science. [2]\n\n\n\n\n\nDefining Terms\nThere are many definitions of repeatability, replicatability, and reproducibility – some are quite conflicting. For our purposes, we’ll stick with the terms as outlined in the table below.\n\n\n\n\n\n\n\n\n\nMetric\nRepeatability\nReplicatability\nReproducibility\n\n\n\n\nOperator – Who performs it?\nSame lab\nOthers\nOthers\n\n\nInput\nSame\nSame\nSame-ish\n\n\nMethods\nSame\nSame\nSame-ish\n\n\nOutcome – Results?\nSame\nSame\nConsistent\n\n\n\n\n\n\nWhy do it?\n\nScientific responsibility\nIncreased acceptance and validation of your work\nTime savings\nCollaborative benefits\n\n\n\n\nReproducbility Crisis\nI’m sure this isn’t news to anyone that has tried to reproduce results from other labs, but there is a reproducibility crisis. The situation is no different for computational analyses.\n\n\n\nFigure 2: Results when 1576 research scientists were asked if there was a reproducibility crisis. [3]\n\n\n\n\n\nBarriers to Reproducibility\nThere are many barriers to reproducbility, highlighted in the figure and table below.\n\n\n\nFigure 3: Barriers to reproducibility can often be hidden and seem daunting. [4]\n\n\n\n\n\n\n\n\n\nFactors\nExamples\n\n\n\n\nHuman\n\nPoor documentation\nConfirmation bias\nWorking in silos\nRandom errors, despite best intentions\n\n\n\nTechnical\n\nVariability\nReagents\nLack of tools\nAtypical nature of work\n\n\n\nInstitutional\n\nLack of rewards\nLack of lab buy-in, support\nPaywalls\n\n\n\n\nWe can classify the above barriers issues in one or more of the following areas - Organization - Documentation - Automation - Dissemination\nIn the next section we will learn about some things we can do to overcome these barriers.\n\n\n\nAdditional Reading\n\nTen Simple Rules for Reproducible Computational Research\nBest Practices for Scientific Computing\nGood Enough Practices in Scientific Computing\nA Practical Introduction to Reproducible Computational Workflows Workshop by ISMB/EECB\nReproducible Bioinformatics blog post by Dave Tang\n\n\n\n\nCitations\n\nTen simple rules for writing and sharing computational analyses in Jupyter Notebooks. Rule A, Birmingham A, Zuniga C, Altintas I, Huang SC, Knight R, Moshiri N, Nguyen MH, Rosenthal SB, Pérez F, Rose PW. PLoS Comput Biol. 2019 Jul 25;15(7):e1007007. doi: https://doi.org/10.1371/journal.pcbi.1007007\nReproducibility, Research Objects, and Reality. Gable C. 2016 Nov 24. https://www.slideshare.net/carolegoble/reproducibility-research-objects-and-reality-leiden-2016\nBaker M. 1,500 scientists lift the lid on reproducibility. Nature. 2016 May 26;533(7604):452-4. doi: https://10.1038/533452a. PMID: 27225100.\nYang-Min Kim, Jean-Baptiste Poline, Guillaume Dumas, Experimenting with reproducibility: a case study of robustness in bioinformatics, GigaScience, Volume 7, Issue 7, July 2018, giy077, https://doi.org/10.1093/gigascience/giy077"
  },
  {
    "objectID": "1-Reproducibility/installation.html",
    "href": "1-Reproducibility/installation.html",
    "title": "Installation and Resources",
    "section": "",
    "text": "Software\n\nInstall the following software\n\n\nBash Shell\nConda.\nPython.\nR.\nR Studio (Posit)\nJupyter\n\n\nCreate a free GitHub account (if you do not have one yet), by signing up here.\n\n\n\nData"
  },
  {
    "objectID": "software-installs.html",
    "href": "software-installs.html",
    "title": "Software Installs",
    "section": "",
    "text": "Information on how to install some commonly used software and tools.\n\n\nBash\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://carpentries.github.io/workshop-template/#shell-windows\n\n\nmacOS\nhttps://carpentries.github.io/workshop-template/#shell-macos\n\n\nLinux\nhttps://carpentries.github.io/workshop-template/#shell-linux\n\n\n\n\n\n\nConda (miniconda)\nInstall miniconda, not Anaconda.\nThis will also install Python, so if you wish to use a specific version of Python, you with want to specify that specific version when installing.\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://docs.conda.io/projects/conda/en/latest/user-guide/install/windows.html\n\n\nmacOS\nhttps://docs.conda.io/projects/conda/en/latest/user-guide/install/macos.html\n\n\nLinux\nhttps://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html\n\n\n\nAfter closing and re-opening the terminal, the conda base environment should be enabled. To check this, make sure you see (base) to the left of your user name in the terminal prompt.\n```\n(base) user: $\n```\n\n\n\nGit\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://carpentries.github.io/workshop-template/#git-windows\n\n\nmacOS\nhttps://carpentries.github.io/workshop-template/#git-macos\n\n\nLinux\nhttps://carpentries.github.io/workshop-template/#git-linux\n\n\n\n\n\n\nJupyter\nI recommend installing through conda. See the conda install above first if you need to install conda, then follow the instructions below.\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://jupyter.org/install\n\n\nmacOS\nhttps://jupyter.org/install\n\n\nLinux\nhttps://jupyter.org/install\n\n\n\n\n\n\nPosit (formerly Rstudio)\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://posit.co/downloads/\n\n\nmacOS\nhttps://posit.co/downloads/\n\n\nLinux\nhttps://posit.co/downloads/\n\n\n\n\n\n\nPython\nPython will also come installed with conda (depending on the installer that is used, I think). Choose the Python version that most of your packages will need. If you are unsure, I would start with Python 3.\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://realpython.com/installing-python/#how-to-install-from-the-full-installer\n\n\nmacOS\nhttps://realpython.com/installing-python/#step-1-download-the-official-installer\n\n\nLinux\nhttps://realpython.com/installing-python/#how-to-install-on-ubuntu-and-linux-mint\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://rstudio-education.github.io/hopr/starting.html#how-to-download-and-install-r\n\n\nmacOS\nhttps://rstudio-education.github.io/hopr/starting.html#how-to-download-and-install-r\n\n\nLinux\nhttps://rstudio-education.github.io/hopr/starting.html#how-to-download-and-install-r\n\n\n\n\n\n\nSnakemake\nI recommend installing this through conda. See the conda install above to first install conda, then follow the instructions below. I also recommend installing through mamba if possible.\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://snakemake.readthedocs.io/en/stable/getting_started/installation.html\n\n\nmacOS\nhttps://snakemake.readthedocs.io/en/stable/getting_started/installation.html\n\n\nLinux\nhttps://snakemake.readthedocs.io/en/stable/getting_started/installation.html"
  },
  {
    "objectID": "learning-resources.html",
    "href": "learning-resources.html",
    "title": "Learning Resource List",
    "section": "",
    "text": "While not exhaustive, we’ve pulled together a set of self-guided learning resources for readers beginning their computational biology journey. Included are learning-oriented tutorials, task-oriented how-to guides, and information-oriented references. The formats vary from YouTube courses and MOOCs to website-based books and cheat-sheets.\nSearch, sort, and filter the resources below :)\n\n\n\n\n\n\n\n\n\nExpand/Collapse All"
  },
  {
    "objectID": "0-The-Unix-Shell/bash-scripting.html",
    "href": "0-The-Unix-Shell/bash-scripting.html",
    "title": "Bash Scripting",
    "section": "",
    "text": "Scripts\nScripts are files that hold a series of commands that are to be interpreted and executed.\n\nStarting a Script\nBecause scripts can be written in any language, the computer needs to know which interpreter to use to interpret the commands. The hashbang, #! (or shebang), followed by the location, tells the computer where to find the interpreter for the specific language that is being used.\nThese are usually found in specific locations, but can vary slightly. The options below are worth trying.\n\n#!/bin/bash\n#!/usr/bin/env bash\n\n\n\n\n\n\n\nTip\n\n\n\nThe hashbang/shebang must the be first line of the script – otherwise the # will be seen as a commenting line.\n\n\n\n\nUsing a Script\nUsing any script is similar to running the commands we’ve learned.\n\nbash script.sh\n./script.sh – need to have permissions to run it this way\n\n\n\n\n\n\n\nTip\n\n\n\nWhile we won’t cover this today, we can create scripts that specify flags and take inputs as parameters/arguments to be used as variable values in the script.\n\n\n\n\n\n\nPutting this into practice – Processig RNA-seq Data\nLet’s put this into action with an example RNA-seq workflow.\n\nRNA-sequencing\nRNA-sequencing (RNA-seq) is a method that allows for the sequencing of complex mixtures of RNA. Different analyses can be peformed with these data, including assessing\n\ngene expression (changes over time, or differences between groups/treatments)\ntranscript splicing\npost-transcriptional modifications\ngene fusions\nand more\n\n\n\n\n\n\n\nTip\n\n\n\nFor a good introduction to RNA-seq analysis, visit RNA-seqlopedia\n\n\n\n\n\nGeneral Analysis Steps\nWhile there are variations to RNA-seq analyses, generally, the following steps are performed\n\nDemultiplex reads\nInitial read quality check\nFilter and trim sequencing reads\nNormalize sequencing reads\nDe novo assembly of transcripts (if a reference genome is not available)\nMap (align) sequencing reads to reference genome or transcriptome\nAnnotate transcripts assembled or to which reads have been mapped\nCount mapped reads to estimate transcript abundance\nPerform statistical analysis to identify differential expression (or differential splicing) among samples or treatments\nPerform multivariate statistical analysis/visualization to assess transcriptome-wide differences among samples\n\n\n\n\nTools/Software\nThere are MANY tools that can be used at each of these steps, each with their own pros and cons. For this lesson, we will use the following, stopping after quantification:\n\n\n\n\n\n\n\nStep\nTool\n\n\n\n\nDemultiplex\nPerformed already (usually using bcl2fastq)\n\n\nInitial read QC\nFastQC\n\n\nFilter and trim reads\nTrimGalore!\n\n\nAlignment\nSTAR\n\n\nAbundance quantification\nSubread\n\n\n\n\n\n\nSample Datasets\nOur dataset here sequencing data files (fastq files) from 6 samples, that are divided into 2 groups (1 and 2).\n\n\n\n\n\n\n\nSample Name\nGroup\n\n\n\n\nsample_01\n1\n\n\nsample_02\n1\n\n\nsample_03\n1\n\n\nsample_04\n2\n\n\nsample_05\n2\n\n\nsample_06\n2\n\n\n\n\n\n\n\nAnalysis\nWe’ll implement this analysis using bash scripts.\nI will walk through the initial step here, then we will work more hands-on in each step, building the scripts together.\n\nInitial Read QC\nOne of the first steps will be to check the quality of the sequencing reads with FastQC. The options we will be using are shown below.\n\n\n\nOption\nDescription\n\n\n\n\n-o\noutput directory\n\n\n-noextract\ndo not unzip (extract) the final output\n\n\n-f\nthe format of the input file is fastq\n\n\n-t\nuse this number of threads for processing\n\n\n[input files]\ninput file(s)\n\n\n\nThe following is how this command could be run at the command line for sample_01.\nNote: The \\ at the end of the line allows me to break up the command onto different lines, but the command in still interpreted as a single command.\n\nfastqc \\\n -o ~/Desktop/rnaseq \\\n --noextract \\\n -f fastq \\\n -t 4 \\\n sample_01_1.fastq\n\nHow would we put this into a bash script?\n\nput the command in a plain text file, saved with a suffix .sh\nspecify the interpreter with the hashbang\nadd in the code\ngeneralize if possibe, with variables, etc.\n\nTry to create a bash script for this first step.\n\n\n\n\n\n\nClick here for an answer\n\n\n\n\n\nIn the example below we\n\nset the interpreter\nset variables for the fastq directory location and the output qc directory location\nmake the output directory location\nperform the anlaysis in a loop\n\nIf we named this fastqc.sh we could run this by typing bash fastqc.sh\n\n#!/usr/bin/env bash\n\n#set variables\nFQ_DIR='/Users/csifuentes/Desktop/shell-lesson-data/simulated_reads/fastq/'\nQC_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/QC/'\n\n#make output directory\nmkdir -p ${QC_DIR}\n\n#fastqc on each file\nfor fq in ${FQ_DIR}*.fastq;\ndo fastqc \\\n    -o ${QC_DIR} \\\n    --noextract \\\n    -f fastq \\\n    -t 4 \\\n    ${fq};\ndone\n\n\n\n\n\n\n\nRead QC Trimming\nA common next step, should the FastQC analysis show a high-level of adapter content, or poor quality sequencing, would be to perform adapter trimming and read filtering or quality trimming. We’re going to pretend we need to trim and will be using TrimGalore!.\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\n-q\nquality value threshold for base calls, cuts bases with score below value\n\n\n--length\nremove reads that become shorter than this length\n\n\n--basename\nthe basename of the sample/file\n\n\n-o\noutput directory\n\n\n--paired\nif paired-end reads, the paired read files\n\n\n\nHow would we put this into a bash script?\n\n\n\n\n\n\nClick here for an answer\n\n\n\n\n\nIn the example below we\n\nset the interpreter\nset variables\nmake the output directory location\nperform the anlaysis in a loop, while grabbing the basename of each file using the basename command.\n\nIf we named this trim.sh we could run this by typing bash trim.sh\n\n#!/usr/bin/env bash\n\n#set variables\nFQ_DIR='/Users/csifuentes/Desktop/shell-lesson-data/simulated_reads/fastq/'\nQC_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/QC/'\nTRIM_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/TRIM/'\n\n#make output directory\nmkdir -p ${TRIM_DIR}\n\n#trimgalore! on each file\nfor fq in ${FQ_DIR}*_1.fastq;\ndo BASE=$(basename ${fq} '_1.fastq');\n    trim_galore \\\n    -q 30 \\\n    --length 20 \\\n    --basename ${BASE} \\\n    -o ${TRIM_DIR} \\\n    --paired ${FQ_DIR}${BASE}_1.fastq ${FQ_DIR}${BASE}_2.fastq;\ndone\n\n\n\n\n\n\n\nAligning Reads\nThe next step is to align filtered reads. We will use STAR for this, with the following options.\nNote: The trimming tool will output a specific file format of the sample name, followed by _val_, then the read, then end in .fq. This must be taken into account for the next step.\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\n-genomeDir\npath to the genome directory, with the index files\n\n\n--readFilesIn\nthe path to the reads files\n\n\n--sjdbGTFfile\nthe path to the GTF file associated with the genome file\n\n\n-outFileNamePrefix\noutput prefix, with directory in front\n\n\n--runThreadN\nnumber of threads to use, if possible\n\n\n--outSAMattributes\nalignment attributes to report\n\n\n--outSAMtype\nthe format to output (SAM/BAM, etc) and whether to sort\n\n\n\nHow would we put this into a bash script?\n\n\n\n\n\n\nClick here for an answer\n\n\n\n\n\nIn the example below we\n\nset the interpreter\nset variables\nmake the output directory location\nperform the anlaysis in a loop, while grabbing the basename of each file using the basename command.\n\nIf we named this star.sh we could run this by typing bash star.sh\n\n#!/usr/bin/env bash\n\n#set variables\nFQ_DIR='/Users/csifuentes/Desktop/shell-lesson-data/simulated_reads/fastq/'\nQC_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/QC/'\nTRIM_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/TRIM/'\nGENOME_FASTA='/Users/csifuentes/Desktop/shell-lesson-data/index/'\nGENOME_GTF='/Users/csifuentes/Desktop/shell-lesson-data/index/Homo_sapiens.GRCh38.103.gtf'\nALN_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/ALIGN/'\n\n#make output directory\nmkdir -p ${ALN_DIR}\n\n#star alignment on each file\nfor i in ${TRIM_DIR}*_val_1.fq;\ndo BASE=$(basename ${i} '_val_1.fq');\n    echo ${BASE};\n    STAR \\\n    --genomeDir ${GENOME_FASTA} \\\n    --readFilesIn ${TRIM_DIR}${BASE}_val_1.fq ${TRIM_DIR}${BASE}_val_2.fq \\\n    --sjdbGTFfile ${GENOME_GTF} \\\n    --outFileNamePrefix ${ALN_DIR}${BASE} \\\n    --runThreadN 4 \\\n    --outSAMattributes Standard \\\n    --outSAMtype BAM SortedByCoordinate \\\n    --outFilterMismatchNmax 999 \\\n    --alignSJoverhangMin 8 \\\n    --alignSJDBoverhangMin 1 \\\n    --outFilterMismatchNoverReadLmax 0.04 \\\n    --alignIntronMin 20 \\\n    --alignIntronMax 1000000 \\\n    --alignMatesGapMax 1000000 \\\n    --sjdbScore 1;\ndone\n\n\n\n\n\n\n\nQuantifying Expression\nIn the next step, we use featureCounts from Subread to quantify the expression of genes.\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\n-O\nassign reads to their overlapping features\n\n\n-p\ncount as fragments, with paired end reads\n\n\n-B\ncount only reads where both pairs align\n\n\n-C\ndo not count if reads map to different chromosomes or different strands\n\n\n-T\nthreads to use\n\n\n-s\nstrand-specific read counting\n\n\n-a\nannotation file (GTF, etc.)\n\n\n-o\noutput file name\n\n\n[file]\nthe format to output (SAM/BAM, etc) and whether to sort\n\n\n\nHow would we put this into a bash script?\n\n\n\n\n\n\nClick here for an answer\n\n\n\n\n\nIn the example below we\n\nset the interpreter\nset variables\nmake the output directory location\nperform the anlaysis in a loop\nclean the files, remove # and cutting specific columns\n\nIf we named this count.sh we could run this by typing bash count.sh\n\n#!/usr/bin/env bash\n\n#set variables\nGENOME_GTF='/Users/csifuentes/Desktop/shell-lesson-data/index/Homo_sapiens.GRCh38.103.gtf'\nALN_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/ALIGN/'\nSTRAND='0'\nCOUNTS_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/COUNTS/'\nANNOT_TMP='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/COUNTS/counts.tmp'\nANNOT_OUT='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/COUNTS/counts.txt'\n\n#make output directory\nmkdir -p ${COUNTS_DIR}\n\n#featureCounts on all files together\nfeatureCounts \\\n    -O \\\n    -p \\\n    -B \\\n    -C \\\n    -T 4 \\\n    -s ${STRAND} \\\n    -a ${GENOME_GTF} \\\n    -o ${ANNOT_TMP} \\\n    ${ALN_DIR}*Aligned.sortedByCoord.out.bam\n\n#clean file\nsed '/^#/d' ${ANNOT_TMP} | cut -f 1,7- > ${ANNOT_OUT}\n\n\n\n\n\nThese scripts used here, can be improved upon, by combining them, generalizing more, adding in extra sanity checks, and taking input from the commandline, etc.\nI encourage you to explore more, build and use these skills."
  },
  {
    "objectID": "0-The-Unix-Shell/series-introduction.html",
    "href": "0-The-Unix-Shell/series-introduction.html",
    "title": "Series Introduction",
    "section": "",
    "text": "Goals and Topics\nThis training series is intended for absolute beginners and focused on the basic usage of the Bash Shell. Concepts introduced in these sessions are foundational to the application of computational approaches and will enable more powerful and reproducible research.\nBy the end of the series, you should be able to\n\ndescribe the Unix file system structure\nnavigate the Unix file system from the command line\ncreate, view, and manipulate files and directories\nchain bash shell commands together\ncreate a basic Bash shell script to automate tasks\n\n\n\nCode of Conduct\nWe are dedicated to supporting a safe, productive, and harassment-free environment for everyone. Harassment includes offensive comments and behavior related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion, technology choices, sexual images, deliberate intimidation, stalking, or inappropriate or unwelcome sexual attention. All communication should be appropriate for a professional audience including people of many different backgrounds.\nIn general:\n\nBe kind to others.\nBe open, supportive, and constructive.\nDo not insult or put down others.\nBehave professionally.\nHarassment and sexist, racist, or exclusionary jokes are not appropriate and will not be tolerated.\n\nThank you for helping make this a welcoming, friendly community for all.\n\n\nSchedule\n\n\n\nSession\nLesson\nSlide Version\n\n\n\n\nSession 1\n\nIntroducing the Shell\nThe File System\n\n\nIntroducing the Shell\nThe File System\n\n\n\nSession 2\n\nPatterns, Filters, and Pipes\n\n\nPatterns, Filters, and Pipes\n\n\n\nSession 3\n\nVariables and Loops\n\n\nVariables and Loops\n\n\n\nSession 4\n\nBash Scripting\n\n\nBash Scripting\n\n\n\n\n\n\nCitations\n\nGabriel A. Devenyi (Ed.), Gerard Capes (Ed.), Colin Morris (Ed.), Will Pitchers (Ed.), Greg Wilson, Gerard Capes, Gabriel A. Devenyi, Christina Koch, Raniere Silva, Ashwin Srinath, … Vikram Chhatre. (2019, July). swcarpentry/shell-novice: Software Carpentry: the UNIX shell, June 2019 (Version v2019.06.1). Zenodo. http://doi.org/10.5281/zenodo.3266823\nComputational Foundations Workshop. (n.d.). Retrieved December 7, 2022, from https://umich-brcf-bioinf.github.io/2022-10-31-umich-computational-foundations/html/index.html\nLearn regular expressions - lesson 1: An introduction, and the abcs. RegexOne. (n.d.). Retrieved April 3, 2023, from https://regexone.com/\nNagarajan, V. (2018). Command line fundamentals: Learn to use the unix command-line tools and Bash Shell scripting. Packt Publishing.\nChadwick, R. (n.d.). Bash scripting tutorial - 1. what is a bash script? A collection of Technology Tutorials. Retrieved April 4, 2023, from <https://ryanstutorials.net/bash-scripting-tutorial/bash-script.php >\n\nNote: This series has been adapted from the Carpentries course entitles “The Unix Shell” [1] as well as the “Computational Foundations Workshop” [2], created by the University of Michigan Bioinformatics Core Workshop Team and inspired by or drawn on information from Regexone practice questions [3] as well as the very complete “Command line fundamentals” book by Vivek Nagaragan [4], and the “Bash scripting tutorial” developed by Ryan Chadwick [5]."
  },
  {
    "objectID": "0-The-Unix-Shell/slides/series-introduction-slides.html",
    "href": "0-The-Unix-Shell/slides/series-introduction-slides.html",
    "title": "Series Introduction",
    "section": "",
    "text": "Goals and Topics\nThis training series is intended for absolute beginners and focused on the basic usage of the Bash Shell. Concepts introduced in these sessions are foundational to the application of computational approaches and will enable more powerful and reproducible research.\nBy the end of the series, you should be able to\n\ndescribe the Unix file system structure\nnavigate the Unix file system from the command line\ncreate, view, and manipulate files and directories\nchain bash shell commands together\ncreate a basic Bash shell script to automate tasks\n\n\n\nCode of Conduct\nWe are dedicated to supporting a safe, productive, and harassment-free environment for everyone. Harassment includes offensive comments and behavior related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion, technology choices, sexual images, deliberate intimidation, stalking, or inappropriate or unwelcome sexual attention. All communication should be appropriate for a professional audience including people of many different backgrounds.\nIn general:\n\nBe kind to others.\nBe open, supportive, and constructive.\nDo not insult or put down others.\nBehave professionally.\nHarassment and sexist, racist, or exclusionary jokes are not appropriate and will not be tolerated.\n\nThank you for helping make this a welcoming, friendly community for all.\n\n\nSchedule\n\n\n\n\n\n\n\nSession\nLesson\n\n\n\n\nSession 1\n\nIntroducing the Shell\nThe File System\n\n\n\nSession 2\n\nPatterns, Filters, and Pipes\n\n\n\nSession 3\n\nLoops\nBash Scripting\n\n\n\nSession 4\n\nPutting it All Together\n\n\n\n\n\n\nCitations\n\nGabriel A. Devenyi (Ed.), Gerard Capes (Ed.), Colin Morris (Ed.), Will Pitchers (Ed.), Greg Wilson, Gerard Capes, Gabriel A. Devenyi, Christina Koch, Raniere Silva, Ashwin Srinath, … Vikram Chhatre. (2019, July). swcarpentry/shell-novice: Software Carpentry: the UNIX shell, June 2019 (Version v2019.06.1). Zenodo. http://doi.org/10.5281/zenodo.3266823\nComputational Foundations Workshop. (n.d.). Retrieved December 7, 2022, from https://umich-brcf-bioinf.github.io/2022-10-31-umich-computational-foundations/html/index.html\n\nNote: This series has been adapted from the Carpentries course entitles “The Unix Shell” [1] as well as the “Computational Foundations Workshop” [2], created by the University of Michigan Bioinformatics Core Workshop Team"
  },
  {
    "objectID": "0-The-Unix-Shell/patterns-filters-and-pipes.html",
    "href": "0-The-Unix-Shell/patterns-filters-and-pipes.html",
    "title": "Patterns, Filters, and Pipes",
    "section": "",
    "text": "Pattern Matching\nWildcards (special characters) can be used in several ways:\n\nStandard wildcards (globbing) – matching to work on a set of files\nRegular expressions – matching to work within files\n\n\n\nStandard Expansion Patterns\nStandard wildcards are used for globbing files – pulling together files to perform an action on them.\n\n\n\n\n\n\n\n\nWildcard\nRepresents\n\n\n\n\n*\n0 or more characters\n\na*e would match ae, a103e, apple\n\n\n\n?\nAny single character\n\na?e would match a1e, ape, are\n\n\n\n[]\nAny one of the characters within the brackets (comma separated list)\n\nm[a,3,n]s would match mas, m3s, mns\n[1-3]a would match 1a, 2a, 3a\n\n\n\n{}\nAny term within the brackets (comma separated list)\n\nls {*.doc, *.pdf} would list all files ending in .doc and .pdf\n\n\n\n[!]\nAnything except (negate) the character within the brackets (comma separated list)\n\nls *[!A,B].txt would match 123.txt, ZNEBF.txt, C.txt\n\n\n\n\\\n“Escapes” the following character, to treat it as a non-special character\n\nls *\\.*.txt would match this.file.txt, NOT this.txt\n\n\n\n\nLet’s try some examples in our shell-lesson-data directory.\n\nQ&A: How can we list all files in shell-lesson-data/north-pacific-gyre that end with .txt?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n# change into directory \ncd ~/Desktop/shell-lesson-data/north-pacific-gyre\n\n# use * wildcard to list all ending in .txt\nls *.txt\n\nNENE01729A.txt\nNENE01729B.txt\nNENE01736A.txt\nNENE01751A.txt\nNENE01751B.txt\nNENE01812A.txt\nNENE01843A.txt\nNENE01843B.txt\nNENE01971Z.txt\nNENE01978A.txt\nNENE01978B.txt\nNENE02018B.txt\nNENE02040A.txt\nNENE02040B.txt\nNENE02040Z.txt\nNENE02043A.txt\nNENE02043B.txt\nthis.file.txt\nthis.txt\n\n\n\n\n\n\n\nQ&A: List the files in shell-lesson-data/north-pacific-gyre that do not end with .txt.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n# change into directory \ncd ~/Desktop/shell-lesson-data/north-pacific-gyre\n\n# use ! to with the [] to negate all files ending in .txt\nls *[!.txt]\n\ngoodiff.sh\ngoostats.sh\n\n\n\n\n\n\n\nQ&A: List the files in shell-lesson-data/north-pacific-gyre with the last two positions before the suffix are a number lower than 5, followed by not Z.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n# change into directory \ncd ~/Desktop/shell-lesson-data/north-pacific-gyre\n\n# use ! to with the [] to negate all files ending in .txt\nls *[0-4][!Z].*\n\nNENE01751A.txt\nNENE01751B.txt\nNENE01812A.txt\nNENE01843A.txt\nNENE01843B.txt\nNENE02040A.txt\nNENE02040B.txt\nNENE02043A.txt\nNENE02043B.txt\n\n\n\n\n\n\n\n\n\nRegular Expressions (regex)\nA complex form of pattern matching that combines “wildcards” to create powerful patterns for text matching and manipulation in files.\n\n\n\n\n\n\nTip\n\n\n\nUsed with grep to search for text – which we’ll explain in a bit.\n\nregex symbols are interpreted by the commands above\n\n\n\n\n\nWhat makes a pattern?\nTo efficiently represent a pattern, we need to develop a language that specifies\n\natom – the actual character that we want to match\npositions – the location of this atom\nnumber of times – how many times we see the atom\ngroups – groups of matched atoms or non-matched\n\n\n\nRepresenting Atoms\nCharacter classes are used to represent atoms.\n\n\n\n\n\n\n\nCharacter class – Example\nMatches\n\n\n\n\nNon-special characters – a\na matches a\n\n\nDot – .\n. matches ANYTHING\n\n\nRange – [a-z]\n[a-z] matches any letter from a through z\n\n\nCharacter set – [abc]\n[abc] matches a, b, or c\n\n\nCharacter set – [[:alnum:]]\n[[:alnum:]] matches any alpha-numeric character\n\n\nCharacter set – [[:lower:]]\n[[:lower:]] matches any lowercase letter\n\n\nCharacter set – [[:space:]]\n[[:space:]] matches any whitespace\n\n\nCharacter set – [[:digit:]] | [[:digit:]] matches any digit |\n\n\nNegated character set – [^abc]\n[^abc] matches anything except a, b, or c\n\n\nWhitespace – \\s\n\\s matches any whitespace character\n\n\nNon-whitespace – \\S\n\\S matches any non-whitespace character\n\n\nWord – \\w\n\\w an entire word (continuous alpha-numeric or underscores)\n\n\nNon-word – \\W\n\\W not a word\n\n\nDigit – \\d\n\\d any digit\n\n\nNon-digit – \\D\n\\D not a digit\n\n\n\n\n\n\nPositions\nAnchors are used to specify the location of characters or set of characters – so the pattern will only match if the position also matches.\n\n\n\n\n\n\n\nAnchor\nExample(s)\n\n\n\n\nStart of line/string – ^\n^a matches the a in apple, but not sandal\n\n\nEnd of line/string – $\na$ matches the a in spa, but not space\n\n\n\n\n\n\nNumber of times\nQuantifiers are used to specify the number of times preceeding characters or sets of characters are repeated.\n\n\n\n\n\n\n\nQuantifier\nExample(s)\n\n\n\n\n0 or 1 time – ?\nre?d matches rd, red, NOT reed, read\n\n\n0 or more times – *\nre*d matches rd, red, reed, NOT read\n\n\n1 or more times – +\nre+d matches red, reed, NOT rd, read\n\n\nSpecified number of times – {}\nre{1}d matches red, NOT rd, reed, read\n\n\nRange of times – {1,3}\nre{1,3}d matches red, reed, NOT rd, read\n\n\nOr – |\nre(e|a)d matches reed, read, NOT rd, red\n\n\n\n\n\n\nGroups and Reference\nMatched atoms can be grouped together and referenced later.\n\n\n\n\n\n\n\nGrouping/Reference\nExample(s)\n\n\n\n\nCapture the group – ()\n(re)d groups re together\n\n\nReference the group – \\1\n\\1 references the first group captured\n\n\n\n\n\n\n\nPracticing with Regex\nLearning regex takes time and practice!\n\nQuestion 1:\nWhich expression will select only the in the following?\n“The great thing about learning is that the experience itself teaches you something, though it may not be the thing you wanted to learn.”\n\nthe\n(T|t)e\n[Tt]he\n*he\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nYes. This will match the.\nNo. This will also match The.\nNo. This will also match The.\nNo. This will also match The.\n\n\n\n\n\n\nQuestion 2:\nWhich expression will select all of the following?\nfoxes boxes loxes\n\n.oxes\n[fbl]oxes\n(f|b|l)oxes\n*oxes\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nYes. . will match anything for the first character.\nYes. Uses character set matching.\nYes. Uses or matching.\nNo. * is a quantifier and references nothing.\n\n\n\n\n\n\nQuestion 3:\nWhich expression will select all of the following?\nnd ned need\n\nne+d\nne?d\nne*d\nne.d\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nNo. + matches e 1 or more times.\nNo. ? matches e 0 or 1 times.\nYes. * matches e 0 or more times.\nNo. . matches anything one time exactly.\n\n\n\n\n\nFor more practice, I recommend RegexOne\n\n\n\n\n\nUsing regex with grep\nRegular expressions are most effective when used with specific commands.\n\ngrep – globally search a regular expression and print\nSearches for a pattern within a file and returns the line containing the pattern.\n\n\n\n\n\n\nTip\n\n\n\nBy default, grep returns the line containing the pattern and is case-sensitive.\nA few of the useful options are below:\n\nuse -i to peform case-insensitive matching\nuse -v to return the non-matching lines\nuse -w to return the word instead of the line that matches\nuse -A to return the line after the matching line\nuse -B to return the line before the matching line\nuse -E to use extended regular expressions\nuse -c to return the number of times a match is seen\nuse -n to output the line number that matches\n\n\n\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ngrep\nflags\npattern /path/to/file\n\n\n\nLet’s try this on a few files in our shell-lesson-data/exercise-data/creatures directory.\nIf we take a look at top 5 lines of each file (head command) we see:\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# print the first 5 lines each file \nhead -n 5 *\n\n==> basilisk.dat <==\nCOMMON NAME: basilisk\nCLASSIFICATION: basiliscus vulgaris\nUPDATED: 1745-05-02\nCCCCAACGAG\nGAAACAGATC\n\n==> minotaur.dat <==\nCOMMON NAME: minotaur\nCLASSIFICATION: bos hominus\nUPDATED: 1765-02-17\nCCCGAAGGAC\nCGACATCTCT\n\n==> unicorn.dat <==\nCOMMON NAME: unicorn\nCLASSIFICATION: equus monoceros\nUPDATED: 1738-11-24\nAGCCGGGTCG\nCTTTACCTTA\n\n\nUsing grep, let’s pull out the common names line of all of the creatures.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# grep COMMON NAME from all files ending in .dat \ngrep 'COMMON NAME' *.dat\n\nbasilisk.dat:COMMON NAME: basilisk\nminotaur.dat:COMMON NAME: minotaur\nunicorn.dat:COMMON NAME: unicorn\n\n\nUsing grep, let’s check how many times the CCC is seen in each creatures genomic sequence.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# grep COMMON NAME from all files ending in .dat \ngrep -c 'CCC' *.dat\n\nbasilisk.dat:22\nminotaur.dat:18\nunicorn.dat:22\n\n\nWhat if we want just the first line following the common name unicorn?\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# grep COMMON NAME from all files ending in .dat \ngrep -A 1 'unicorn' *.dat\n\nunicorn.dat:COMMON NAME: unicorn\nunicorn.dat-CLASSIFICATION: equus monoceros\n\n\nWhat if we wanted anything updates in the 1740’s? We need to use -E option to use the extended regular expressions we covered earlier.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# grep COMMON NAME from all files ending in .dat \ngrep -E '174\\d-\\d{2}-\\d{2}' *.dat\n\nbasilisk.dat:UPDATED: 1745-05-02\n\n\nAs we can see, grep and pattern matching is useful, but it becomes even more powerful it we combine it with filtering.\n\n\n\n\nFiltering\nIn unix, we can filter data in many ways. Here we’ll cover a few light, but useful commands to do so.\n\ncut – filtering data from each line, cutting columns/fields out\nFilter data (“cut”) based upon a separator.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ncut\nflags\nfile/input\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe cut command separates fields by tabs by default.\nSome useful flags are below:\n\nuse -d to set the delimeter between fields to another character\nuse -f to list the fields to cut (can create a list -f 2,3 cuts field 2 and 3. -f 3-5 cuts field 3 to 5.)\n\n\n\nLet’s take a look at the animals.csv file in shell-lesson-data/exercise-data/animal-counts.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data/exercise-data/animal-counts\n\n# look at file\nhead -n 3 animals.csv\n\n2012-11-05,deer,5\n2012-11-05,rabbit,22\n2012-11-05,raccoon,7\n\n\nLet’s keep only the animals and counts – fields 2 and 3 if we consider the comma as the field separator.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data/exercise-data/animal-counts\n\n# cut to keep the second field (-f), using comma as a field separator (-d)\ncut -f2,3 -d ',' animals.csv\n\ndeer,5\nrabbit,22\nraccoon,7\nrabbit,19\ndeer,2\nfox,4\nrabbit,16\nbear,1\n\n\n\n\n\nuniq – report or filter out repeated lines\nFilters out repeated ADJACENT lines, but also allows for counting them, or ignoring a specific number of them.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nuniq\nflags\ninput/file output/file\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe uniq command is case sensitive by default and removes all duplicated adjacent lines. Thus, sorting prior is recommended.\nSome useful flags are below:\n\nuse -c add the count of the number of times the line occurs\nuse -i to ignore case\n\n\n\nIf a file looked like this:\n\n$ cat animals.txt\nbear\ndeer\ndeer\nfox\nrabbit\nrabbit\nrabbit\nraccoon\n\nThen uniq, with counts would output\n\nuniq -c animals.txt\n   1 bear\n   2 deer\n   1 fox\n   3 rabbit\n   1 raccoon\n\n\n\n\nsort – order lines of a file\nSorts a file or input in a highly customizable way.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nsort\nflags\nfile/input\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe sort command is case sensitive by default sorts lexiconically\nSome useful flags are below:\n\nuse -t to specify the field separator\nuse -i to ignore case\nuse -c to check if a file is sorted\nuse -k to specify a field to sort on\nuse -u to keep unique lines\nuse -n to perform a numberic sort\n\n\n\nLet’s sort the animals file by the second field (-k), using the commma as the field separator (-t).\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data/exercise-data/animal-counts\n\n# cut to keep the second field (-f), using comma as a field separator (-d)\nsort -t , -k 2 animals.csv\n\n2012-11-07,bear,1\n2012-11-06,deer,2\n2012-11-05,deer,5\n2012-11-06,fox,4\n2012-11-07,rabbit,16\n2012-11-06,rabbit,19\n2012-11-05,rabbit,22\n2012-11-05,raccoon,7\n\n\n\n\n\ngrep – globally search a regular expression and print\nReturns filtered lines, can also negate lines.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ngrep\nflags\npattern /path/to/file\n\n\n\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data/exercise-data/animal-counts\n\n# give me the lines that do not have an animal that ends in r\ngrep -Ev ',\\w+r,' animals.csv\n\n2012-11-05,rabbit,22\n2012-11-05,raccoon,7\n2012-11-06,rabbit,19\n2012-11-06,fox,4\n2012-11-07,rabbit,16\n\n\n\n\n\n\nPipes\nPipes (|) are used to quickly connect unix commands by “piping” output of one command to the input of another.\ncommand1 | command2 | command3\n\nDownload the gtf\nWe will download the file with wget or curl.\nIn the terminal, type which wget, and which curl.\n\nIf you see a path returned when you type one of those commands and press enter, then you have that command.\n\n\n#check for wget\nwhich wget\n\n#check for curl\nwhich curl\n\n/Users/csifuentes/miniconda3/bin/wget\n/usr/bin/curl\n\n\n\nYou can download the file as below, depending on the command you want to use.\n\nwgetcurl\n\n\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# wget file (using capital -O as the flag to create a gzipped file named example.gtf.gz)\nwget -O example.gtf.gz ftp://ftp.ensemblgenomes.org/pub/release-39/fungi/gtf/fungi_basidiomycota1_collection/cryptococcus_neoformans_var_grubii_h99/Cryptococcus_neoformans_var_grubii_h99.CNA3.39.gtf.gz\n\n\n\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# wget file (using lowercase -o as the flag to create a gzipped file name example.gtf.gz)\ncurl -o example.gtf.gz ftp://ftp.ensemblgenomes.org/pub/release-39/fungi/gtf/fungi_basidiomycota1_collection/cryptococcus_neoformans_var_grubii_h99/Cryptococcus_neoformans_var_grubii_h99.CNA3.39.gtf.gz\n\n\n\n\nYou can unzip the file as below, depending on the command you want to use.\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# gunzip file\ngunzip example.gtf.gz\n\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# view it\nhead example.gtf\n\n#!genome-build CNA3\n#!genome-version CNA3\n#!genome-date 2015-11\n#!genome-build-accession GCA_000149245.3\n#!genebuild-last-updated 2015-11\n1   ena gene    100 5645    .   -   .   gene_id \"CNAG_04548\"; gene_source \"ena\"; gene_biotype \"protein_coding\";\n1   ena transcript  100 5645    .   -   .   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\";\n1   ena exon    5494    5645    .   -   .   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\"; exon_id \"AFR92135-1\";\n1   ena CDS 5494    5645    .   -   0   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\"; protein_id \"AFR92135\"; protein_version \"1\";\n1   ena start_codon 5643    5645    .   -   0   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\";\n\n\nGTF files contain the following information, as columns (fields)\n\nchromosome name\nannotation source\nfeature-type\ngenomic start\ngenomic end\nscore\nstrand\ngenomic phase\nadditonal information (gene_id, etc.)\n\n\n\n\nAnalysis\nUsing the commands we’ve learned thus far, let’s explore the example.gtf file to answer the following:\n\nHow many chromosomes does the organism have?\nHow many unique gene ids does the organism have?\nWhich chromosome has the most genes?\n\n\nHow many chromosomes does the organism have?\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the first column (chromosomes)\n# sort the chromosomes numerically, removing duplicates\ncat example.gtf | grep -v '^#' | cut -f1 | sort -nu \n\nMt\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\nThis organism has 14 + Mt chromosomes.\n\n\nHow many genes does the organism have?\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the third column (biotype)\n# sort values\n# keep unique values, specifying counts of each unique value\ncat example.gtf | grep -v '^#' | cut -f3 | sort | uniq -c\n\n49063 CDS\n52036 exon\n6923 five_prime_utr\n8497 gene\n7860 start_codon\n3167 stop_codon\n7034 three_prime_utr\n9348 transcript\n\n\nThis organism has 8497 genes.\n\n\nWhich chromosome has the most genes?\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the first and third columns (chromosome, biotype)\n# sort values\n# keep unique values, specifying counts of each unique value to get totals of biotypes by chromosome\n# pull out gene biotype totals\ncat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep 'gene'\n\n1033 1  gene\n 474 10 gene\n 663 11 gene\n 326 12 gene\n 322 13 gene\n 417 14 gene\n 706 2  gene\n 725 3  gene\n 503 4  gene\n 812 5  gene\n 640 6  gene\n 641 7  gene\n 639 8  gene\n 554 9  gene\n  42 Mt gene\n\n\nChromosome 1 has the most genes, 1033. Mt has the least, 42.\nAs we can see, piping commands together allows us to easily perform analyses as a set of commands. In the next lesson, we’ll learn about how we can use loops and scripts to do this even more efficiently."
  },
  {
    "objectID": "0-The-Unix-Shell/introducing-the-shell.html",
    "href": "0-The-Unix-Shell/introducing-the-shell.html",
    "title": "Introducing the Shell",
    "section": "",
    "text": "What is the shell?\nThe shell (also known as the command-line) is a program that allows us to tell the computer what to do by giving it a “command” Figure 1a.\n\n\n\n\n\n\nTip\n\n\n\nOther names for the shell are terminal, Bash, UNIX command line, and more.\n\n\nAnother common way we tell the computer what to do is through the use of a “point and click” graphical user interface (GUI) approach Figure 1b.\n\n\n\n\n\n\n\n(a) Command Line Interface (CLI)\n\n\n\n\n\n\n\n(b) Graphical User Interface (GUI)\n\n\n\n\nFigure 1: Different ways to interact with a computer\n\n\n\n\n\nWhy use the shell?\nIsn’t pointing and clicking easier? Imagine you had the following task:\n\n\n\n\n\n\nYou have a directory with 10 .txt files.\nPull the first line from each file into a single new file. You should end up with a list of all of the first lines.\n\n\n\nTake a look below to see the process for GUI and CLI.\n\nGUI StepsCLI Code\n\n\n1. Create new file\n2. Open file 1, copy line 1, paste into new file, close file 1.\n3. Open file 2, copy line 1, paste into new file, close file 2.\n4. Repeat 7 more times\n\n\nhead -n1 -q *.txt > new-file.txt\n\n\n\nFor this task, the GUI was tedious, time-consuming, and error-prone while the CLI was a single-command, quick, and relatively error proof.\n\n\n\nAccessing the Shell\nLet’s start using the shell. Open the shell (terminal) on your computer. Select the appropriate instructions below, based on your operating system.\n\nWindows InstructionsmacOS Instructions\n\n\n\nGo the the Start menu and select “All Apps”.\nScroll down the list of applications and select the Git option.\nFrom the drop-down menu, select Git Bash.\nA terminal should open up.\n\n\n\n\nOpen Finder and go to the Applications tab.\nScroll down the list of applications and select Utilities.\nSelect Terminal.\nA terminal should open up.\n\n\n\n\n\n\n\nUsing the shell\nOnce we open our terminal, the $ shows us that shell is ready for input.\nLet’s see what day it is using the ls command.\n\nls stands for list\nlists the objects in a location\n\nIn your terminal, type ls and press enter.\n\nls\n\ncount.sh\nexample.gtf\nexercise-data\nfastqc.sh\nfastqc_step.sh\nfeature_counts.sh\nindex\nmetadata.txt\nnorth-pacific-gyre\nrnaseq\nrnaseq.sh\nsimulated_reads\nstar.sh\nthesis\ntrim.sh\ntrim_fq.sh\n\n\nBefore we learn more commands, let’s learn about the structure of commands.\n\n\n\nCommand syntax\nCommands follow a general syntax\ncommand option/flag argument\n\ncommand – the main command\noption/flag – modifies the behavior of the command, often optional\nargument – the source and/or target of the command, sometimes optional\n\n\n\n\n\n\n\nTip\n\n\n\n\nOptions use either - or -- to signal their usage.\nArguments can be either a target (as in the ls command) or both a source and target (as in the mv command)\n\n\n\n\nAlter Command Behavior\nLet’s change the way ls command behaves by providing a value for the option.\nIn your terminal, type ls -F and press enter.\n\nls -F\n\ncount.sh\nexample.gtf\nexercise-data/\nfastqc.sh\nfastqc_step.sh\nfeature_counts.sh\nindex/\nmetadata.txt\nnorth-pacific-gyre/\nrnaseq/\nrnaseq.sh\nsimulated_reads/\nstar.sh\nthesis/\ntrim.sh\ntrim_fq.sh\n\n\nThis -F option/flag returns the output in a different format, with a / following directories and @ preceeding symbolic links.\n\n\n\n\nGetting help\nTo better understand command usage and their options we can use the following (depending on the command).\n\n\n\n\n\n\n\n\nMethod of getting help\nDescription\nExample\n\n\n\n\n--help or -h option/flag\nDisplays help menu for the command/program\nls --help\n\n\nman command\nDisplays the manual for the command/program in-depth\nman ls\n\n\n\n\n\n\n\n\n\n\n(a) Using the --help flag\n\n\n\n\n\n\n\n(b) Using the man command\n\n\n\n\nFigure 2: Different ways to get help with a command.\n\n\n\n\n\nMaking sense of errors\nThe shell provides (usually) helpful and informative error messages.\nFor example, if you look closely at the ls --help example above, you’ll see that the usage of --help actually resulted in an error (see below).\n\nls: unrecognized option `--help'\nusage: ls [-@ABCFGHILOPRSTUWabcdefghiklmnopqrstuvwxy1%,] [--color=when] [-D format] [file ...]\n\n\nQ&A: What is the error above telling us?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n--help is an unrecognized option\n\nThe correct usage and options for ls"
  },
  {
    "objectID": "0-The-Unix-Shell/installation.html",
    "href": "0-The-Unix-Shell/installation.html",
    "title": "Installation and Resources",
    "section": "",
    "text": "Software\nBash Shell For this series, you will need access to the Bash shell. Linux and macOS users will have access to this already and should not need to install anything.\nWindows users will need to do some extra work.\n\nInstall Git for Windows, which will provide acess to Bash shell and Git by following the instructions here.\n\nRNA-seq processing workflow\nIn the final lesson, we will use miniconda to control in installation of several tools. Follow the steps below.\n\nInstall miniconda using the appropriate directions from here: https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html\nAfter closing and re-opening the terminal, the conda base environment should be enabled. To check this, make sure you see (base) to the left of your user name in the terminal prompt.\n(base) user: $\nCreate a conda environment called rnaseq while installing the needed tools/software – enter “y” when prompted.\nconda activate base\nconda create -n rnaseq -c bioconda fastqc trim-galore subread star\n\n\n\nData\nIntroductory Files These data are zipped and should begin downloading once the link below is clicked.\n\nClick here to download the data.\nMove the shell-lesson-data.zip file from your Downloads to your Desktop.\nUnzip the file to extract the data. You should end up with a shell-lesson-data directory on your Desktop.\n\nRNA-seq similated data/files For the last lesson, you will need simulated reads, fasta files, index files, etc.\n\nClick here to download the data.\nMove the directory to your Desktop if possible."
  },
  {
    "objectID": "0-The-Unix-Shell/variables-and-loops.html",
    "href": "0-The-Unix-Shell/variables-and-loops.html",
    "title": "Variables and Loops",
    "section": "",
    "text": "Storing and Using Values – Variables\nValues can be temporarily stored into items called variables. This is very useful in looping and scripting, particularly when we may not know or be able to keep track of values.\nInterestingly, we use diffent syntax when assigning/unsetting and using variables.\n\nsetting variables – use variable=value\nusing variables – use $variable\nunsetting variables – use unset variable\n\n#create a variable named file_type and assign it a value of fastq\nfile_type=\"fastq\"\n\n#call the file_type variable, print it to the screen\necho \"the value after setting:\" $file_type\n\n#unset (or remove) the variable assignment\nunset file_type\n\n#check for the value of file_type\necho \"the value after unsetting:\" $file_type \n\nthe value after setting: fastq\nthe value after unsetting:\n\n\n\n\n\n\n\n\n\nTips and Tricks with Variables\n\n\n\n\nWhen setting, no spaces around the = – variable = value will not do what we want.\nUsing quotes when calling variables prevents weird issues – command \"$variable\" prevents issues when variable values have spaces, etc.\nCommand output can be stored using $() – variable=$(command x) stores the output of command x as variable.\nSuffixes can be added by using ${variable} – \"${file_type}1\" from above would be fastq1\n\n\n\n\nVariables – Checking Understanding\n\nQ&A: Which of the following correctly assigns the value of fastq to a variable named file_suffix?\n\nfastq=$file_suffix\nfastq = $file_suffix\nfastq=file_suffix\nfile_suffix=fastq\nfile_suffix=$fastq\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nfastq=$file_suffix – No. Refers to a variable that doesn’t exist and wrong order.\nfastq = $file_suffix – No. The added space tries to call a command named fastq. Also, this is the wrong order.\nfastq=file_suffix – No. This is the wrong order and would create a variable called fastq.\nfile_suffix=fastq – Yes.\nfile_suffix=$fastq – No. Refers to a variable that doesn’t exist.\n\n\n\n\n\n\nQ&A: Which of the following correctly assigns the value of trt to a variable named var1?\nCorrect order, spacing and quotes/brackets\n\nvar1=${trt}\nvar1 =trt\nvar1=trt\nvar1=$trt\nvar1=\"trt\"\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nvar1=${trt} – No. Refers to variable that doesn’t exist.\nvar1 =trt – No. The added space tries to call a command named var1.\nvar1=trt – Yes.\nvar1=$trt – No. Refers to a variable that doesn’t exist.\nvar1=\"trt\" – Yes.\n\n\n\n\n\n\nQ&A: How can I save the value of the directory that I am in, as a variable named start_dir?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nstart_dir=\"$(pwd)\" and start_dir=$(pwd)\n\n\n\n\n\nQ&A: What would the value of out_var=$\"(ls)\" be?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n(ls). Why not the command output?\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$file1${ext1}\n\necho \"${name1}\"\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n.txt\nThe value of name1 begins with $file1, which is not a variable name, so it has no value. The only value assigned comes from ext1, references as ${ext1}.\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$base1$\"ext1\"\n\necho $name1\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nsampleXext1\nThe value of name1 begins with $base1, which is correctly referenced and holds the value of \"sampleX\". This is followed by $\"ext1\". There is no variable named \"ext1\", the variable is actually named ext1, which would be referenced by $ext1, or ${ext1}, or \"$ext1\", or \"${ext1}\". By having $ before the quotes, we’re really just adding in a string value at the end.\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$base1\"${ext1}\"\n\necho $name1\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nsampleX.txt\nThe value of name1 begins with $base1, which is correctly referenced and holds the value of \"sampleX\". This is followed by \"${ext1}\", which is correctly references and holds the value of .txt.\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$base1\"${ext1}\"\nunset $name1\n\necho $name1\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nsampleX.txt\nThe value of name1 begins with $base1, which is correctly referenced and holds the value of \"sampleX\". This is followed by \"${ext1}\", which is correctly references and holds the value of .txt. To unset, we need to pass the variable name (name1), not a reference to the variable ($name1).\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$base1\"${ext1}\"\nunset name1\n\necho $name1\".otherstuff\"\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n.otherstuff\nThe value of name1 is unset right before we reference it, so it holds not value. The last line, we print $name1, followed by a string \".otherstuff\".\n\n\n\n\n\n\n\nUse Case\nLet’s see how we can use variables, combined with previous commands/methods in a quick analysis.\nFrom the example.gtf file (downloaded and used in the previous lesson), which chromosome has the highest number of genes? What about exons?\nA reminder, the initial structure is below, with the chromosome name in the first field, and the feature type in the third field.\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# view first few lines of the file\nhead example.gtf\n\n#!genome-build CNA3\n#!genome-version CNA3\n#!genome-date 2015-11\n#!genome-build-accession GCA_000149245.3\n#!genebuild-last-updated 2015-11\n1   ena gene    100 5645    .   -   .   gene_id \"CNAG_04548\"; gene_source \"ena\"; gene_biotype \"protein_coding\";\n1   ena transcript  100 5645    .   -   .   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\";\n1   ena exon    5494    5645    .   -   .   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\"; exon_id \"AFR92135-1\";\n1   ena CDS 5494    5645    .   -   0   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\"; protein_id \"AFR92135\"; protein_version \"1\";\n1   ena start_codon 5643    5645    .   -   0   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\";\n\n\nFrom last time, we remember that we need to remove the leading lines of the file to make it easier to work with, using grep -v '^#', then we can cut the fields that we need, sort and count the total genes with sort | uniq -c | grep 'gene'. This gives us the following output.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the first and third columns (chromosome, biotype)\n# sort values\n# keep unique values, specifying counts of each unique value to get totals of biotypes by chromosome\n# pull out gene biotype totals\ncat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep 'gene'\n\n1033 1  gene\n 474 10 gene\n 663 11 gene\n 326 12 gene\n 322 13 gene\n 417 14 gene\n 706 2  gene\n 725 3  gene\n 503 4  gene\n 812 5  gene\n 640 6  gene\n 641 7  gene\n 639 8  gene\n 554 9  gene\n  42 Mt gene\n\n\nWe’re not quite there yet. Let’s capture the output as a variable, named chr_n, to use for later.\nNote: We’re introducing awk here, a language the is quite useful in parsing text, to print out the second column $2.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the first and third columns (chromosome, biotype)\n# sort values\n# keep unique values, specifying counts of each unique value to get totals of biotypes by chromosome\n# pull out gene biotype totals\n# grab the first line\n# use awk to print the 2nd column\nbiotype_gene=\"gene\"\nbiotype_exon=\"exon\"\nchr_n_gene=$(cat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep $biotype_gene | head -n 1 | awk '{print $2;}')\nchr_n_exon=$(cat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep $biotype_exon | head -n 1 | awk '{print $2;}')\n\necho \"The chromosome with the most \"$biotype_gene\" is: \"$chr_n_gene\necho \"The chromosome with the most \"$biotype_exon\" is: \"$chr_n_exon\n\nThe chromosome with the most gene is: 1\nThe chromosome with the most exon is: 1\n\n\nThe option to capture values and use them in further commands is really evident when we get into loops.\n\n\n\n\nPerforming Actions, Repetitively\nLoops allow us to perform a command (or set of commands) on each item in a list.\n\nFor Loop Syntax\nBash for loops follow a specific syntax.\n\n\n\nFigure 1: The syntax of a bash for loop.\n\n\nKey components of the syntax\n\nkeywords for, in, do, done – tell bash when portions of the loop are coming\nitem – a variable that holds the value of an item from the list for an iteration of the loop\nlist – a set of items (list or array) to iterate over\ncommands – the command(s) performed with each item in the list or array\n\n\nLet’s work through an example from our sample data in ~/Desktop/shell-lesson-data/exercise-data/creatures, by printing out the first two lines of each file.\nWalking through the 4 lines, line-by-line.\n\nFirst lineSecond lineThird lineFourth line\n\n\n\nThe keyword for tells the computer we are entering a loop.\nA variable named filename is created, which is initially empty.\nThe keyword in tells the computer to create an empty list.\nbasilisk.dat, minotour.dat, and unicorn.dat are added to the list.\n\n\n#cd to ~/Desktop/shell-lesson-data/\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\nfor filename in basilisk.dat minotaur.dat unicorn.dat\ndo\n  head -n 2 $filename\ndone\n\n\n\n\nThe keyword do tells the computer to listen for the following commands perform on each item in the list.\n\n\n#cd to ~/Desktop/shell-lesson-data/\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\nfor filename in basilisk.dat minotaur.dat unicorn.dat\ndo\n  head -n 2 $filename\ndone\n\n\n\n\nThe computer the commands to perform on the value held by the variable $filename.\n\n\n#cd to ~/Desktop/shell-lesson-data/\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\nfor filename in basilisk.dat minotaur.dat unicorn.dat\ndo\n  head -n 2 $filename\ndone\n\n\n\n\nThe keyword done tells the computer that the loop is over.\n\n\n#cd to ~/Desktop/shell-lesson-data/\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\nfor filename in basilisk.dat minotaur.dat unicorn.dat\ndo\n  head -n 2 $filename\ndone\n\n\n\n\nIn the example above, there are 3 iterations of the loop. Notice how the value of filename changes with each iteration.\n\n\n\n\n\n\n\n\nIteration\nfilename\nlist\n\n\n\n\n1\nbasilisk.dat\nbasilisk.dat minotaur.dat unicorn.dat\n\n\n2\nminotaur.dat\nbasilisk.dat minotaur.dat unicorn.dat\n\n\n3\nunicorn.dat\nbasilisk.dat minotaur.dat unicorn.dat\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe variable could be named anything – in the example above, we can say\nfor x in basilisk.dat minotaur.dat unicorn.dat instead.\n\n\n\n\n\nWhile Loop Syntax\nA while loop is another useful type of loop in bash and follows a specific syntax.\n\n\n\nFigure 2: The syntax of a bash while loop.\n\n\nKey components of the syntax\n\nkeywords while, do, done – tell bash when portions of the loop are coming\ncondition – a condition to be met for the loop to continue (“while true”)\ncommands – the command(s) performed with each item in the list or array\n\nLet’s see an example where we print out numbers less than or equal to 7 (-le).\nNote: We can increment num by 1 each time by reassigning the value of num, num=$(($num+1)).\n\nnum=1\n\nwhile [ $num -le 7 ]\ndo\n  echo $num\" is less than or equal to 7.\"\n  num=$(($num+1))\ndone\n\n1 is less than or equal to 7.\n2 is less than or equal to 7.\n3 is less than or equal to 7.\n4 is less than or equal to 7.\n5 is less than or equal to 7.\n6 is less than or equal to 7.\n7 is less than or equal to 7.\n\n\n\n\n\nUsing Variables in Loops\nLet’s return to our earlier example with the gtf file. Using a loop, we can now identify the chromosomes with the most of several biotypes.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\nfor bt in gene exon transcript CDS start_codon\ndo \n chr_n=$(cat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep $bt | head -n 1 | awk '{print $2;}')\n echo \"The chromosome with the most \"$bt\" is: \"$chr_n\ndone\n\nThe chromosome with the most gene is: 1\nThe chromosome with the most exon is: 1\nThe chromosome with the most transcript is: 1\nThe chromosome with the most CDS is: 1\nThe chromosome with the most start_codon is: 1\n\n\nWe can take this futher and capture all of the types of biotypes as an array to pass to the loop as a variable.\nNote: An item at position x in an array can be accessed via array[x]. In a loop, we use ${array[@]} to access the item.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# capture the types of biotypes as an array\nbtype_array=$(cat example.gtf | grep -v '^#' | cut -f3 | sort | uniq)\n\nfor bt in ${btype_array[@]}\ndo \n chr_n=$(cat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep $bt | head -n 1 | awk '{print $2;}')\n echo \"The chromosome with the most \"$bt\" is: \"$chr_n\ndone\n\nThe chromosome with the most CDS is: 1\nThe chromosome with the most exon is: 1\nThe chromosome with the most five_prime_utr is: 1\nThe chromosome with the most gene is: 1\nThe chromosome with the most start_codon is: 1\nThe chromosome with the most stop_codon is: 1\nThe chromosome with the most three_prime_utr is: 1\nThe chromosome with the most transcript is: 1\n\n\n\n\n\nLoops – Checking Understanding\n\nQ&A: Write a loop that would print out the months of the year. Create an array that holds the months.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nmonths_array=(january february march april may june july august september october november december)\n\nfor month in ${months_array[@]}\ndo\n  echo ${month}\ndone\n\njanuary\nfebruary\nmarch\napril\nmay\njune\njuly\naugust\nseptember\noctober\nnovember\ndecember\n\n\n\n\n\n\n\nQ&A: Look at the following code and output.\n\n$ ls\ncubane.pdb  ethane.pdb  methane.pdb octane.pdb  pentane.pdb propane.pdb\n\nWhat would be the output of the following code?\n\n$ for filename in c*\n  do \n    ls $filename\n  done\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\ncubane.pdb. The list that is iterated over is any file that startes with c.\n\n\n\n\nHopefully you’ve seen how helpful variables and loops can be. Next, we’ll put things together with bash scripts."
  },
  {
    "objectID": "0-The-Unix-Shell/the-file-system.html",
    "href": "0-The-Unix-Shell/the-file-system.html",
    "title": "The File System",
    "section": "",
    "text": "A Common Structure\nThe file system manages and organizes our files and directories using a common structure defined by:\n\nParent-child relationships\nA “family tree” (more like a root system) of “parent” and “child” relationships (Figure 1a).\nDirectionality\nParent items are at the top/up; child items are at the bottom/ down (Figure 1a).\nDifferent ways to access\nAccessible via command-line (Figure 1b) and GUI (Figure 1c).\n\n\n\n\n\n\n\n\n(a) A representative file system with parent-child relationships shown.\n\n\n\n\n\n\n\n\n\n(b) Accessing the file system via the command-line.\n\n\n\n\n\n\n\n(c) Accessing the file system via graphical interface.\n\n\n\n\nFigure 1: A representative file system.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe top-most directory is called the root directory and is shown with the /.\n\n\n\n\n\nPaths\nThe directories, files, and subdirectories of a file system are connected by paths. Paths also describe the locations within the file system.\n\n\n\nFigure 2: The absolute path from / to mouse.gtf, highlighted in red.\n\n\n\nAbsolute and Relative Paths\nThere are two types of paths:\n\nAbsolute path\nThe path taken from the top-most directory (root, /), to the specified file or directory. The absolute path always starts with /.\nRelative path\nThe path taken from the present working directory to the specified file or directory.\n\nExample paths to a few items from Figure 1a are shown below.\n\n\n\n\n\n\n\n\nTarget\nAbsolute Path\nRelative Path (from the /bin directory)\n\n\n\n\nplot.R\n/bin/plot.R\nplot.R\n\n\nconda\n/bin/conda\nconda\n\n\n\n\n\n., .., and ~ aliases\nThe characters ., .. and ~ have special meaning in the unix shells.\n\n. – Current directory\n.. – Parent directory\n~ – Users home directory\n\nFor example the following code means to do_the_thing in the current directory.\n\ndo_the_thing ./\n\nThe code below means to do_the_thing two directories above our current directory.\n\ndo_the_thing ../../\n\nFinally, the code below means to do_the_thing in the user’s home directory.\n\ndo_the_thing ~\n\n\nQ&A: If we are in the /tmp directory, what are the absolute and relative paths of the genome.fa file?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n\n\n\n\n\n\n\nTarget\nAbsolute Path\nRelative Path\n\n\n\n\ngenome.fa\n/data/genome.fa\n../data/genome.fa\n\n\n\n\n\n\n\n\n\n\n\nNavigating the File System\nLet’s learn a few useful commands for moving around the file system.\n\npwd – print working directory\nPrints out our current location, called our “working directory”.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\npwd\n\n\n\n\n\nRun the pwd command in your terminal.\n\npwd\n\n/Users/csifuentes/Desktop/shell-lesson-data\n\n\n\nQ&A: Is the path returned an absolute or relative path?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nAbsolute, the path starts with /. Also, pwd will always return the absolute path (from the root directory).\n\n\n\n\n\n\n\nls – list\nLists the items in a directory.\nWithout a target, the command defaults to the current directory (./)\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nls\nflags\npath/to/directory\n\n\n\nIn terminal, type ls and press enter/return.\n\nls\n\nexercise-data\nnorth-pacific-gyre\n\n\nItems in your home directory is listed, alphabetically. Flags/options can make the output more useful, a few are shown below.\n\n\n\n\n\n\n\nFlag\nDescription\n\n\n\n\n-l\nReturns the results in a long format, which provides information about\n\nthe item type (- for file, d for directory, l for link)\nitem permissions\nthenumber of links or files inside that item\nthe item owner\nthe item group\nthe time the item was created\nitem size\nitem name\n\n\n\n-h\nReturns the results with a human-readible size value\n\n\n-a\nIncludes entries beginning with a ., which are not shown by default\n\n\n\nLet’s use these 3 flags together. Type the ls -lha into your terminal.\n\nls -lha\n\ntotal 16\ndrwxrwxr-x@  5 csifuentes  staff   160B Mar  2 11:54 .\ndrwx------@  6 csifuentes  staff   192B Feb 27 13:35 ..\n-rw-r--r--@  1 csifuentes  staff   6.0K Feb 27 18:00 .DS_Store\ndrwxrwxr-x@  7 csifuentes  staff   224B Sep 16  2021 exercise-data\ndrwxrwxr-x@ 21 csifuentes  staff   672B Sep 16  2021 north-pacific-gyre\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe . is also used to hide items.\n\n\n\n\n\ncd – change directory\nChanges our location in the file system.\nNote: Without a target directory, cd will default to the user home directory.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ncd\n\npath/to/directory\n\n\n\n\nQ&A: Change your current working directory to be one directory above the current directory, then check the new working directory location and list it’s contents.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\ncd ..\npwd\nls -lha\n\n/Users/csifuentes/Desktop\ntotal 920\ndrwx------@  6 csifuentes  staff   192B Feb 27 13:35 .\ndrwxr-xr-x+ 73 csifuentes  staff   2.3K Mar  2 11:54 ..\n-rw-r--r--@  1 csifuentes  staff   6.0K Feb 17 11:08 .DS_Store\n-rw-r--r--   1 csifuentes  staff     0B Sep 22  2020 .localized\ndrwxrwxr-x@  5 csifuentes  staff   160B Mar  2 11:54 shell-lesson-data\n-rw-r--r--@  1 csifuentes  staff   450K Feb 24 15:42 shell-lesson-data.zip\n\n\n\n\n\n\nNow let’s move back into the shell-lesson-data directory.\n\ncd ~/Desktop/shell-lesson-data\n\n\n\n\nmkdir – make directory\nCreates new directories.\nNote: The -p flag will create the directory and any required intermediate directories.\n\n\n\n\n\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nmkdir\nflags\npath/to/directory path/to/additional/directory\n\n\n\nLet’s pretend we want to create a directory structure for our thesis work. We need the following:\n\nA top-level directory.\nSeparate directories for each chapter (we have 5).\nDirectories for images, data, and text of each chapter.\n\nWe’ll do this using only the commands we’ve learned thus far (except for my use of tree to easily view directory structures). Later, we’ll learn quicker ways to do this.\nMake a top-level directory.\n\n# let's first change into our shell-lesson-data directory\ncd ~/Desktop/shell-lesson-data\n\n# make the directory\nmkdir -p thesis\n\n# look at the structure of thesis\ntree thesis\n\nthesis\n\n0 directories, 0 files\n\n\nCreate a directory for each chapter.\n\n# create all of the directories at one time\nmkdir -p thesis/chapter_1 thesis/chapter_2 thesis/chapter_3 thesis/chapter_4 thesis/chapter_5\n\n# look at the structure of thesis\ntree thesis\n\nthesis\n├── chapter_1\n├── chapter_2\n├── chapter_3\n├── chapter_4\n└── chapter_5\n\n5 directories, 0 files\n\n\nCreate a directory for each subsection of each chapter.\n\n# create sub-directories in each chapter\nmkdir -p thesis/chapter_1/images thesis/chapter_1/data thesis/chapter_1/text\nmkdir -p thesis/chapter_2/images thesis/chapter_2/data thesis/chapter_2/text\nmkdir -p thesis/chapter_3/images thesis/chapter_3/data thesis/chapter_3/text\nmkdir -p thesis/chapter_4/images thesis/chapter_4/data thesis/chapter_4/text\nmkdir -p thesis/chapter_5/images thesis/chapter_5/data thesis/chapter_5/text\n\n# look at the structure of thesis\ntree thesis\n\nthesis\n├── chapter_1\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_2\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_3\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_4\n│   ├── data\n│   ├── images\n│   └── text\n└── chapter_5\n    ├── data\n    ├── images\n    └── text\n\n20 directories, 0 files\n\n\n\n\n\n\n\n\nGood file and directory names\n\n\n\nComplicated names make it difficult when working on the CL\n\nDo not use spaces – bash reads these a separate arguments\nDo not begin with a dash, “-” – bash reads these a options\nUse alpha-numeric, ., -, and _\n\nIf you need refer to a file/directory that contains a space, put the entire thing in ” ”\n\"/root/subdir/file with spaces\"\n\n\n\n\n\n\nWorking in the File System\nNow let’s learn some useful ways to work in the file system.\n\nText Editors\nAllow one to create and edit text files\n\nusing plain characters only, unlike MS Word and Google Docs\nvarying easy of use and capability of the text editors\ncan use in-terminal (in the shell) or GUI (external)\n\n\n\n\nIn-Terminal Examples\nGUI Examples\n\n\n\n\npico, nano\nnotepad, notepad++\n\n\nemacs, Vim\nAtom, Visual Studio Code\n\n\n\n\n\n\n\n\n(a) In-terminal Editor – nano\n\n\n\n\n\n(b) GUI Editor – Visual Studio Code\n\n\nFigure 3: In-live vs GUI text editors\n\n\nContinuing with our thesis work, let’s create a README.txt file to keep track of each chapter directory.\n\n\nnano – in-line text editor\nOpens the editor into a file (or new file if it doesn’t exist).\nNote: Creates the target file if it does not already exist. Flags and arguments are optional here.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nnano\nflags\npath/to/file\n\n\n\nLet’s create the README.txt file in our thesis directory.\n\nnano ~/Desktop/shell-lesson-data/thesis/README.txt\n\nA file will open in the editor. Follow the directions in Figure 4 below.\n\n\n\nFigure 4: Edit and save the file as README.txt using the nano editor.\n\n\nLooking in thesis, we see our new file.\n\nls ~/Desktop/shell-lesson-data/thesis\n\nREADME.txt\nchapter_1\nchapter_2\nchapter_3\nchapter_4\nchapter_5\n\n\n\n\n\ncp – copy\nCopies and pastes items with a single command.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ncp\nflags\npath/to/source path/to/destination\n\n\n\nIt might be nice to have a README in each chapter directory. Let’s use the cp command to do this.\n\n# copy to each chapter directory\ncp thesis/README.txt thesis/chapter_1/\ncp thesis/README.txt thesis/chapter_2/\ncp thesis/README.txt thesis/chapter_3/\ncp thesis/README.txt thesis/chapter_4/\ncp thesis/README.txt thesis/chapter_5/\n\n# view the structure of thesis\ntree thesis\n\nthesis\n├── README.txt\n├── chapter_1\n│   ├── README.txt\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_2\n│   ├── README.txt\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_3\n│   ├── README.txt\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_4\n│   ├── README.txt\n│   ├── data\n│   ├── images\n│   └── text\n└── chapter_5\n    ├── README.txt\n    ├── data\n    ├── images\n    └── text\n\n20 directories, 6 files\n\n\nThis was tedious. Don’t worry, we’ll learn more efficient ways to do this.\n\n\n\nmv – move and rename\nMoves and renames items, including files and directories. Note that the last argument is the destination.\n\n\n\n\n\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nmv\nflags\npath/to/source path/to/other/source path/to/destination\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe mv command will overwrite a files without warning!\n\nuse the -n flag to prevent overwriting existing files\nuse the -i flag to prompt for confirmation before overwriting existing files\n\n\n\nLet’s rename the README.txt file in the chapter 1 directory so that it contains the chapter number.\n\n# rename the file\nmv thesis/chapter_1/README.txt thesis/chapter_1/README_1.txt\n\n# list files in chapter 1\nls thesis/chapter_1\n\nREADME_1.txt\ndata\nimages\ntext\n\n\n\n\n\nrm – remove\nDeletes the specified target.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nrm\nflags\npath/to/target\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nUnlike in the GUI, rm deletes items permanently!\n\nuse the -r flag to remove files and directories recursively\nuse the -i flag to prompt for confirmation before deleting each item\n\n\n\nFor fun, let’s remove the thesis directory.\n\n# remove the items (files and directories) recursively\nrm -r thesis\n\n# list items in shell-lesson-data\nls\n\nexercise-data\nnorth-pacific-gyre\n\n\n\n\n\n\nIntroducing Wildcards\nWildcards represent 0 or more characters and are used for pattern matching.\n\n* – 0 or more characters\n\n? – exactly 1 character\n\nLet’s see some examples with of each. From our shell-lesson-data/exercise-data/proteins.\nListing all files.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/proteins\n\n# list all files in proteins\nls \n\ncubane.pdb\nethane.pdb\nmethane.pdb\noctane.pdb\npentane.pdb\npropane.pdb\n\n\nListing files ending in ethane.pdb, using *. Note that we use the * at the end becuase all files have the same .pdb ending, so this is faster.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/proteins\n\nls *ethane.*\n\nethane.pdb\nmethane.pdb\n\n\nListing files ending in ethane.pdb with a preceeding character, using ?.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/proteins\n\nls ?ethane.*\n\nmethane.pdb\n\n\nAs shown above, wildcards can be used together and combined in different ways to form complex patterns.\nFor example, we can use ???ane.pdb together to indicate any 3 characters followed by ane.pdb.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/proteins\n\n# list all files with 3 characters followed by ane.pdb\nls ???ane.pdb\n\ncubane.pdb\nethane.pdb\noctane.pdb\n\n\n\n\n\nQuiz Time\n\nQuestion 1:\nStarting from /Users/amanda/data, which command(s) whould take Amanda to her home directory (/Users/amanda)?\n\n\n\n\n\n\na.) cd .\n\n\n\n\n\nNO, will be in the same place\n\n\n\n\n\n\n\n\n\nb.) cd /\n\n\n\n\n\nNO, will be in root\n\n\n\n\n\n\n\n\n\nc.) cd /home/amanda\n\n\n\n\n\nNO, not where we want to be\n\n\n\n\n\n\n\n\n\nd.) cd ../..\n\n\n\n\n\nNO, will be in /Users\n\n\n\n\n\n\n\n\n\ne.) cd ~\n\n\n\n\n\nYES, ~ is an alias for the user’s home directory\n\n\n\n\n\n\n\n\n\nf.) cd home\n\n\n\n\n\nNO, not a thing\n\n\n\n\n\n\n\n\n\ng.) cd\n\n\n\n\n\nYES, without input cd will take you to the home directory\n\n\n\n\n\n\n\n\n\nh.) cd ..\n\n\n\n\n\nYES\n\n\n\n\n\nQuestion 2:\nWith the file system shown, if pwd displays Users/thing, what will ls -F ../backup display?\nNote: -F adds a / to the end of directories.\n\n\n../backup: No such file or directory\n2012-12-01 2013-01-08 2013-01-27\n2012-12-01/ 2013-01-08/ 2013-01-27/\noriginal/ pnas_final/ pnas_sub/\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n../backup/ refers to /Users/backup\n\n\n\n\n\n\nQuestion 3:\nWith the file system below, if pwd displays /Users/backup and ls -r displays items in reverse order, what command(s) will result in the following output?\npnas_sub/ pnas_final/ original/\n\n\nls pwd\nls -r -F\nls -r -F /Users/backup\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nYES.\nYES.\n\n\n\n\n\n\nQuestion 4:\nChris runs the following commands and realizes that sucrose.dat and maltose.dat should be in the raw/ directory.\n\n$ ls -F\n analyzed/ raw/\n$ ls -F analyzed\nfructose.dat glucose.dat maltose.dat sucrose.dat\n$ cd analyzed\n\nComplete the command below to move these files into the raw/ directory.\n\n$ mv sucrose.dat maltose.dat _____/____\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n$ mv sucrose.dat maltose.dat ../raw\n\n\n\n\n\n\nQuestion 5:\nChris gave you a file named file.txt, which contains a list of his favorite animals. You want to rename it to why_do_i_need_this.txt. Which of the following commands would do the trick?\n\ncp file.txt why_do_i_need_this.txt\nmv file.txt why_do_i_need_this.txt\nmv file.txt .\ncp file.txt .\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nNo. This creates a new file instead of renaming the old file.\nYES. This renames the file.\nNo. This moves the file to the current directory with no new file name – would throw an error.\nNo. This copies the file to the current directory with no new file name – would throw an error.\n\n\n\n\n\n\nQuestion 6:\nWhat is the output of the final ls command in the sequence shown below?\n\n$ pwd\n /Users/jamie/data\n$ ls \n proteins.dat\n$ mkdir recombined\n$ mv proteins.dat recombined/\n$ cp recombined/proteins.dat ../proteins-saved.dat\n$ ls\n\n\nproteins-saved.dat recombined\nrecombined\nproteins.dat recombined\nproteins-saved.dat\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nrecombined\n\n\n\n\n\n\nQuestion 7:\nChris accidentally removed a file named important_file.txt. How can the file be retrieved?\n\nrm --undo\n“^Z”, control+Z\nRestore from the “Trash” bin\nIt can’t.\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nIt can’t. Be very careful when removing files/directories.\n\n\n\n\n\n\nQuestion 8:\nWhen run the in proteins/ directory, which command(s) will produce the output below?\nethane.pdb methane.pdb\n\nls *t*ane.pdb\nls *t?ne.*\nls *t??ne.pdb\nls ethane.*\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nNo. Would give ethane.pdb methane.pdb octane.pdb pentane.pdb\nNo. Would give octane.pdb pentane.pdb\nYES.\nNo. Would give ethane.pdb\n\n\n\n\n\n\nQuestion 9:\nSam has the following diretory structure.\n\n.\n├── 2015-10-23-calibration.txt\n├── 2015-10-23-dataset1.txt\n├── 2015-10-23-dataset2.txt\n├── 2015-10-23-dataset_overview.txt\n├── 2015-10-26-calibration.txt\n├── 2015-10-26-dataset1.txt\n├── 2015-10-26-dataset2.txt\n├── 2015-10-26-dataset_overview.txt\n├── 2015-11-23-calibration.txt\n├── 2015-11-23-dataset1.txt\n├── 2015-11-23-dataset2.txt\n├── 2015-11-23-dataset_overview.txt\n├── backup\n│   ├── calibration\n│   └── datasets\n└── send_to_bob\n    ├── all_datasets_created_on_a_23rd\n    └── all_november_files\n\nSam uses the following commands to create a backup directory and another directory to send to her collaborator, Bob.\n\n$ cp *dataset* backup/datasets\n$ cp ____calibration____ backup/calibration\n$ cp 2015-____-____ send_to_bob/all_november_files/\n$ cp ____ send_to_bob/all_datasets_created_on_a_23rd/\n\nHelp Sam by filling in the blanks so that the resulting structure looks like this.\n\n.\n├── 2015-10-23-calibration.txt\n├── 2015-10-23-dataset1.txt\n├── 2015-10-23-dataset2.txt\n├── 2015-10-23-dataset_overview.txt\n├── 2015-10-26-calibration.txt\n├── 2015-10-26-dataset1.txt\n├── 2015-10-26-dataset2.txt\n├── 2015-10-26-dataset_overview.txt\n├── 2015-11-23-calibration.txt\n├── 2015-11-23-dataset1.txt\n├── 2015-11-23-dataset2.txt\n├── 2015-11-23-dataset_overview.txt\n├── backup\n│   ├── calibration\n│   │   ├── 2015-10-23-calibration.txt\n│   │   ├── 2015-10-26-calibration.txt\n│   │   └── 2015-11-23-calibration.txt\n│   └── datasets\n│       ├── 2015-10-23-dataset1.txt\n│       ├── 2015-10-23-dataset2.txt\n│       ├── 2015-10-23-dataset_overview.txt\n│       ├── 2015-10-26-dataset1.txt\n│       ├── 2015-10-26-dataset2.txt\n│       ├── 2015-10-26-dataset_overview.txt\n│       ├── 2015-11-23-dataset1.txt\n│       ├── 2015-11-23-dataset2.txt\n│       └── 2015-11-23-dataset_overview.txt\n└── send_to_bob\n    ├── all_datasets_created_on_a_23rd\n    │   ├── 2015-10-23-dataset1.txt\n    │   ├── 2015-10-23-dataset2.txt\n    │   ├── 2015-10-23-dataset_overview.txt\n    │   ├── 2015-11-23-dataset1.txt\n    │   ├── 2015-11-23-dataset2.txt\n    │   └── 2015-11-23-dataset_overview.txt\n    └── all_november_files\n        ├── 2015-11-23-calibration.txt\n        ├── 2015-11-23-dataset1.txt\n        ├── 2015-11-23-dataset2.txt\n        └── 2015-11-23-dataset_overview.txt\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n$ cp *calibration.txt backup/calibration\n$ cp 2015-11-* send_to_bob/all_november_files/\n$ cp *-23-dataset* send_to_bob/all_datasets_created_on_a_23rd/"
  },
  {
    "objectID": "2-Intro-to-R/introduction-to-r-and-rstudio.html",
    "href": "2-Intro-to-R/introduction-to-r-and-rstudio.html",
    "title": "Introduction to R and RStudio",
    "section": "",
    "text": "What is R? What is R Studio?\n\nR is a (mostly statistical) programming language and a software that interprets scripts written in R\nRStudio is an interface used to interact with R\n\n\n\n\nWhy learn R?\nIncreased reproducibility\nWhen using code, your analysis can be clearly understood and easily rerun.\nIncreased extensibility\nCombine R with 10,000+ packages to extend capabilities including image analysis, time-series, population genetics, additional languages, making websites, and more.\nWorks with a variety of data types, shapes, and sizes\nR has special data structures and data types to handle all sorts of data.\nR can also connect to spreadsheets, databases, and read in special data formats.\nCan produce publication-quality graphics Base functionality and packages allow you to create a variety of graphics, while controlling minute details.\nHas a large and welcoming community\nThe R user-community is VERY active, helpful, and welcoming.\nMany resources have been developed to help people learn how to use R.\n\n\n\n\n\n\nTip\n\n\n\nLooking for community and community resources?\n\nStack Overflow\nRStudio Community\nhttps://www.rfordatasci.com/\nhttps://rladies.org/\n\n\n\n\n\n\nKnowing your around RStudio\nRStudio is an Integrated Development Environment (IDE) for working with R and can be use to do many things. We will cover things in bold and italics.\n\nwrite code and scripts\nrun code\nnavigate files on your computer\ninspect variables and data objects\nvisualize plots\nenable version control\ndevelop packages\nwrite Shiny apps\n\n\n\n\nFigure 1: RStudio interface screenshot. Clockwise from top left: Source,Environment/History, Files/Plots/Packages/Help/Viewer,Console. [1]\n\n\nRStudio is divided into 4 “panes”:\n\nThe Source for your scripts and documents (top-left, in the default layout)\nYour Environment/History (top-right) which shows all the objects in your working space (Environment) and your command history (History)\nYour Files/Plots/Packages/Help/Viewer (bottom-right)\nThe R Console (bottom-left)\n\n\n\n\nGetting Set Up\nWe want to keep our work (data, analyses, text) self-contained in a single directory, called the working directory. This allows us to use relative paths to other files in our scripts within that working directory so that we can move our project to other locations and share our project with others without breaking any scripts.\nWe can do this using “Projects” in RStudio.\n\nStart RStudio.\nUnder the File menu, click on New Project. Choose New Directory, then New Project.\nEnter a name for this new folder (or “directory”), and choose a convenient location for it. This will be your working directory for the rest of the day (e.g., ~/data-carpentry).\nClick on Create Project.\nDownload the code handout, place it in your working directory and rename it (e.g.,data-carpentry-script.R).\n(Optional) Set Preferences to ‘Never’ save workspace in RStudio.\n\n\n\n\n\n\n\nTip\n\n\n\nWorkspaces\nA workspace is your working environment in R and includes any user-defined object.\nBy default, all objects in a workspace are saved (to .RData) and reloaded when you open your project. While this can be useful, this can result in debugging issues by having objects in memory that you forgot about. Therefore, we recommended to turn this off by\n\nGo to Tools > Global Options.\nSelect ‘Never’ option for ‘Save workspace to .RData on exit.’\n\n\n\n\nFigure 2: Set ‘Save workspace to .RData on exit’ to’Never’. [1]\n\n\n\n\n\n\n\nThe Working Directory\nThe working directory is the place from there R (and your computer) will be looking for and saving files and directories.\nIt’s good practice to develop a common structure for your projects to:\n\nkeep things organized\nensure you and others can find things in various projects\nincrease the portability of scripts that might be useful in multiple projects\n\n\n\n\n\n\n\n\nDirectory\nContains\n\n\n\n\nscripts/\nR scripts for analyses, plotting, etc.\n\n\ndata/\nRaw data and processed data (probably should be kept separately)\n\n\ndocuments/\nOutlines, drafts, other texts\n\n\n\nCreating our directory structure\nFor our purposes, we’ll create the following structure\n\n\n\nFigure 3: How it should look like at the beginning of this lesson [1]\n\n\nThat means a working directory called data-carpentry, then 3 subdirectories, data_raw, data, and fig.\nLet’s do this programmatically in the Console.\n\nUse R command called dir.create, passing the value “~/data_carpentry” as the “path”.\n\n\ndir.create(\"~/data-carpentry\")\n\n\nCreate the subdirectories.\n\n\ndir.create(\"~/data-carpentry/data_raw\")\ndir.create(\"~/data-carpentry/data\")\ndir.create(\"~/data-carpentry/fig\")\n\n\n\n\n\n\n\nTip\n\n\n\nThe tilde ~ is a special character that means the home directory of the user.\n\n\n\n\n\nInteracting with R\nIn order to do anything in R we need to tell the computer what to do. We do this with a command. An example is the dir.create command that you used to create the directory structure just now. We can do this in 2 ways\n\nusing the console (as you did above)\nusing the script pane above\n\nWhat’s the benefit of using the script?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nReproducibility. Commands types in the console will eventually disappear. Using a script allows you to keep a record of what was done.\n\n\n\nRStudio allows you to execute commands directly from the script editor.\n\n\n\n\n\n\n\nOS\nShortcut\n\n\n\n\nWindows\nCtrl + Enter\n\n\nmacOS\nCtrl + Enter OR Cmd + Return\n\n\n\nYou can find other keyboard shortcuts in this RStudio cheatsheet about the RStudioIDE.\n\n\n\nSeeking help\nIf you need help with a specific function, for instance mean(), you can type ?mean() and press enter. Documentation on the function will pop up in the Help window.\n\n\n\nFigure 4: RStudio help panel. When typing a word in the search field, it will show related suggestions. [1]\n\n\n\n\n\nAutomatic Code Completion\nWhen you write code in RStudio, you can use its automatic code completion to remind yourself of a function’s name or arguments.\n\nStart typing the function name and pay attention to the suggestions that pop up.\nUse the up and down arrow to select a suggested code completion and Tab to apply it.\n\n\n\n\n\n\n\nTip\n\n\n\nYou can also use code completion to complete function’s argument names, object, names and file names. It even works if you don’t get the spelling 100% correct.\n\n\n\n\n\nDealing with error messages\nWe WILL encounter errors, and a lot of them! Watch for red “X”’s next to the line number in RStudio to catch them.\n\n\n\nFigure 5: RStudio shows a red x next to a line of code that R doesn’t understand. [1]\n\n\nIf you need more help\n\nGoogle the error\nAsk a question (with appropriate context and an example) on Stack Overflow\n\n\n\n\nCreating objects in R\nYou can get output from R simply by typing math in the console:\n\n3 + 5\n\n[1] 8\n\n12 / 7\n\n[1] 1.714286\n\n\n\nThis can be more useful if we store these values as objects, which would allow us to refer back to these objects later.We do this by using the assignment operator <-.\nFor example, if we wanted to create an object named weight_kg and assign it the value of 55, we could type the following\n\nweight_kg <- 55\n\n\n\n\n\n\n\n\nNote\n\n\n\nA note on naming\nObjects can be named just about anything (x, the_thing, other_5tUfF). Be thoughtful about what you use. Below are some guidelines\n\nBe explicit and not too long.\nThey cannot start with a number (2x is not valid, but x2 is).\nR is case sensitive, so for example, weight_kg is different from Weight_kg.\nThere are some names that cannot be used because they are the names of fundamental functions in R (e.g., if, else, for, see here for a complete list). If in doubt, double-check\nAvoid dots (.) within names. Dots have a special meaning (methods) in R and other programming languages. To avoid confusion, don’t include dots in names.\nUse nouns for object names and verbs for function names.\nBe consistent in the styling of your code, such as where you put spaces, how you name objects, etc.\n\n\n\n\nWhen assigning a value to an object, R does not print anything. You can force R to print the value by using parentheses or by typing the object name:\n\nweight_kg <- 55    # doesn't print anything\n(weight_kg <- 55)  # but putting parenthesis around the call prints the value of `weight_kg`\n\n[1] 55\n\nweight_kg          # and so does typing the name of the object\n\n[1] 55\n\n\n\nNow that R has weight_kg in memory, we can do arithmetic with it. Let’s convert this weight into pounds (weight in pounds is 2.2 times the weight in kg):\n\n2.2 * weight_kg\n\n[1] 121\n\n\n\nWe can also change an object’s value by assigning it a new one:\n\nweight_kg <- 57.5\n2.2 * weight_kg\n\n[1] 126.5\n\n\n\nAssigning a value to one object does not change the values of other objects.\nFor example, let’s store the animal’s weight in pounds in a new object, weight_lb:\n\nweight_lb <- 2.2 * weight_kg\n\nNow, let’s change weight_kg to 100.\n\nweight_kg <- 100\n\nWhat do you think is the current content of the object weight_lb? 126.5 or 220?\n\n\n\nSaving your code\nUntil now, we’ve used the console. Since we want to save our work, let’s\n\nOpen up a script – by pressing Ctrl + Shift + N.\nSave the script – by pressing Ctrl + S and selecting the save location, and naming it.\n\n\n\n\nAdding Comments\nIn R the comment character is #. Anything to the right of # in a script will be ignored by R. We use comments to leave notes and explanations in scripts.\n\n\nChallenge\n\nQ&A: What are the values after each statement in the following?\n\nmass <- 47.5            # mass?\nage  <- 122             # age?\nmass <- mass * 2.0      # mass?\nage  <- age - 20        # age?\nmass_index <- mass/age  # mass_index?\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nmass <- 47.5            # mass is 47.5\nage  <- 122             # age is 122\nmass <- mass * 2.0      # mass is 95\nage  <- age - 20        # age is 102\nmass_index <- mass/age  # mass_index is 0.9313725\n\n\n\n\n\n\n\n\n\nFunctions and their arguments\nFunctions are “canned scripts” that automate more complicated sets of commands including operations assignments, etc.\n\nUsually takes one or more inputs called arguments\nOften return a value (but not always)\nExample: sqrt() takes a number as the argument and returns the square root of the number\n\n\n\n\n\n\n\nNote\n\n\n\nMany functions are predefined, or can be made available by importing R packages (more on that later).\n\n\n\nExecuting a function (‘running it’) is called calling the function. An example of a function call is:\n\nweight_kg <- sqrt(10)\n\nLet’s break it down\n\nthe value of 10 is given to the sqrt() function\nthe sqrt() function calculates the square root\nthe function returns the value which is then assigned to the object weight_kg\n\n\nReturn values\nAs noted earlier, a value is not always returned. If returned, the return ‘value’\n\ncan be any value, or thing\ncan be multiple values (a set of things)\ncan even be a dataset\n\nArguments\nArguments can be anything, not only numbers or filenames, but also other objects.\n\nEach argument can differ based on the function, and must be looked up in the documentation (see below).\nSome functions take multiple arguments\nSome arguments MUST be specified by the user when calling the function\nSome arugments might take on a default value (these are called options) if left out\n\n\n\n\n\n\n\nTip\n\n\n\nOptions are typically used to alter the way the function operates, such as whether it ignores ‘bad values’, or what symbol to use in a plot. However, if you want something specific, you can specify a value of your choice which will be used instead of the default.\n\n\n\nLet’s try a function that can take multiple arguments: round().\n\nround(3.14159)\n\n[1] 3\n\n\nWe called round() with just one argument, 3.14159, and it returned the value 3. That’s because the default is to round to the nearest whole number.\n\nLet’s modify the number of digits we want in the answer. How do we know how to find more information about the round function?\nWe can use args(round) to find what arguments it takes.\n\nargs(round)\n\nfunction (x, digits = 0) \nNULL\n\n\nWe can also look at the help for this function using ?round.\n\n?round\n\nWe see that if we want a different number of digits, we can type digits = 2 or however many we want. Let’s try it.\n\nround(3.14159, digits = 2)\n\n[1] 3.14\n\n\n\nIf you provide the arguments in the exact same order as they are defined you don’t have to name them:\n\nround(3.14159, 2)\n\n[1] 3.14\n\n\nAnd if you do name the arguments, you can switch their order:\n\nround(digits = 2, x = 3.14159)\n\n[1] 3.14\n\n\n\n\n\n\n\n\nTip\n\n\n\nIt’s good practice to put the non-optional arguments (like the number you’re rounding) first in your function call, and to then specify the names of all optional arguments. If you don’t, someone reading your code might have to look up the definition of a function with unfamiliar arguments to understand what you’re doing.\n\n\n\n\n\nVectors and data types\nA vector is the most common and basic data type in R.\n\nCan be a series of values (numbers or characters).\nAssigned using c() function\n\nFor example, let’s create a vector of animal weights and assign it to an object weight_g:\n\nweight_g <- c(50, 60, 65, 82)\nweight_g\n\n[1] 50 60 65 82\n\n\n\nA vector can also contain characters:\n\nanimals <- c(\"mouse\", \"rat\", \"dog\")\nanimals\n\n[1] \"mouse\" \"rat\"   \"dog\"  \n\n\nThe quotes around “mouse”, “rat”, etc. are essential here. Without the quotes R will assume objects have been created called mouse, rat and dog. As these objects don’t exist in R’s memory, there will be an error message.\n\nThere are many functions that allow you to inspect the content of a vector. length() tells you how many elements are in a particular vector:\n\nlength(weight_g)\n\n[1] 4\n\nlength(animals)\n\n[1] 3\n\n\n\nAll of the elements are the same type of data. The function class() indicates what kind of object you are working with:\n\nclass(weight_g)\n\n[1] \"numeric\"\n\nclass(animals)\n\n[1] \"character\"\n\n\n\nThe function str() provides an overview of the structure of an object and its elements. It is a useful function when working with large and complex objects:\n\nstr(weight_g)\n\n num [1:4] 50 60 65 82\n\nstr(animals)\n\n chr [1:3] \"mouse\" \"rat\" \"dog\"\n\n\n\nYou can use the c() function to add other elements to your vector:\n\nweight_g <- c(weight_g, 90) # add to the end of the vector\nweight_g <- c(30, weight_g) # add to the beginning of the vector\nweight_g\n\n[1] 30 50 60 65 82 90\n\n\nLet’s break this down:\n\nIn the first line, we take the original vector weight_g, add the value 90 to the end of it, and save the result back into weight_g.\nThen we add the value 30 to the beginning, again saving the result back into weight_g.\n\nWe can do this over and over again to grow a vector, or assemble a dataset. As we program, this may be useful to add results that we are collecting or calculating.\n\nAn atomic vector is the simplest R data type and is a linear vector of a single type. These are the basic building blocks that all R objects are built from.\nThe there are 6 main atomic vector thar R uses:\n\n\"character\" for character (A) or string values (Apple)\n\"numeric\" (or \"double\") for all real numbers with our without decimal values\n\"logical\" for TRUE and FALSE (the boolean data type)\n\"integer\" for integer numbers (e.g., 2L, the L suffix indicates to R that it’s an integer)\n\"complex\" to represent complex numbers with real and imaginary parts (e.g.,1 + 4i) and that’s all we’re going to say about them\n\"raw\" for bitstreams that we won’t discuss further\n\nYou can check the type of your vector using the typeof() function and inputting your vector as the argument.\n\nVectors are one of the many data structures that R uses. Other important ones are lists (list), matrices (matrix), data frames (data.frame), factors (factor) and arrays (array).\n\n\nChallenge\n\nQ&A: What happens if we try to mix these types in a single vector?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nR implicitly converts them to all be the same type\n\n\n\n\n\nQ&A: What will happen in each of these examples? (hint: use class() to check the data type of your objects):\n\nnum_char <- c(1, 2, 3, \"a\")\nnum_logical <- c(1, 2, 3, TRUE)\nchar_logical <- c(\"a\", \"b\", \"c\", TRUE)\ntricky <- c(1, 2, 3, \"4\")\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nnum_char <- c(1, 2, 3, \"a\")\nnum_logical <- c(1, 2, 3, TRUE)\nchar_logical <- c(\"a\", \"b\", \"c\", TRUE)\ntricky <- c(1, 2, 3, \"4\")\n\nclass(num_char)\n\n[1] \"character\"\n\nclass(num_logical)\n\n[1] \"numeric\"\n\nclass(char_logical)\n\n[1] \"character\"\n\nclass(tricky)\n\n[1] \"character\"\n\n\n\n\n\n\n\nQ&A: Why do you think it happens?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nVectors can be of only one data type. R tries to convert (coerce) the content of this vector to find a “common denominator” that doesn’t lose any information.\n\n\n\n\n\nQ&A: How many values in combined_logical are \"TRUE\" (as a character) in the following example (reusing the 2 ..._logicals from above):\n\ncombined_logical <- c(num_logical, char_logical)\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nOnly one. There is no memory of past data types, and the coercion happens the first time the vector is evaluated. Therefore, the TRUE in num_logical gets converted into a 1 before it gets converted into \"1\" in combined_logical.\n\n\n\n\n\nQ&A: You’ve probably noticed that objects of different types get converted into a single, shared type within a vector. In R, we call converting objects from one class into another class coercion. These conversions happen according to a hierarchy, whereby some types get preferentially coerced into other types. Can you draw a diagram that represents the hierarchy of how these data types are coerced?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nlogical → numeric → character ← logical\n\n\n\n\n\n\n\n\nSubsetting vectors\nIf we want to extract one or several values from a vector, we must provide one or several indices (positions of elements in the object, starting with 1) in square brackets.\nFor instance:\n\nanimals <- c(\"mouse\", \"rat\", \"dog\", \"cat\")\nanimals[2]\n\n[1] \"rat\"\n\nanimals[c(3, 2)]\n\n[1] \"dog\" \"rat\"\n\n\n\nWe can also repeat the indices to create an object with more elements than the original one:\n\nmore_animals <- animals[c(1, 2, 3, 2, 1, 4)]\nmore_animals\n\n[1] \"mouse\" \"rat\"   \"dog\"   \"rat\"   \"mouse\" \"cat\"  \n\n\n\nR indices start at 1. Programming languages like Fortran, MATLAB, Julia, and R start counting at 1, because that’s what human beings typically do. Languages in the C family (including C++, Java, Perl, and Python) count from 0 because that’s simpler for computers to do.\n\nConditional subsetting\nAnother common way of subsetting is by using a logical vector.\n\nTRUE will select the element with the same index\nFALSE will not select the element with the same index\n\n\nweight_g <- c(21, 34, 39, 54, 55)\nweight_g[c(TRUE, FALSE, FALSE, TRUE, TRUE)]\n\n[1] 21 54 55\n\n\n\nSome functions and logical tests will output vectors of logical values, which can be useful.\nFor exmaple, if you wanted to select only the values above 50:\n\nweight_g > 50    # will return logicals with TRUE for the indices that meet the condition\n\n[1] FALSE FALSE FALSE  TRUE  TRUE\n\n## so we can use this to select only the values above 50\nweight_g[weight_g > 50]\n\n[1] 54 55\n\n\nLet’s break it down. 1. The weight_g > 50 inside the brackets is evaluated and returns a list of TRUE for indices less than 50 2. The outside weight_g is subsetted based on that returned list, pulling out only the indices that are TRUE\n\nYou can combine multiple tests using & (both conditions are true, AND) or | (at least one of the conditions is true, OR):\n\nweight_g[weight_g > 30 & weight_g < 50]\n\n[1] 34 39\n\nweight_g[weight_g <= 30 | weight_g == 55]\n\n[1] 21 55\n\nweight_g[weight_g >= 30 & weight_g == 21]\n\nnumeric(0)\n\n\nA quick overview of some operators\n\n\n\nOperator\nMeaning\n\n\n\n\n&\nand\n\n\n|\nor\n\n\n>\ngreater than\n\n\n<\nless than\n\n\n>=\ngreater than or equal to\n\n\n<=\nless than or equal to\n\n\n==\nis equal to\n\n\n\n\nThe function %in% allows you to test if any of the elements of a search vector are found:\n\nanimals <- c(\"mouse\", \"rat\", \"dog\", \"cat\", \"cat\")\n\n# return both rat and cat\nanimals[animals == \"cat\" | animals == \"rat\"]\n\n[1] \"rat\" \"cat\" \"cat\"\n\n# return a logical vector that is TRUE for the elements within animals\n# that are found in the character vector and FALSE for those that are not\nanimals %in% c(\"rat\", \"cat\", \"dog\", \"duck\", \"goat\", \"bird\", \"fish\")\n\n[1] FALSE  TRUE  TRUE  TRUE  TRUE\n\n# use the logical vector created by %in% to return elements from animals\n# that are found in the character vector\nanimals[animals %in% c(\"rat\", \"cat\", \"dog\", \"duck\", \"goat\", \"bird\", \"fish\")]\n\n[1] \"rat\" \"dog\" \"cat\" \"cat\"\n\n\n\n\nChallenge\n\nQ&A: Can you figure out why \"four\" > \"five\" returns TRUE?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nWhen using “>” or “<” on strings, R compares their alphabetical order. Here “four” comes after “five”, and therefore is “greater than” it.\n\n\n\n\n\n\n\n\nMissing data\nMissing data are represented in vectors as NA. When doing operations on numbers, most functions will return NA if the data you are working with include missing values.\nFor example, the mean() below:\n\nheights <- c(2, 4, 4, NA, 6)\nmean(heights)\n\n[1] NA\n\n\n\nThis feature makes it harder to overlook the cases where you are dealing with missing data. You can add the argument na.rm = TRUE to calculate the result as if the missing values were removed (rm stands for ReMoved) first.\n\nheights <- c(2, 4, 4, NA, 6)\nmean(heights, na.rm = TRUE)\n\n[1] 4\n\n\n\nIf your data include missing values, you may want to become familiar with the functions is.na(), na.omit(), and complete.cases(). See below for examples.\n\n## Extract those elements which are not missing values.\nheights[!is.na(heights)]\n\n[1] 2 4 4 6\n\n## Returns the object with incomplete cases removed.\n#The returned object is an atomic vector of type `\"numeric\"` (or #`\"double\"`).\nna.omit(heights)\n\n[1] 2 4 4 6\nattr(,\"na.action\")\n[1] 4\nattr(,\"class\")\n[1] \"omit\"\n\n## Extract those elements which are complete cases.\n#The returned object is an atomic vector of type `\"numeric\"` (or #`\"double\"`).\nheights[complete.cases(heights)]\n\n[1] 2 4 4 6\n\n\nRecall that you can use the typeof() function to find the type of your atomic vector.\n\nChallenge\n\nQ&A: 1. Using this vector of heights in inches, create a new vector, heights_no_na, with the NAs removed.\nheights <- c(63, 69, 60, 65, NA, 68, 61, 70, 61, 59, 64, 69, 63, 63, NA, 72, 65, 64, 70, 63, 65)\n\nUse the function median() to calculate the median of the heights vector.\nUse R to figure out how many people in the set are taller than 67 inches.?\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nheights <- c(63, 69, 60, 65, NA, 68, 61, 70, 61, 59, 64, 69, 63, 63, NA, 72, 65, 64, 70, 63, 65)\n\n# 1.\nheights_no_na <- heights[!is.na(heights)]\n# or\nheights_no_na <- na.omit(heights)\n# or\nheights_no_na <- heights[complete.cases(heights)]\n\n# 2.\nmedian(heights, na.rm = TRUE)\n\n[1] 64\n\n# 3.\nheights_above_67 <- heights_no_na[heights_no_na > 67]\nlength(heights_above_67)\n\n[1] 6\n\n\n\n\n\n\n\n\n\n\nCitations\n\nData Analysis and visualization in R for ecologists. Data Analysis and Visualisation in R for Ecologists: Data Analysis and Visualization in R for Ecologists. https://datacarpentry.org/R-ecology-lesson/index.html"
  },
  {
    "objectID": "2-Intro-to-R/series-introduction.html",
    "href": "2-Intro-to-R/series-introduction.html",
    "title": "Series Introduction",
    "section": "",
    "text": "Goals and Topics\nThis series in intended to provide an (unexhaustive) introduction to the R language, R studio, and data analysis and visualization with R. Concepts introduced here can be built upon and combined with more advanced topics to perform complex analyses and visualizations.\n\n\nCode of Conduct\nWe are dedicated to supporting a safe, productive, and harassment-free environment for everyone. Harassment includes offensive comments and behavior related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion, technology choices, sexual images, deliberate intimidation, stalking, or inappropriate or unwelcome sexual attention. All communication should be appropriate for a professional audience including people of many different backgrounds.\nIn general:\n\nBe kind to others.\nBe open, supportive, and constructive.\nDo not insult or put down others.\nBehave professionally.\nHarassment and sexist, racist, or exclusionary jokes are not appropriate and will not be tolerated.\n\nThank you for helping make this a welcoming, friendly community for all.\n\n\nSchedule\n\n\n\nSession\nLesson\n\n\n\n\nSession 1\nIntroduction to R and RStudio\n\n\nSession 2\nStarting with Data\n\n\nSession 3\nManipulating and Analyzing Data with Tidyverse\n\n\nSession 4\nData Visualization with ggplot2\n\n\n\n\n\nCitations\n\nData Analysis and visualization in R for ecologists. Data Analysis and Visualisation in R for Ecologists: Data Analysis and Visualization in R for Ecologists. https://datacarpentry.org/R-ecology-lesson/index.html"
  },
  {
    "objectID": "2-Intro-to-R/manipulating-analyzing-and-exporting-with-tidyverse.html",
    "href": "2-Intro-to-R/manipulating-analyzing-and-exporting-with-tidyverse.html",
    "title": "Manipulating, analyzing, and exporting data with tidyverse",
    "section": "",
    "text": "Data manipulation using dpylr and tidyr\nWe’ve learned to subset with brackets [], which is useful, but can become cumbersome with complex subsetting operations. Enter the two packages below, both of which are part of the tidyverse.\n\ndplyr – a package that is useful for tabular data manipulation\ntidyr – a package that is useful for donverting between data formats used in plotting / analysis\n\nThe tidyverse package tries to address 3 common issues that arise when doing data analysis in R:\n\nThe results from a base R function sometimes depend on the type of data.\nR expressions are used in a non standard way, which can be confusing for new learners.\nThe existence of hidden arguments having default operations that new learners are not aware of.\n\n\n\n\n\n\n\nNote\n\n\n\nYou should have tidyverse installed already. If you do not, you can type the following into the console.\n\n# install the package\ninstall.packages(\"tidyverse\")\n\n\n# load the package\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\n\nLet’s read in our data using read_csv(), from the tidyverse package, readr.\n\nsurveys <- read_csv(\"~/data-carpentry/data_raw/portal_data_joined.csv\") #read in data\n\nRows: 34786 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): species_id, sex, genus, species, taxa, plot_type\ndbl (7): record_id, month, day, year, plot_id, hindfoot_length, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(surveys) #inspect the data\nview(surveys) #preview the data\n\n\nNext, we’re going to learn some of the most common dplyr functions\n\nselect(): subset columns\nfilter(): subset rows on conditions\nmutate(): create new columns by using information from other columns\ngroup_by() and summarize(): create summary statistics on grouped data\narrange(): sort results\ncount(): count discrete values\n\n\n\n\nSelecting columns and filtering rows\nTo select columns of a dataframe, we use select().\nselect(datafame, columns_to_keep)\n\nselect(surveys, plot_id, species_id, weight)\n\n# A tibble: 34,786 × 3\n   plot_id species_id weight\n     <dbl> <chr>       <dbl>\n 1       2 NL             NA\n 2       2 NL             NA\n 3       2 NL             NA\n 4       2 NL             NA\n 5       2 NL             NA\n 6       2 NL             NA\n 7       2 NL             NA\n 8       2 NL             NA\n 9       2 NL            218\n10       2 NL             NA\n# … with 34,776 more rows\n\n\n\nTo EXCLUDE a specific column, put - in front of the variable.\n\nselect(surveys, -record_id, -species_id)\n\n# A tibble: 34,786 × 11\n   month   day  year plot_id sex   hindfoot…¹ weight genus species taxa  plot_…²\n   <dbl> <dbl> <dbl>   <dbl> <chr>      <dbl>  <dbl> <chr> <chr>   <chr> <chr>  \n 1     7    16  1977       2 M             32     NA Neot… albigu… Rode… Control\n 2     8    19  1977       2 M             31     NA Neot… albigu… Rode… Control\n 3     9    13  1977       2 <NA>          NA     NA Neot… albigu… Rode… Control\n 4    10    16  1977       2 <NA>          NA     NA Neot… albigu… Rode… Control\n 5    11    12  1977       2 <NA>          NA     NA Neot… albigu… Rode… Control\n 6    11    12  1977       2 <NA>          NA     NA Neot… albigu… Rode… Control\n 7    12    10  1977       2 <NA>          NA     NA Neot… albigu… Rode… Control\n 8     1     8  1978       2 <NA>          NA     NA Neot… albigu… Rode… Control\n 9     2    18  1978       2 M             NA    218 Neot… albigu… Rode… Control\n10     3    11  1978       2 <NA>          NA     NA Neot… albigu… Rode… Control\n# … with 34,776 more rows, and abbreviated variable names ¹​hindfoot_length,\n#   ²​plot_type\n\n\n\nTo choose specific rows based on criteria, we use filter()\n\nfilter(surveys, year == 1995)\n\n# A tibble: 1,180 × 13\n   record…¹ month   day  year plot_id speci…² sex   hindf…³ weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n 1    22314     6     7  1995       2 NL      M          34     NA Neot… albigu…\n 2    22728     9    23  1995       2 NL      F          32    165 Neot… albigu…\n 3    22899    10    28  1995       2 NL      F          32    171 Neot… albigu…\n 4    23032    12     2  1995       2 NL      F          33     NA Neot… albigu…\n 5    22003     1    11  1995       2 DM      M          37     41 Dipo… merria…\n 6    22042     2     4  1995       2 DM      F          36     45 Dipo… merria…\n 7    22044     2     4  1995       2 DM      M          37     46 Dipo… merria…\n 8    22105     3     4  1995       2 DM      F          37     49 Dipo… merria…\n 9    22109     3     4  1995       2 DM      M          37     46 Dipo… merria…\n10    22168     4     1  1995       2 DM      M          36     48 Dipo… merria…\n# … with 1,170 more rows, 2 more variables: taxa <chr>, plot_type <chr>, and\n#   abbreviated variable names ¹​record_id, ²​species_id, ³​hindfoot_length\n\n\n\n\n\nConnecting inputs and outputs with pipes\nWe often want to perform multiple manipulations to our datasets. This can be done in a few ways: intermediate steps, nested functions, or pipes.\nWith intermediate steps, a temporary dataframe is created and used as input into the next function.\n\nsurveys2 <- filter(surveys, weight < 5) #filer surveys to create surveys2, the intermediate file\nsurveys_sml <- select(surveys2, species_id, sex, weight) #use surveys2 as input for the next step \n\nWhile sometimes useful (for initial validation, etc.), this can clutter the workspace and make it difficult to follow.\n\nNested functions fit one function inside of another.\n\nsurveys_sml <- select(filter(surveys, weight < 5), species_id, sex, weight) # filtering first, then selecting\n\nThis is handy, but can be difficult to read if too many functions are nested, as R evaluates the expression from the inside out (in this case, filtering, then selecting).\n\nPipes (%>%) are a recent addition to R and let you take the output of one function and send it directly to the next function as input. The package enabling this is magrittr, installed when you install dplyr.\n\nsurveys %>% # send surveys to filter\n  filter(weight < 5) %>% # use surveys as input, filter and send output to select\n  select(species_id, sex, weight) # use filtered data as input, select, and send output to console\n\n# A tibble: 17 × 3\n   species_id sex   weight\n   <chr>      <chr>  <dbl>\n 1 PF         F          4\n 2 PF         F          4\n 3 PF         M          4\n 4 RM         F          4\n 5 RM         M          4\n 6 PF         <NA>       4\n 7 PP         M          4\n 8 RM         M          4\n 9 RM         M          4\n10 RM         M          4\n11 PF         M          4\n12 PF         F          4\n13 RM         M          4\n14 RM         M          4\n15 RM         F          4\n16 RM         M          4\n17 RM         M          4\n\n\nLet’s break it down a bit.\n\nWe use the pipe to send the surveys dataset through filter()\nFilter takes that input, and performs the filtering to keep rows where weight is less than 5, then send the output to select\nSelect takes that input, and keeps only the species_id, sex, and weight columns.\n\nNote that since %>% takesthe object on its left and passes it as the first argument to the function on its right, we don’t need to explicitly include the data frame as an argument to the filter() and select() functions any more.\n\n\n\n\n\n\nTip\n\n\n\nSome may find it helpful to read the pipe like the word “then.” For instance, in the example above, we took the dataframe surveys, then we filtered for rows with weight < 5, then we selected columns species_id, sex, and weight. The dplyr functions by themselves are somewhat simple, but by combining them into linear workflows with the pipe we can accomplish more complex manipulations of dataframes.\n\n\n\nIf we want to create a new object with this smaller version of the data, we can assign it a new name using the assignment operator.\n\nsurveys_sml <- surveys %>%\n  filter(weight < 5) %>%\n  select(species_id, sex, weight)\n\nsurveys_sml\n\nNote that the final dataframe is the leftmost part of this expression.\n\n\nChallenge\n\nQ&A: Using pipes, subset the surveys data to include animals collected before 1995 and retain only the columns year, sex, and weight.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nsurveys %>%\n    filter(year < 1995) %>%\n    select(year, sex, weight)\n\n# A tibble: 21,486 × 3\n    year sex   weight\n   <dbl> <chr>  <dbl>\n 1  1977 M         NA\n 2  1977 M         NA\n 3  1977 <NA>      NA\n 4  1977 <NA>      NA\n 5  1977 <NA>      NA\n 6  1977 <NA>      NA\n 7  1977 <NA>      NA\n 8  1978 <NA>      NA\n 9  1978 M        218\n10  1978 <NA>      NA\n# … with 21,476 more rows\n\n\n\n\n\n\n\n\n\n\nMutate\nFrequently you’ll want to create new columns based on the values in existing columns, for example to do unit conversions, or to find the ratio of values in two columns. For this we’ll use mutate().\nTo create a new column of weight in kg\n\nsurveys %>%\n  mutate(weight_kg = weight / 1000) #assign the column name to the left of the \"=\"\n\n# A tibble: 34,786 × 14\n   record…¹ month   day  year plot_id speci…² sex   hindf…³ weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n 1        1     7    16  1977       2 NL      M          32     NA Neot… albigu…\n 2       72     8    19  1977       2 NL      M          31     NA Neot… albigu…\n 3      224     9    13  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 4      266    10    16  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 5      349    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 6      363    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 7      435    12    10  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 8      506     1     8  1978       2 NL      <NA>       NA     NA Neot… albigu…\n 9      588     2    18  1978       2 NL      M          NA    218 Neot… albigu…\n10      661     3    11  1978       2 NL      <NA>       NA     NA Neot… albigu…\n# … with 34,776 more rows, 3 more variables: taxa <chr>, plot_type <chr>,\n#   weight_kg <dbl>, and abbreviated variable names ¹​record_id, ²​species_id,\n#   ³​hindfoot_length\n\n\n\nYou can also create a second new column based on the first new column within the same call of mutate()\n\nsurveys %>%\n  mutate(weight_kg = weight / 1000,\n         weight_lb = weight_kg * 2.2)\n\n# A tibble: 34,786 × 15\n   record…¹ month   day  year plot_id speci…² sex   hindf…³ weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n 1        1     7    16  1977       2 NL      M          32     NA Neot… albigu…\n 2       72     8    19  1977       2 NL      M          31     NA Neot… albigu…\n 3      224     9    13  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 4      266    10    16  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 5      349    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 6      363    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 7      435    12    10  1977       2 NL      <NA>       NA     NA Neot… albigu…\n 8      506     1     8  1978       2 NL      <NA>       NA     NA Neot… albigu…\n 9      588     2    18  1978       2 NL      M          NA    218 Neot… albigu…\n10      661     3    11  1978       2 NL      <NA>       NA     NA Neot… albigu…\n# … with 34,776 more rows, 4 more variables: taxa <chr>, plot_type <chr>,\n#   weight_kg <dbl>, weight_lb <dbl>, and abbreviated variable names\n#   ¹​record_id, ²​species_id, ³​hindfoot_length\n\n\n\nIf this runs off your screen and you just want to see the first few rows, you can use a pipe to view the head() of the data. (Pipes work with non-dplyr functions, too, as long as the dplyr or magrittr package is loaded).\n\nsurveys %>%\n  mutate(weight_kg = weight / 1000) %>%\n  head()\n\n# A tibble: 6 × 14\n  record_id month   day  year plot_id speci…¹ sex   hindf…² weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n1         1     7    16  1977       2 NL      M          32     NA Neot… albigu…\n2        72     8    19  1977       2 NL      M          31     NA Neot… albigu…\n3       224     9    13  1977       2 NL      <NA>       NA     NA Neot… albigu…\n4       266    10    16  1977       2 NL      <NA>       NA     NA Neot… albigu…\n5       349    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n6       363    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n# … with 3 more variables: taxa <chr>, plot_type <chr>, weight_kg <dbl>, and\n#   abbreviated variable names ¹​species_id, ²​hindfoot_length\n\n\n\nThe first few rows of the output are full of NAs, so if we wanted to remove those we could insert a filter() in the chain, using the !is.na() approach we used in past sessions.\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  mutate(weight_kg = weight / 1000) %>%\n  head()\n\n# A tibble: 6 × 14\n  record_id month   day  year plot_id speci…¹ sex   hindf…² weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n1       588     2    18  1978       2 NL      M          NA    218 Neot… albigu…\n2       845     5     6  1978       2 NL      M          32    204 Neot… albigu…\n3       990     6     9  1978       2 NL      M          NA    200 Neot… albigu…\n4      1164     8     5  1978       2 NL      M          34    199 Neot… albigu…\n5      1261     9     4  1978       2 NL      M          32    197 Neot… albigu…\n6      1453    11     5  1978       2 NL      M          NA    218 Neot… albigu…\n# … with 3 more variables: taxa <chr>, plot_type <chr>, weight_kg <dbl>, and\n#   abbreviated variable names ¹​species_id, ²​hindfoot_length\n\n\n\n\nChallenge\n\nQ&A: Create a new data frame from the surveys data that meets the following criteria:\nContains only the species_id column and a new column called hindfoot_cm containing the hindfoot_length values (currently in mm) converted to centimeters.\nIn this hindfoot_cm column, there are no NAs and all values are less than 3.\nHint: think about how the commands should be ordered to produce this data frame!\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nsurveys_hindfoot_cm <- surveys %>% # save to new object, pass surveys to filter\n    filter(!is.na(hindfoot_length)) %>% #filter out rows with NAs in the hindfoot_length column, pass on\n    mutate(hindfoot_cm = hindfoot_length / 10) %>% # convert hindfoot_length from mm to cm, save as new column hindfoot_cm, pass on\n    filter(hindfoot_cm < 3) %>% # filter out rows, keeping those where hindfoot_cm is less than 3\n    select(species_id, hindfoot_cm) # select the species_id and hindfoot_cm columns\n\n\n\n\n\n\n\n\n\nSplit-apply-combine data analysis and the summarize() function\nMany data analysis tasks can be approached using the split-apply-combine paradigm:\n\nsplit the data into groups\napply some analysis to each group\nand then combine the results.\n\nKey functions of dplyr for this workflow are group_by() and summarize()\n\n\nThe group_by() and summarize() functions\ngroup_by() is often used together with summarize(), which collapses each group into a single-row summary of that group\ngroup_by() takes as arguments the column names that contain the categorical variables for which you want to calculate the summary statistics.\nSo to compute the mean weight by sex\n\nsurveys %>%\n  group_by(sex) %>% # group by values categorical sex column\n  summarize(mean_weight = mean(weight, na.rm = TRUE)) # calculate the mean weight for each category in the sex column, save as a new column mean_weight, then summarize\n\n# A tibble: 3 × 2\n  sex   mean_weight\n  <chr>       <dbl>\n1 F            42.2\n2 M            43.0\n3 <NA>         64.7\n\n\nNotice that we can pass summarize a column name – so it’s almost like saying “give me a tibble with this column that is this values/computational output”.\n\nYou can also group by multiple columns.\n\nsurveys %>%\n  group_by(sex, species_id) %>% # create more granular groups of sex, species_id combined\n  summarize(mean_weight = mean(weight, na.rm = TRUE)) %>%\n  tail()\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 6 × 3\n# Groups:   sex [1]\n  sex   species_id mean_weight\n  <chr> <chr>            <dbl>\n1 <NA>  SU                 NaN\n2 <NA>  UL                 NaN\n3 <NA>  UP                 NaN\n4 <NA>  UR                 NaN\n5 <NA>  US                 NaN\n6 <NA>  ZL                 NaN\n\n\nHere, we used tail() to look at the last six rows of our summary. Before, we had used head() to look at the first six rows.\n\nWe can see that the sex column contains NA values. The resulting mean_weight column does not contain NA but NaN (which refers to “Not a Number”) because mean() was called on a vector of NA values while at the same time setting na.rm = TRUE (we didn’t filter out the rows, we just omitted the NAs from the calculation).\nTo avoid this, we can remove the missing values for weight before we attempt to calculate the summary statistics on weight. Because the missing values are removed first, we can omit na.rm = TRUE when computing the mean.\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight))\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 64 × 3\n# Groups:   sex [3]\n   sex   species_id mean_weight\n   <chr> <chr>            <dbl>\n 1 F     BA                9.16\n 2 F     DM               41.6 \n 3 F     DO               48.5 \n 4 F     DS              118.  \n 5 F     NL              154.  \n 6 F     OL               31.1 \n 7 F     OT               24.8 \n 8 F     OX               21   \n 9 F     PB               30.2 \n10 F     PE               22.8 \n# … with 54 more rows\n\n\n\nOnce the data are grouped, you can also summarize multiple variables at the same time (and not necessarily on the same variable).\nFor instance, we could add a column indicating the minimum weight for each species for each sex.\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight),\n            min_weight = min(weight))\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 64 × 4\n# Groups:   sex [3]\n   sex   species_id mean_weight min_weight\n   <chr> <chr>            <dbl>      <dbl>\n 1 F     BA                9.16          6\n 2 F     DM               41.6          10\n 3 F     DO               48.5          12\n 4 F     DS              118.           45\n 5 F     NL              154.           32\n 6 F     OL               31.1          10\n 7 F     OT               24.8           5\n 8 F     OX               21            20\n 9 F     PB               30.2          12\n10 F     PE               22.8          11\n# … with 54 more rows\n\n\n\nWe can also arrange the data.\nFor example, let’s sort (low to high value) on min_weight.\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight),\n            min_weight = min(weight)) %>%\n  arrange(min_weight)\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 64 × 4\n# Groups:   sex [3]\n   sex   species_id mean_weight min_weight\n   <chr> <chr>            <dbl>      <dbl>\n 1 F     PF                7.97          4\n 2 F     RM               11.1           4\n 3 M     PF                7.89          4\n 4 M     PP               17.2           4\n 5 M     RM               10.1           4\n 6 <NA>  PF                6             4\n 7 F     OT               24.8           5\n 8 F     PP               17.2           5\n 9 F     BA                9.16          6\n10 M     BA                7.36          6\n# … with 54 more rows\n\n\n\nWe can sort in descending order by using the desc() function.\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight),\n            min_weight = min(weight)) %>%\n  arrange(desc(mean_weight))\n\n`summarise()` has grouped output by 'sex'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 64 × 4\n# Groups:   sex [3]\n   sex   species_id mean_weight min_weight\n   <chr> <chr>            <dbl>      <dbl>\n 1 <NA>  NL               168.          83\n 2 M     NL               166.          30\n 3 F     NL               154.          32\n 4 M     SS               130          130\n 5 <NA>  SH               130          130\n 6 M     DS               122.          12\n 7 <NA>  DS               120           78\n 8 F     DS               118.          45\n 9 F     SH                78.8         30\n10 F     SF                69           46\n# … with 54 more rows\n\n\n\n\n\n\nCounting\nWe often want to count the number of observations found for each factor or a combination of factors. For this, we use count().\nLet’s count the number of rows of data for each sex.\n\nsurveys %>%\n    count(sex)\n\n# A tibble: 3 × 2\n  sex       n\n  <chr> <int>\n1 F     15690\n2 M     17348\n3 <NA>   1748\n\n\nThe count() function is shorthand for something we’ve already seen: grouping by a variable, and summarizing it by counting the number of observations in that group. In other words, surveys %>% count() is equivalent to\n\nsurveys %>%\n    group_by(sex) %>%\n    summarize(count = n())\n\n# A tibble: 3 × 2\n  sex   count\n  <chr> <int>\n1 F     15690\n2 M     17348\n3 <NA>   1748\n\n\n\nFor convenience, count() provides the sort argument.\n\nsurveys %>%\n    count(sex, sort = TRUE)\n\n# A tibble: 3 × 2\n  sex       n\n  <chr> <int>\n1 M     17348\n2 F     15690\n3 <NA>   1748\n\n\n\nPrevious example shows the use of count() to count the number of rows/observations for one factor (i.e., sex).\nIf we wanted to count combination of factors, such as sex and species, we would specify the first and the second factor as the arguments of count()\n\nsurveys %>%\n  count(sex, species)\n\n# A tibble: 81 × 3\n   sex   species         n\n   <chr> <chr>       <int>\n 1 F     albigula      675\n 2 F     baileyi      1646\n 3 F     eremicus      579\n 4 F     flavus        757\n 5 F     fulvescens     57\n 6 F     fulviventer    17\n 7 F     hispidus       99\n 8 F     leucogaster   475\n 9 F     leucopus       16\n10 F     maniculatus   382\n# … with 71 more rows\n\n\n\nWith the above code, we can then use arrange() to sort the table according to a number of criteria so that we have a better comparison.\nFor instance, we might want to arrange the table above in\n\n\nan alphabetical order of the levels of the species\n\n\nin descending order of the count\n\n\n\nsurveys %>%\n  count(sex, species) %>%\n  arrange(species, desc(n)) #n is the column name of the counts output from the count command, so it's used here to define the decreasing on value\n\n# A tibble: 81 × 3\n   sex   species             n\n   <chr> <chr>           <int>\n 1 F     albigula          675\n 2 M     albigula          502\n 3 <NA>  albigula           75\n 4 <NA>  audubonii          75\n 5 F     baileyi          1646\n 6 M     baileyi          1216\n 7 <NA>  baileyi            29\n 8 <NA>  bilineata         303\n 9 <NA>  brunneicapillus    50\n10 <NA>  chlorurus          39\n# … with 71 more rows\n\n\nFrom the table above, we may learn that, for instance, there are 75 observations of the albigula species that are not specified for its sex (i.e. NA).\n\n\nChallenge\n\nQ&A: Using survey, how many animals were caught in each plot_type surveyed?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nsurveys %>%\n    count(plot_type)\n\n# A tibble: 5 × 2\n  plot_type                     n\n  <chr>                     <int>\n1 Control                   15611\n2 Long-term Krat Exclosure   5118\n3 Rodent Exclosure           4233\n4 Short-term Krat Exclosure  5906\n5 Spectab exclosure          3918\n\n\n\n\n\n\n\n\n\nChallenge\n\nQ&A: Starting with survey, use group_by() and summarize() to find the mean, min, and max hindfoot length for each species (using species_id). Also add the number of observations (hint: see ?n).\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nsurveys %>%\n    filter(!is.na(hindfoot_length)) %>% #remove NAs\n    group_by(species_id) %>% #group by species\n    summarize( #give me this output/table with the following\n      mean_val = mean(hindfoot_length), #mean_cal column, computing the mean on column x\n      min_val = min(hindfoot_length), #min_cal column, computing the min on column x\n      max_val = max(hindfoot_length), #max_cal column, computing the max on column x\n      n = n()) #gives number of current groups size\n\n# A tibble: 25 × 5\n   species_id mean_val min_val max_val     n\n   <chr>         <dbl>   <dbl>   <dbl> <int>\n 1 AH             33        31      35     2\n 2 BA             13         6      16    45\n 3 DM             36.0      16      50  9972\n 4 DO             35.6      26      64  2887\n 5 DS             49.9      39      58  2132\n 6 NL             32.3      21      70  1074\n 7 OL             20.5      12      39   920\n 8 OT             20.3      13      50  2139\n 9 OX             19.1      13      21     8\n10 PB             26.1       2      47  2864\n# … with 15 more rows\n\n\n\n\n\n\n\n\n\nChallenge\n\nQ&A: Starting with survey, what was the heaviest animal measured in each year? Return the columns year, genus, species_id, and weight.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nsurveys %>%\n    filter(!is.na(weight)) %>% #filter out NA\n    group_by(year) %>% #group by species\n    filter(weight == max(weight)) %>% #select the max weight rows for each year, save to weight column\n    select(year, genus, species, weight) %>% #select specific columns of interest\n    arrange(year) #arrange in ascending order by year\n\n# A tibble: 27 × 4\n# Groups:   year [26]\n    year genus     species     weight\n   <dbl> <chr>     <chr>        <dbl>\n 1  1977 Dipodomys spectabilis    149\n 2  1978 Neotoma   albigula       232\n 3  1978 Neotoma   albigula       232\n 4  1979 Neotoma   albigula       274\n 5  1980 Neotoma   albigula       243\n 6  1981 Neotoma   albigula       264\n 7  1982 Neotoma   albigula       252\n 8  1983 Neotoma   albigula       256\n 9  1984 Neotoma   albigula       259\n10  1985 Neotoma   albigula       225\n# … with 17 more rows\n\n\n\n\n\n\n\n\n\n\nTidy data\nStructuring data is an important aspect of working with data, making it easier to analyze and visualize. The best way to work with our data is in “tidy” format.\n\n\n\nFigure 1: Rules to form tidy data. [2]\n\n\n\n\n\nReshaping with pivot_longer() and pivot_wider()\nWhen working with tidy data there are two common dataformats for tabular datasets, wide and long.\nIn the example below we collected information on 3 variables – site, year, and cases.\nWide\n\nData relating to the same measured thing in different columns.\nIn this case, we have values related to our “metric” spread across multiple columns (a column each for a year).\n\nLong\n\nA column for each of the types of things we measured or recorded in our data.\nIn other words, each variable has its own column (a column for site, year, and case).\n\n\n\n\nFigure 2: Examples of wide (left) and long (right) data. [2]\n\n\n\nDepending on what you want do to, you might want to reshape from one form to the other. Luckily, there are functions for the pivot_wider() and pivot_longer().\n\n\n\nFigure 3: Pivoting from wide to long formatted data. [1]\n\n\n\n\nPivoting from long to wide format\npivot_wider() takes three principal arguments\n\nthe data\nthe names_from column variable whose values will become new column names.\nthe values_from column variable whose values will fill the new column variables.\n\nFurther arguments include values_fill which, if set, fills in missing values with the value provided.\n\nWhat if we wanted to plot comparisons between the weight of genera in different plots?\nTo do this, we’ll need to 1. Create our dataset of interest – will generate a long formatted dataframe 2. Convert from long to wide format, filling missing values with 0.\nCreate our dataset – use filter(), group_by() and summarize() to filter our observations and variables of interest, and create a new variable for the mean_weight.\n\nsurveys_gw <- surveys %>% \n  filter(!is.na(weight)) %>% #remove rows with empty weight\n  group_by(plot_id, genus) %>% #group by plot_id and genus\n  summarize(mean_weight = mean(weight)) #give me the mean weight for each group\n\n`summarise()` has grouped output by 'plot_id'. You can override using the\n`.groups` argument.\n\nhead(surveys_gw)\n\n# A tibble: 6 × 3\n# Groups:   plot_id [1]\n  plot_id genus       mean_weight\n    <dbl> <chr>             <dbl>\n1       1 Baiomys            7   \n2       1 Chaetodipus       22.2 \n3       1 Dipodomys         60.2 \n4       1 Neotoma          156.  \n5       1 Onychomys         27.7 \n6       1 Perognathus        9.62\n\n\nThis yields surveys_gw, a long-formatted dataframe where the observations for each plot are distributed across multiple rows, 196 observations of 3 variables.\n\nLet’s use pivot_wider() as follows\n\ndata – the surveys_gw dataframe\nnames_from – genus (column variable whose values will become new column names)\nvalues_from – mean_weight (column variable whose values will fill the new column variables)\n\nUsing pivot_wider() with the names from genus and with values from mean_weight this becomes 24 observations of 11 variables, one row for each plot.\n\nsurveys_wide <- surveys_gw %>%\n  pivot_wider(names_from = genus, values_from = mean_weight, values_fill = 0)\n\nhead(surveys_wide)\n\n# A tibble: 6 × 11\n# Groups:   plot_id [6]\n  plot_id Baiomys Chaetodipus Dipodomys Neotoma Onycho…¹ Perog…² Perom…³ Reith…⁴\n    <dbl>   <dbl>       <dbl>     <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl>\n1       1    7           22.2      60.2    156.     27.7    9.62    22.2    11.4\n2       2    6           25.1      55.7    169.     26.9    6.95    22.3    10.7\n3       3    8.61        24.6      52.0    158.     26.0    7.51    21.4    10.5\n4       4    0           23.0      57.5    164.     28.1    7.82    22.6    10.3\n5       5    7.75        18.0      51.1    190.     27.0    8.66    21.2    11.2\n6       6    0           24.9      58.6    180.     25.9    7.81    21.8    10.7\n# … with 2 more variables: Sigmodon <dbl>, Spermophilus <dbl>, and abbreviated\n#   variable names ¹​Onychomys, ²​Perognathus, ³​Peromyscus, ⁴​Reithrodontomys\n\n\n\n\n\nFigure 4: From long to wide format. [1]\n\n\n\n\n\nPivoting from wide to long format\nWhat if we wanted were given a wide format, but wanted to treat the genus names (which are column names) as values of a genus variable instead (we wanted a genus column)?\npivot_longer() takes four principal arguments:\n\nthe data\nthe names_to column variable we wish to create from column names.\nthe values_to column variable we wish to create and fill with values.\ncols are the name of the columns we use to make this pivot (or to drop).\n\n\nLet’s use pivot_longer() as follows\n\ndata – the surveys_wide dataframe\nnames_to – genus (column variable to create from column names)\nvalues_to – mean_weight (column variable we wish to create and fill with values)\ncols – -plot_id (names of columns we use to make the pivot or drop)\n\n\nsurveys_long <- surveys_wide %>%\n  pivot_longer(names_to = \"genus\", values_to = \"mean_weight\", cols = -plot_id) #were including all cols here except plot_id\n\nhead(surveys_long)\n\n# A tibble: 6 × 3\n# Groups:   plot_id [1]\n  plot_id genus       mean_weight\n    <dbl> <chr>             <dbl>\n1       1 Baiomys            7   \n2       1 Chaetodipus       22.2 \n3       1 Dipodomys         60.2 \n4       1 Neotoma          156.  \n5       1 Onychomys         27.7 \n6       1 Perognathus        9.62\n\n\n\n\n\nFigure 5: From wide to long format. [1]\n\n\n\n\n\nChallenge\n\nQ&A: Reshape the surveys dataframe with year as columns, plot_id as rows, and the number of genera per plot as the values.\nYou will need to summarize before reshaping, and use the function n_distinct() to get the number of unique genera within a particular chunk of data. It’s a powerful function! See ?n_distinct for more.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nYear is spread across columns, so we need a wide format.\n\neach row will have a distinct plot_id\nthe value will be the genera per plot, for each year – which we need to calculate\n\n\nsurveys_wide_genera <- surveys %>%\n  group_by(plot_id, year) %>% #group by plot_id and year\n  summarize(n_genera = n_distinct(genus)) %>% #count number of distinct genera, create column\n  pivot_wider(names_from = year, values_from = n_genera) #pivot to wide format, where names from year, and values from number of unique genera\n\n`summarise()` has grouped output by 'plot_id'. You can override using the\n`.groups` argument.\n\nhead(surveys_wide_genera)\n\n# A tibble: 6 × 27\n# Groups:   plot_id [6]\n  plot_id `1977` `1978` `1979` `1980` `1981` `1982` `1983` `1984` `1985` `1986`\n    <dbl>  <int>  <int>  <int>  <int>  <int>  <int>  <int>  <int>  <int>  <int>\n1       1      2      3      4      7      5      6      7      6      4      3\n2       2      6      6      6      8      5      9      9      9      6      4\n3       3      5      6      4      6      6      8     10     11      7      6\n4       4      4      4      3      4      5      4      6      3      4      3\n5       5      4      3      2      5      4      6      7      7      3      1\n6       6      3      4      3      4      5      9      9      7      5      6\n# … with 16 more variables: `1987` <int>, `1988` <int>, `1989` <int>,\n#   `1990` <int>, `1991` <int>, `1992` <int>, `1993` <int>, `1994` <int>,\n#   `1995` <int>, `1996` <int>, `1997` <int>, `1998` <int>, `1999` <int>,\n#   `2000` <int>, `2001` <int>, `2002` <int>\n\n\n\n\n\n\n\n\n\nChallenge\n\nQ&A: Now take that data frame and pivot_longer() it, so each row is a unique plot_id by year combination.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nThe current column values are plot_id, and a large range of years.\n\nnames_to will be year – creating a year column\nvalues_to will be n_genera – creating a n_genera column, putting the individual cell values in this\nthe columns to reshape/pivot on (cols) will be the year columns, so -plot_id to select all but plot_id\n\n\nsurveys_long <- surveys_wide_genera %>%\n  pivot_longer(names_to = \"year\", values_to = \"n_genera\", cols = -plot_id)\n\nhead(surveys_long)\n\n# A tibble: 6 × 3\n# Groups:   plot_id [1]\n  plot_id year  n_genera\n    <dbl> <chr>    <int>\n1       1 1977         2\n2       1 1978         3\n3       1 1979         4\n4       1 1980         7\n5       1 1981         5\n6       1 1982         6\n\n\n\n\n\n\n\n\n\n\nExporting data\nAfter analyzing, processing data, we often want to export the results to a file.\nLet’s create a cleaned up version of our dataset that does not include missing data (weight, hindfoot_length, and sex) – in preparation for next session.\n\nsurveys_complete <- surveys %>%\n  filter(!is.na(weight),           # remove missing weight\n         !is.na(hindfoot_length),  # remove missing hindfoot_length\n         !is.na(sex))                # remove missing sex\n\n\nWe’re going to be plotting species abundances over time – so let’s remove observations for rare species (that have been observed less than 50 times).\n\n## Extract the common species_id\nspecies_counts <- surveys_complete %>%\n    count(species_id) %>%\n    filter(n >= 50)\n\n## Use the common species id as a key for filtering (keeping)\nsurveys_complete <- surveys_complete %>%\n  filter(species_id %in% species_counts$species_id) \n\n\nTo make sure that everyone has the same dataset, check the dimensions by typing dim(surveys_complete), with values matching the output shown.\n\ndim(surveys_complete)\n\n[1] 30463    13\n\n\n\nNow, let’s write to a file with write_csv().\n\nwrite_csv(surveys_complete, file = \"~/data-carpentry/data/surveys_complete.csv\")\n\n\n\n\nCitations\n\nData Analysis and visualization in R for ecologists. Data Analysis and Visualisation in R for Ecologists: Data Analysis and Visualization in R for Ecologists. https://datacarpentry.org/R-ecology-lesson/index.html\nWickham, H. Tidy Data. Journal of Statistical Software 59 (10). https://10.18637/jss.v059.i10"
  },
  {
    "objectID": "2-Intro-to-R/installation.html",
    "href": "2-Intro-to-R/installation.html",
    "title": "Installation and Resources",
    "section": "",
    "text": "For this series, we will need to make sure\n\nR and RStudio are installed or updated\nR packages are installed\nLesson data are downloaded\n\n\nInstalling Software\n\nInstall the following software\n\n\nR\nR Studio (Posit)\n\n\n\nUpdating Software\n\nWhen you open RStudio, check that your R version is 4.0.0 or later by looking at the bottom left the console.\n\n\n\n\n\n\nFigure 1: R version in RStudio console.\n\n\n\nIf your version is older than 4.0.0, that is 3.x.x or lower, then follow the instructions above to download and install the latest version of R for your operating system.\nTo update RStudio, after opening, click Help, then select Check for Updates. Follow the instructions on the screen to install the new version if one is available.\n\n\n\nInstalling R packages\n\nOpen RStudio and in the console type\n\n\ninstall.packages(c(\"tidyverse\", \"hexbin\",\"patchwork\"))\n\n\n\nData\nWe will download these data during the sessions, but you can also download them now to make sure you have them.\nhttps://doi.org/10.6084/m9.figshare.1314459"
  },
  {
    "objectID": "2-Intro-to-R/starting-with-data.html",
    "href": "2-Intro-to-R/starting-with-data.html",
    "title": "Starting with data",
    "section": "",
    "text": "Loading survey data\nToday we’ll work with animal species data, stored as comma-separated values (CSV) in a .csv file in the following format:\n\n\n\nColumn\nDescription\n\n\n\n\nrecord_id\nUnique id for the observation\n\n\nmonth\nmonth of observation\n\n\nday\nday of observation\n\n\nyear\nyear of observation\n\n\nplot_id\nID of a particular experimental plot of land\n\n\nspecies_id\n2-letter code\n\n\nsex\nsex of animal (“M”, “F”)\n\n\nhindfoot_length\nlength of the hindfoot in mm\n\n\nweight\nweight of the animal in grams\n\n\ngenus\ngenus of animal\n\n\nspecies\nspecies of animal\n\n\ntaxon\ne.g. Rodent, Reptile, Bird, Rabbit\n\n\nplot_type\ntype of plot\n\n\n\n\nDownloading the data\nWe first need to download the data using the download.file() function.\nChecking the documentation with ?download.file(), we see that the function takes two important options\n\nurl – a character string naming the URL of a resource to be downloaded\ndestfile – a character string with the file path where the file will be saved\n\nWe’re going to save this to our data_raw directory that we created last session.\n\ndownload.file(url = \"https://ndownloader.figshare.com/files/2292169\",\n              destfile = \"~/data-carpentry/data_raw/portal_data_joined.csv\")\n\n\nReading the data into R\nNow we can load the data from the computer into an object in R. We’ll do this with the read_csv() function from the tidyverse package.\n\n\n\n\n\n\nBase R function and packages\n\n\n\nUntil now we’ve used base R functions that are built into R. Packages provide acccess to additional functions beyond those that come with R.\nHere we use functions from the package tidyverse.\nFirst, let’s install tidyverse (if you haven’t already).\n\ninstall.packages(\"tidyverse\")\n\n\n\n\nLet’s load the tidyverse package.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\nNow we can read the data from the file into a dataframe object, surveys.\n\nsurveys <- read_csv(\"~/data-carpentry/data_raw/portal_data_joined.csv\")\n\nRows: 34786 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): species_id, sex, genus, species, taxa, plot_type\ndbl (7): record_id, month, day, year, plot_id, hindfoot_length, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNotice the data types are set for each column of surveys, even though we didn’t set them. This is because read_csv will look at the first 1000 rows of each column and guess the data type.\n\n\n\n\n\n\nNote\n\n\n\nread_csv() assumes that fields are delineated by commas. However, this may not always be the case. There are several other functions to read in data in a tabular format. The most generalizable function would be read_delim() which allows for the specification of column / field delimiters.\n\n\n\nLet’s view the contents of the first 6 rows of survey by using the head() function.\n\nhead(surveys)\n\n# A tibble: 6 × 13\n  record_id month   day  year plot_id speci…¹ sex   hindf…² weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n1         1     7    16  1977       2 NL      M          32     NA Neot… albigu…\n2        72     8    19  1977       2 NL      M          31     NA Neot… albigu…\n3       224     9    13  1977       2 NL      <NA>       NA     NA Neot… albigu…\n4       266    10    16  1977       2 NL      <NA>       NA     NA Neot… albigu…\n5       349    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n6       363    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n# … with 2 more variables: taxa <chr>, plot_type <chr>, and abbreviated\n#   variable names ¹​species_id, ²​hindfoot_length\n\n\nWe can change the number of rows we view by passing the option n to the function.\n\nhead(surveys, n=7)\n\n# A tibble: 7 × 13\n  record_id month   day  year plot_id speci…¹ sex   hindf…² weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n1         1     7    16  1977       2 NL      M          32     NA Neot… albigu…\n2        72     8    19  1977       2 NL      M          31     NA Neot… albigu…\n3       224     9    13  1977       2 NL      <NA>       NA     NA Neot… albigu…\n4       266    10    16  1977       2 NL      <NA>       NA     NA Neot… albigu…\n5       349    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n6       363    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n7       435    12    10  1977       2 NL      <NA>       NA     NA Neot… albigu…\n# … with 2 more variables: taxa <chr>, plot_type <chr>, and abbreviated\n#   variable names ¹​species_id, ²​hindfoot_length\n\n\n\nNow let’s look at the last 7 lines using tail(), which works in a similar fashion.\n\ntail(surveys, n=7)\n\n# A tibble: 7 × 13\n  record_id month   day  year plot_id speci…¹ sex   hindf…² weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n1     26557     7    29  1997       7 PL      F          20     22 Pero… leucop…\n2     26787     9    27  1997       7 PL      F          21     16 Pero… leucop…\n3     26966    10    25  1997       7 PL      M          20     16 Pero… leucop…\n4     27185    11    22  1997       7 PL      F          21     22 Pero… leucop…\n5     27792     5     2  1998       7 PL      F          20      8 Pero… leucop…\n6     28806    11    21  1998       7 PX      <NA>       NA     NA Chae… sp.    \n7     30986     7     1  2000       7 PX      <NA>       NA     NA Chae… sp.    \n# … with 2 more variables: taxa <chr>, plot_type <chr>, and abbreviated\n#   variable names ¹​species_id, ²​hindfoot_length\n\n\n\nFor a more complete view of surveys we can use the view() command.\n\nview(surveys)\n\n\n\n\n\n\n\nNote\n\n\n\nThere are two functions for viewing which are case-sensitive. Using view() with a lowercase ‘v’ is part of tidyverse, whereas using View() with an uppercase ‘V’ is loaded through base R in the utils package.\n\n\n\n\n\nWhat are dataframes?\nDataframes are a VERY common data structure for tabular data.\n\ncolumns are vectors of the same length\neach column must contain a single data type (characters, integers, etc.)\n\nAn example of this is shown in the figure below.\n\n\n\nFigure 1: A dataframe comprising a numeric, a character, and a logical vector. [1]\n\n\n\nWe can also see this when inspecting the structure of the dataframe using the function str().\n\nstr(surveys)\n\nspc_tbl_ [34,786 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ record_id      : num [1:34786] 1 72 224 266 349 363 435 506 588 661 ...\n $ month          : num [1:34786] 7 8 9 10 11 11 12 1 2 3 ...\n $ day            : num [1:34786] 16 19 13 16 12 12 10 8 18 11 ...\n $ year           : num [1:34786] 1977 1977 1977 1977 1977 ...\n $ plot_id        : num [1:34786] 2 2 2 2 2 2 2 2 2 2 ...\n $ species_id     : chr [1:34786] \"NL\" \"NL\" \"NL\" \"NL\" ...\n $ sex            : chr [1:34786] \"M\" \"M\" NA NA ...\n $ hindfoot_length: num [1:34786] 32 31 NA NA NA NA NA NA NA NA ...\n $ weight         : num [1:34786] NA NA NA NA NA NA NA NA 218 NA ...\n $ genus          : chr [1:34786] \"Neotoma\" \"Neotoma\" \"Neotoma\" \"Neotoma\" ...\n $ species        : chr [1:34786] \"albigula\" \"albigula\" \"albigula\" \"albigula\" ...\n $ taxa           : chr [1:34786] \"Rodent\" \"Rodent\" \"Rodent\" \"Rodent\" ...\n $ plot_type      : chr [1:34786] \"Control\" \"Control\" \"Control\" \"Control\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   record_id = col_double(),\n  ..   month = col_double(),\n  ..   day = col_double(),\n  ..   year = col_double(),\n  ..   plot_id = col_double(),\n  ..   species_id = col_character(),\n  ..   sex = col_character(),\n  ..   hindfoot_length = col_double(),\n  ..   weight = col_double(),\n  ..   genus = col_character(),\n  ..   species = col_character(),\n  ..   taxa = col_character(),\n  ..   plot_type = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen we loaded the data into R, it got stored as an object of class tibble, which is a special kind of data frame (the difference is not important for our purposes, but you can learn more about tibbles here).\n\n\n\n\n\nInspecting dataframes\nThere are several functions that can be useful in checking content, structure, and other characteristics fo the dataframe. Here is a incomplete list.\n\n\n\n\n\n\n\n\nCharacteristic\nFunction\nDescritption\n\n\n\n\nSize\ndim(suverys)\nreturns a vector with the number of rows in the first element, and the number of columns as the second element (the dimensions of the object)\n\n\n\nnrow(surveys)\nreturns the number of rows\n\n\n\nncol(surveys)\nreturns the number of columns\n\n\nContent\nhead(surveys)\nshows the first n rows, 6 by default\n\n\n\ntail(surveys)\nshows the last n rows, 6 by default\n\n\nNames\nnames(surveys)\nreturns the column names (synonym of colnames() for data.frame objects)\n\n\n\nrownames(surveys)\nreturns the row names\n\n\nSummary\nstr(surveys)\nstructure of the object and information about the class, length and content of each column\n\n\n\nsummary(surveys)\nsummary statistics for each column\n\n\n\nTake some time to try these out by copy/pasting these into your console.\n\n\nChallenge\n\nQ&A: Based on the output of str(surveys), can you answer the following questions?\n\nWhat is the class of the object surveys?\nHow many rows and how many columns are in this object?\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nstr(surveys)\n\nspc_tbl_ [34,786 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ record_id      : num [1:34786] 1 72 224 266 349 363 435 506 588 661 ...\n $ month          : num [1:34786] 7 8 9 10 11 11 12 1 2 3 ...\n $ day            : num [1:34786] 16 19 13 16 12 12 10 8 18 11 ...\n $ year           : num [1:34786] 1977 1977 1977 1977 1977 ...\n $ plot_id        : num [1:34786] 2 2 2 2 2 2 2 2 2 2 ...\n $ species_id     : chr [1:34786] \"NL\" \"NL\" \"NL\" \"NL\" ...\n $ sex            : chr [1:34786] \"M\" \"M\" NA NA ...\n $ hindfoot_length: num [1:34786] 32 31 NA NA NA NA NA NA NA NA ...\n $ weight         : num [1:34786] NA NA NA NA NA NA NA NA 218 NA ...\n $ genus          : chr [1:34786] \"Neotoma\" \"Neotoma\" \"Neotoma\" \"Neotoma\" ...\n $ species        : chr [1:34786] \"albigula\" \"albigula\" \"albigula\" \"albigula\" ...\n $ taxa           : chr [1:34786] \"Rodent\" \"Rodent\" \"Rodent\" \"Rodent\" ...\n $ plot_type      : chr [1:34786] \"Control\" \"Control\" \"Control\" \"Control\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   record_id = col_double(),\n  ..   month = col_double(),\n  ..   day = col_double(),\n  ..   year = col_double(),\n  ..   plot_id = col_double(),\n  ..   species_id = col_character(),\n  ..   sex = col_character(),\n  ..   hindfoot_length = col_double(),\n  ..   weight = col_double(),\n  ..   genus = col_character(),\n  ..   species = col_character(),\n  ..   taxa = col_character(),\n  ..   plot_type = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nClass: dataframe Rows: 34786 Columns: 13\n\n\n\n\n\n\n\n\nIndexing and subsetting dataframes\nDataframes are 2 dimensional data types. The location of each item in a dataframe can be described by the indices of these two dimensions (row and column indices) – where row number comes first, followed by column number.\n\n\n\n\n\n\nImportant\n\n\n\nDifferent ways of specifying these coordinates lead to results with different classes.\n\n\n\n\nExtracting specific values\ndataframe[row_index, column_index]\nFirst row, first column\n\nsurveys[1,1]\n\n# A tibble: 1 × 1\n  record_id\n      <dbl>\n1         1\n\n\n\nFirst row, sixth column\n\nsurveys[1,6]\n\n# A tibble: 1 × 1\n  species_id\n  <chr>     \n1 NL        \n\n\n\n\n\nExtracting entire rows or columns\ndatarame[row_index, ] – specific row, all columns\ndatarame[, col_index] – all rows, specific column\nFirst row, all columns\n\nsurveys[1, ]\n\n# A tibble: 1 × 13\n  record_id month   day  year plot_id speci…¹ sex   hindf…² weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n1         1     7    16  1977       2 NL      M          32     NA Neot… albigu…\n# … with 2 more variables: taxa <chr>, plot_type <chr>, and abbreviated\n#   variable names ¹​species_id, ²​hindfoot_length\n\n\n\nAll rows, first column\n\nsurveys[, 1]\n\n# A tibble: 34,786 × 1\n   record_id\n       <dbl>\n 1         1\n 2        72\n 3       224\n 4       266\n 5       349\n 6       363\n 7       435\n 8       506\n 9       588\n10       661\n# … with 34,776 more rows\n\n\n\nAnother way to get a specific column, all rows. Note, there is no comma used.\n\nsurveys[1]\n\n# A tibble: 34,786 × 1\n   record_id\n       <dbl>\n 1         1\n 2        72\n 3       224\n 4       266\n 5       349\n 6       363\n 7       435\n 8       506\n 9       588\n10       661\n# … with 34,776 more rows\n\n\n\n\n\nMultiple rows or columns – use vectors to specify indices\ndata_frame[c(row_index, row_index, rowindex), c(column_index, column_index)]\nThe first three rows of the fifth and sixth columns\n\nsurveys[c(1, 2, 3), c(5, 6)]\n\n# A tibble: 3 × 2\n  plot_id species_id\n    <dbl> <chr>     \n1       2 NL        \n2       2 NL        \n3       2 NL        \n\n\n\nAnother way, use the : to select a range of indces\n\nsurveys[1:3, 5:6]\n\n# A tibble: 3 × 2\n  plot_id species_id\n    <dbl> <chr>     \n1       2 NL        \n2       2 NL        \n3       2 NL        \n\n\n\n\n\nReturning vectors – use [[]]\nAs we’ve seen thus far when working with tibbles, subsetting with [] returns a dataframe.\nIf we want vectors returned we can use [[]]\nThe first column as a vector\n\nsurveys[[1]]\n\n\nThe first value in our dataframe.\n\nsurveys[[1,1]]\n\n[1] 1\n\n\n\n\n\nExcluding indices – use -\nAll rows, all but the first column\n\nsurveys[, -1]\n\n# A tibble: 34,786 × 12\n   month   day  year plot_id species_id sex   hindf…¹ weight genus species taxa \n   <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>   <dbl>  <dbl> <chr> <chr>   <chr>\n 1     7    16  1977       2 NL         M          32     NA Neot… albigu… Rode…\n 2     8    19  1977       2 NL         M          31     NA Neot… albigu… Rode…\n 3     9    13  1977       2 NL         <NA>       NA     NA Neot… albigu… Rode…\n 4    10    16  1977       2 NL         <NA>       NA     NA Neot… albigu… Rode…\n 5    11    12  1977       2 NL         <NA>       NA     NA Neot… albigu… Rode…\n 6    11    12  1977       2 NL         <NA>       NA     NA Neot… albigu… Rode…\n 7    12    10  1977       2 NL         <NA>       NA     NA Neot… albigu… Rode…\n 8     1     8  1978       2 NL         <NA>       NA     NA Neot… albigu… Rode…\n 9     2    18  1978       2 NL         M          NA    218 Neot… albigu… Rode…\n10     3    11  1978       2 NL         <NA>       NA     NA Neot… albigu… Rode…\n# … with 34,776 more rows, 1 more variable: plot_type <chr>, and abbreviated\n#   variable name ¹​hindfoot_length\n\n\n\nThe equivalent of head (first 6 rows, all columns – or all but the 7th through max row number).\n\nsurveys[-(7:nrow(surveys)), ]\n\n# A tibble: 6 × 13\n  record_id month   day  year plot_id speci…¹ sex   hindf…² weight genus species\n      <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>   <chr>   <dbl>  <dbl> <chr> <chr>  \n1         1     7    16  1977       2 NL      M          32     NA Neot… albigu…\n2        72     8    19  1977       2 NL      M          31     NA Neot… albigu…\n3       224     9    13  1977       2 NL      <NA>       NA     NA Neot… albigu…\n4       266    10    16  1977       2 NL      <NA>       NA     NA Neot… albigu…\n5       349    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n6       363    11    12  1977       2 NL      <NA>       NA     NA Neot… albigu…\n# … with 2 more variables: taxa <chr>, plot_type <chr>, and abbreviated\n#   variable names ¹​species_id, ²​hindfoot_length\n\n\n\n\n\nCalling column names directly\nDataframes can also be subet by calling the names of the columns directly.\nUsing column names to return dataframes.\n\nsurveys[\"species_id\"]\nsurveys[, \"species_id\"]\n\n\nUsing column names to return vectors.\n\nsurveys[[\"species_id\"]]\n\n\nWe can also use the $ operator to call column names instead of [[]].\n\nsurveys$species_id\n\n\n\n\nChallenge\n\nQ&A: Write code that does the following:\n\nCreate a dataframe (surveys_200) containing only the data in row 200 of the surveys dataset.\nNotice how nrow() gave you the number of rows in a dataframe?\n\n\nUse that number to pull out just the last row of the surveys dataset.\nCompare that with the output of using tail() to make sure it meets expectations.\nPull out the last row using nrow() instead of the row number.\nCreate a new dataframe (surveys_last) from that last row.\n\n\nUse nrow() to extract the row that is in the middle of the dataframe. Store the content of this row in an object named surveys_middle.\nCombine nrow() with the - notation above to reproduce the behavior of head(surveys), keeping just the first through sixth of the surveys dataset.\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n## 1.\nsurveys_200 <- surveys[200, ]\n## 2.\n# Saving `n_rows` to improve readability and reduce duplication\nn_rows <- nrow(surveys)\nsurveys_last <- surveys[n_rows, ]\n## 3.\nsurveys_middle <- surveys[n_rows / 2, ]\n## 4.\nsurveys_head <- surveys[-(7:n_rows), ]\n\n\n\n\n\n\n\n\n\nFactors\nUsing str(surveys) showed us that several of the columns consist of categorical data, meaning there are a limited number of values (categories). This is contrast to some of the other columns that have a large range of possible number values.\nFactor – a special class for working with categorical data\n\nOnce created, factors can only contain a pre-defined set of values, know as levels\nStored as integers associated with labels\nCan be ordered or unordered\nAre treated as integer vectors\n\nWe can convert columns to the factor data type using the factor() function.\n\nsurveys$sex <- factor(surveys$sex)\n\nLet’s check the conversion with summary().\n\nsummary(surveys$sex)\n\n    F     M  NA's \n15690 17348  1748 \n\n\n\nBy default, R always sorts levels in alphabetical order. For instance, if you have a factor with 2 levels, like below.\n\nsex <- factor(c(\"male\", \"female\", \"female\", \"male\"))\n\nR will assign\n\n1 to the level \"female\"\n2 to the level \"male\"\n\nYou can see this by using the function levels().\n\nlevels(sex)\n\n[1] \"female\" \"male\"  \n\n\nYou can find the number of level using nlevels()\n\nnlevels(sex)\n\n[1] 2\n\n\n\nSometimes, the order of the factors does not matter, other times you might want to specify the order because it is meaningful (e.g., “low”, “medium”, “high”), it improves your visualization, or it is required by a particular type of analysis.\nHere, one way to reorder our levels in the sex vector would be:\n\nsex # current order\n\n[1] male   female female male  \nLevels: female male\n\nsex <- factor(sex, levels = c(\"male\", \"female\"))\nsex # after re-ordering\n\n[1] male   female female male  \nLevels: male female\n\n\n\nWhile factors are represented by integers (1, 2, 3), they are more informative because they are self-describing: \"female\", \"male\" is more descriptive than 1, 2.\nFactors have this information built in, which is helpful when there are many levels (like the species names in our example dataset).\n\n\nChallenge\n\nQ&A: What code would you write to do the following?\n\nChange the columns taxa and genus in the surveys dataframe into a factor.\nUsing the functions you learned before, can you find out…\n\n\nHow many rabbits were observed?\nHow many different genera are in the genus column?\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nnum_char <- c(1, 2, 3, \"a\")\nsurveys$taxa <- factor(surveys$taxa)\nsurveys$genus <- factor(surveys$genus)\nsummary(surveys)\n\n   record_id         month             day            year         plot_id     \n Min.   :    1   Min.   : 1.000   Min.   : 1.0   Min.   :1977   Min.   : 1.00  \n 1st Qu.: 8964   1st Qu.: 4.000   1st Qu.: 9.0   1st Qu.:1984   1st Qu.: 5.00  \n Median :17762   Median : 6.000   Median :16.0   Median :1990   Median :11.00  \n Mean   :17804   Mean   : 6.474   Mean   :16.1   Mean   :1990   Mean   :11.34  \n 3rd Qu.:26655   3rd Qu.:10.000   3rd Qu.:23.0   3rd Qu.:1997   3rd Qu.:17.00  \n Max.   :35548   Max.   :12.000   Max.   :31.0   Max.   :2002   Max.   :24.00  \n                                                                               \n  species_id          sex        hindfoot_length     weight      \n Length:34786       F   :15690   Min.   : 2.00   Min.   :  4.00  \n Class :character   M   :17348   1st Qu.:21.00   1st Qu.: 20.00  \n Mode  :character   NA's: 1748   Median :32.00   Median : 37.00  \n                                 Mean   :29.29   Mean   : 42.67  \n                                 3rd Qu.:36.00   3rd Qu.: 48.00  \n                                 Max.   :70.00   Max.   :280.00  \n                                 NA's   :3348    NA's   :2503    \n             genus         species               taxa        plot_type        \n Dipodomys      :16167   Length:34786       Bird   :  450   Length:34786      \n Chaetodipus    : 6029   Class :character   Rabbit :   75   Class :character  \n Onychomys      : 3267   Mode  :character   Reptile:   14   Mode  :character  \n Reithrodontomys: 2694                      Rodent :34247                     \n Peromyscus     : 2234                                                        \n Perognathus    : 1629                                                        \n (Other)        : 2766                                                        \n\nnlevels(surveys$genus)\n\n[1] 26\n\n## * how many genera: There are 26 unique genera in the `genus` column.\n## * how many rabbts: There are 75 rabbits in the `taxa` column.\n\n\n\n\n\n\n\n\n\nConverting Factors\nTo convert a factor to a character vector, you can use the as.character() function.\n\nas.character(sex)\n\n[1] \"male\"   \"female\" \"female\" \"male\"  \n\n\n\nWhile factors are an efficient way to represent data (because each unique character value is represented once), there may be times when you want to convert factors to numeric vectors, for example, performing simple mathematical operations.\nFor this, you cannot use as.numeric(), since this will just return the index values of the factor, not the levels. To avoid this, we conver factors –> characters –> numbers.\nAnother method is to use the levels() function.\nHere’s an example.\n\nyear_fct <- factor(c(1990, 1983, 1977, 1998, 1990))\nas.numeric(year_fct)               # Wrong! And there is no warning...\n\n[1] 3 2 1 4 3\n\nas.numeric(as.character(year_fct)) # Works...\n\n[1] 1990 1983 1977 1998 1990\n\nas.numeric(levels(year_fct))[year_fct]    # The recommended way.\n\n[1] 1990 1983 1977 1998 1990\n\n\n\nLet’s break down the levels() approach.\nThere are 3 steps that occur:\n\nWe obtain all the factor levels using levels(year_fct)\nWe convert these levels to numeric values using as.numeric(levels(year_fct))\nWe access these numeric values using the underlying integers of the vector year_fct inside the square brackets.\n\n\n\n\nRenaming factors\nWhen your data are stored as factors, you can use the plot() function to get a quick glance at the number of observations represented by each factor level.\nLet’s look at the number of males and females captured over the course of the experiment.\n\n## bar plot of the number of females and males captured during the experiment\nplot(surveys$sex)\n\n\n\n\n\nIn the plot above, we’re missing the individuals for which sex information was not recorded. To show them in the plot we can convert the missing values into a factor level with addNA(). We’ll need to also give the factor a label.\nNote: We are going to make a copy of the sex column so that we are not modigying the working copy of the dataframe.\n\nsex <- surveys$sex #create a copy\nlevels(sex) #look at the levels\n\n[1] \"F\" \"M\"\n\nsex <- addNA(sex) #addNA as a level\nlevels(sex) #check the levels again\n\n[1] \"F\" \"M\" NA \n\nhead(sex) #look at the data\n\n[1] M    M    <NA> <NA> <NA> <NA>\nLevels: F M <NA>\n\nlevels(sex)[3] <- \"undetermined\" #assign the value \"undetermined\" to the third, by index, level\nlevels(sex) #check the levels again\n\n[1] \"F\"            \"M\"            \"undetermined\"\n\nhead(sex) #look at the dataset again\n\n[1] M            M            undetermined undetermined undetermined\n[6] undetermined\nLevels: F M undetermined\n\n\nNow we can plot the data again, using plot(sex).\n\nplot(sex)\n\n\n\n\n\nChallenge\n\nQ&A: Write the code to do the following:\n\nRename “F” and “M” to “female” and “male” respectively.\nNow that we have renamed the factor level to “undetermined”, can you create the bar plot such that “undetermined” is first (before “female”)?\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nlevels(sex)[1:2] <- c(\"female\", \"male\")\nsex <- factor(sex, levels = c(\"undetermined\", \"female\", \"male\"))\nplot(sex)\n\n\n\n\n\n\n\n\n\nQ&A: We have seen how dataframes are created when using read_csv(), but they can also be created by hand with the data.frame() function. There are a few mistakes in this hand-crafted data.frame. Can you spot and fix them? Don’t hesitate to experiment!\n\nanimal_data <- data.frame(\n          animal = c(dog, cat, sea cucumber, sea urchin),\n          feel = c(\"furry\", \"squishy\", \"spiny\"),\n          weight = c(45, 8 1.1, 0.8)\n          )\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nThe animals listed have no quotes around them.\nThere are not the same number of items in each vector.\nThere is a missing comma in the weight vector.\n\n\n\n\n\n\nQ&A: Can you predict the class for each of the columns in the following example?\n\nAre they what you expected? Why? Why not?\nWhat would you need to change to ensure that each column had the accurate data type?\n\n\ncountry_climate <- data.frame(\n       country = c(\"Canada\", \"Panama\", \"South Africa\", \"Australia\"),\n       climate = c(\"cold\", \"hot\", \"temperate\", \"hot/temperate\"),\n       temperature = c(10, 30, 18, \"15\"),\n       northern_hemisphere = c(TRUE, TRUE, FALSE, \"FALSE\"),\n       has_kangaroo = c(FALSE, FALSE, FALSE, 1)\n       )\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\ncountry –> character\n\nclimate –> character\n\ntemperature –> character\n\nnorthern_hemisphere –> character\n\nhas_kangaroo –> numeric\n\n\n\n\n\n\nThe automatic conversion of data type is sometimes a blessing, sometimes an annoyance.\nBe aware that it exists, learn the rules, and double check that data you import in R are of the correct type within your data frame. If not, use it to your advantage to detect mistakes that might have been introduced during data entry (for instance, a letter in a column that should only contain numbers).\n\n\n\nFormatting dates\nA common challenge for R users is converting date and time information into an analysis-suitable format.\nOne way to start date information is to store each component (day, month, year) in a separate column. We can see thatsurveys takes this approach.\n\nstr(surveys)\n\nspc_tbl_ [34,786 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ record_id      : num [1:34786] 1 72 224 266 349 363 435 506 588 661 ...\n $ month          : num [1:34786] 7 8 9 10 11 11 12 1 2 3 ...\n $ day            : num [1:34786] 16 19 13 16 12 12 10 8 18 11 ...\n $ year           : num [1:34786] 1977 1977 1977 1977 1977 ...\n $ plot_id        : num [1:34786] 2 2 2 2 2 2 2 2 2 2 ...\n $ species_id     : chr [1:34786] \"NL\" \"NL\" \"NL\" \"NL\" ...\n $ sex            : Factor w/ 2 levels \"F\",\"M\": 2 2 NA NA NA NA NA NA 2 NA ...\n $ hindfoot_length: num [1:34786] 32 31 NA NA NA NA NA NA NA NA ...\n $ weight         : num [1:34786] NA NA NA NA NA NA NA NA 218 NA ...\n $ genus          : Factor w/ 26 levels \"Ammodramus\",\"Ammospermophilus\",..: 13 13 13 13 13 13 13 13 13 13 ...\n $ species        : chr [1:34786] \"albigula\" \"albigula\" \"albigula\" \"albigula\" ...\n $ taxa           : Factor w/ 4 levels \"Bird\",\"Rabbit\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ plot_type      : chr [1:34786] \"Control\" \"Control\" \"Control\" \"Control\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   record_id = col_double(),\n  ..   month = col_double(),\n  ..   day = col_double(),\n  ..   year = col_double(),\n  ..   plot_id = col_double(),\n  ..   species_id = col_character(),\n  ..   sex = col_character(),\n  ..   hindfoot_length = col_double(),\n  ..   weight = col_double(),\n  ..   genus = col_character(),\n  ..   species = col_character(),\n  ..   taxa = col_character(),\n  ..   plot_type = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nWe’ll use the ymd() function from the lubridate packages (installed with tidyverse).\nLoad the package.\n\nlibrary(lubridate)\n\nLoading required package: timechange\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\n\nLet’s create a data object and inspect the structure.\n\nmy_date <- ymd(\"2015-01-01\")\nstr(my_date)\n\n Date[1:1], format: \"2015-01-01\"\n\n\n\nNow let’s paste the year, month, and day separately - we get the same result.\n\n# sep indicates the character to use to separate each component\nmy_date <- ymd(paste(\"2015\", \"1\", \"1\", sep = \"-\")) \nstr(my_date)\n\n Date[1:1], format: \"2015-01-01\"\n\n\n\nNow we apply this function to the surveys dataset. Create a character vector from the year, month, and day columns of surveys using paste()\n\nhead(paste(surveys$year, surveys$month, surveys$day, sep = \"-\"))\n\n[1] \"1977-7-16\"  \"1977-8-19\"  \"1977-9-13\"  \"1977-10-16\" \"1977-11-12\"\n[6] \"1977-11-12\"\n\n\nThis character vector can be used as the argument for ymd():\n\nhead(ymd(paste(surveys$year, surveys$month, surveys$day, sep = \"-\")))\n\nWarning: 129 failed to parse.\n\n\n[1] \"1977-07-16\" \"1977-08-19\" \"1977-09-13\" \"1977-10-16\" \"1977-11-12\"\n[6] \"1977-11-12\"\n\n\nThere is a warning telling us that some dates could not be parsed (understood) by the ymd() function. For these dates, the function has returned NA, which means they are treated as missing values – we will deal with this problem later.\n\nFirst we add the resulting Date vector to the surveys dataframe as a new column called date.\n\nsurveys$date <- ymd(paste(surveys$year, surveys$month, surveys$day, sep = \"-\"))\n\nWarning: 129 failed to parse.\n\nstr(surveys) # notice the new column, with 'date' as the class\n\nspc_tbl_ [34,786 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ record_id      : num [1:34786] 1 72 224 266 349 363 435 506 588 661 ...\n $ month          : num [1:34786] 7 8 9 10 11 11 12 1 2 3 ...\n $ day            : num [1:34786] 16 19 13 16 12 12 10 8 18 11 ...\n $ year           : num [1:34786] 1977 1977 1977 1977 1977 ...\n $ plot_id        : num [1:34786] 2 2 2 2 2 2 2 2 2 2 ...\n $ species_id     : chr [1:34786] \"NL\" \"NL\" \"NL\" \"NL\" ...\n $ sex            : Factor w/ 2 levels \"F\",\"M\": 2 2 NA NA NA NA NA NA 2 NA ...\n $ hindfoot_length: num [1:34786] 32 31 NA NA NA NA NA NA NA NA ...\n $ weight         : num [1:34786] NA NA NA NA NA NA NA NA 218 NA ...\n $ genus          : Factor w/ 26 levels \"Ammodramus\",\"Ammospermophilus\",..: 13 13 13 13 13 13 13 13 13 13 ...\n $ species        : chr [1:34786] \"albigula\" \"albigula\" \"albigula\" \"albigula\" ...\n $ taxa           : Factor w/ 4 levels \"Bird\",\"Rabbit\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ plot_type      : chr [1:34786] \"Control\" \"Control\" \"Control\" \"Control\" ...\n $ date           : Date[1:34786], format: \"1977-07-16\" \"1977-08-19\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   record_id = col_double(),\n  ..   month = col_double(),\n  ..   day = col_double(),\n  ..   year = col_double(),\n  ..   plot_id = col_double(),\n  ..   species_id = col_character(),\n  ..   sex = col_character(),\n  ..   hindfoot_length = col_double(),\n  ..   weight = col_double(),\n  ..   genus = col_character(),\n  ..   species = col_character(),\n  ..   taxa = col_character(),\n  ..   plot_type = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\nLet’s make sure everything worked correctly. One way to inspect the new column is to use summary().\n\nsummary(surveys$date)\n\n        Min.      1st Qu.       Median         Mean      3rd Qu.         Max. \n\"1977-07-16\" \"1984-03-12\" \"1990-07-22\" \"1990-12-15\" \"1997-07-29\" \"2002-12-31\" \n        NA's \n       \"129\" \n\n\n\nSo why were some dates not parsed?\nWe can use the functions we saw previously to deal with missing data to identify the rows in our data frame that are failing.\nIf we combine them with what we learned about subsetting data frames earlier, we can extract the columns “year,”month”, “day” from the records that have NA in our new column date. We will also use head() so we don’t clutter the output.\n\nmissing_dates <- surveys[is.na(surveys$date), c(\"year\", \"month\", \"day\")]\n\nhead(missing_dates)\n\n# A tibble: 6 × 3\n   year month   day\n  <dbl> <dbl> <dbl>\n1  2000     9    31\n2  2000     4    31\n3  2000     4    31\n4  2000     4    31\n5  2000     4    31\n6  2000     9    31\n\n\nLooking at the dates that were not converted, it seems that they don’t actualy exist – September and April only have 30 days, not 31 days as it is specified in our dataset.\nThere are several ways you could deal with situation:\n\nIf you have access to the raw data (e.g., field sheets) or supporting information (e.g., field trip reports/logs), check them and ensure the electronic database matches the information in the original data source.\nIf you are able to contact the person responsible for collecting the data, you could refer to them and ask for clarification.\nYou could also check the rest of the dataset for clues about the correct value for the erroneous dates.\nIf your project has guidelines on how to correct this sort of errors, refer to them and apply any recommendations.\nIf it is not possible to ascertain the correct value for these observations, you may want to leave them as missing data.\n\nRegardless of the option you choose, it is important that you document the error and the corrections (if any) that you apply to your data.\n\n\n\nCitations\n\nData Analysis and visualization in R for ecologists. Data Analysis and Visualisation in R for Ecologists: Data Analysis and Visualization in R for Ecologists. https://datacarpentry.org/R-ecology-lesson/index.html"
  }
]