[
  {
    "objectID": "domain-specific-series.html",
    "href": "domain-specific-series.html",
    "title": "Domain-Specific Series",
    "section": "",
    "text": "Hands-on tutorials created for members of the Neurodegeneration Challenge Network (NDCN), and taught at NDCN Office Hours. Past series materials will be added here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Unix Shell\n\n\nLearn the basics of the Unix Shell\n\n\n\nChristopher Sifuentes\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Self-Guided Learning",
    "section": "",
    "text": "MIT License\nCopyright (c) 2023 Christopher Sifuentes\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A resource for self-guided learning",
    "section": "",
    "text": "Computational biology approaches have become common in biological research, and an essential tool for many labs. Still, the complexity and ever changing nature of computational approaches can make learning to design, analyze, and interpret these data a daunting task.\nWhile not exhaustive, we’ve pulled together a set of self-guided learning resources for readers beginning their computational biology journey. Included are learning-oriented tutorials, task-oriented how-to guides, and information-oriented references. The formats vary from YouTube courses and MOOCs to website-based books and cheat-sheets.\n\nResource Descriptions\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Resources\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Installs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain-Specific Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "1-Reproducibility/series-introduction.html",
    "href": "1-Reproducibility/series-introduction.html",
    "title": "Series Introduction",
    "section": "",
    "text": "Goals and Topics\nWhile intended for those with prior coding experience (either in R, python, or bash), this first several sections of this training can be very helpful for beginners. The concepts introduced and covered here are meant to help one move toward computational reproducibility.\n\n\nCode of Conduct\nWe are dedicated to supporting a safe, productive, and harassment-free environment for everyone. Harassment includes offensive comments and behavior related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion, technology choices, sexual images, deliberate intimidation, stalking, or inappropriate or unwelcome sexual attention. All communication should be appropriate for a professional audience including people of many different backgrounds.\nIn general:\n\nBe kind to others.\nBe open, supportive, and constructive.\nDo not insult or put down others.\nBehave professionally.\nHarassment and sexist, racist, or exclusionary jokes are not appropriate and will not be tolerated.\n\nThank you for helping make this a welcoming, friendly community for all.\n\n\nSchedule\n\n\n\n\n\n\n\nSession\nLesson\n\n\n\n\nSession 1\nIntroduction to Bioinformatic Reproducibility\n\n\nSession 2\nGood Enough Practices\n\n\nSession 3\nPlan for Reproducibility\n\n\nSession 4\nTutorial: A Practical Introduction to Reproducible Computational Workflows\n\n\nSession 5\nSnakemake\n\n\n\n\n\nCitations\n\nTen simple rules for writing and sharing computational analyses in Jupyter Notebooks. Rule A, Birmingham A, Zuniga C, Altintas I, Huang SC, Knight R, Moshiri N, Nguyen MH, Rosenthal SB, Pérez F, Rose PW. PLoS Comput Biol. 2019 Jul 25;15(7):e1007007. doi: https://doi.org/10.1371/journal.pcbi.1007007\nReproducibility, Research Objects, and Reality. Gable C. 2016 Nov 24. https://www.slideshare.net/carolegoble/reproducibility-research-objects-and-reality-leiden-2016\nBaker M. 1,500 scientists lift the lid on reproducibility. Nature. 2016 May 26;533(7604):452-4. doi: 10.1038/533452a. PMID: 27225100.\nYang-Min Kim, Jean-Baptiste Poline, Guillaume Dumas, Experimenting with reproducibility: a case study of robustness in bioinformatics, GigaScience, Volume 7, Issue 7, July 2018, giy077, https://doi.org/10.1093/gigascience/giy077"
  },
  {
    "objectID": "software-installs.html",
    "href": "software-installs.html",
    "title": "Software Installs",
    "section": "",
    "text": "Information on how to install some commonly used software and tools.\n\n\nBash\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://carpentries.github.io/workshop-template/#shell-windows\n\n\nmacOS\nhttps://carpentries.github.io/workshop-template/#shell-macos\n\n\nLinux\nhttps://carpentries.github.io/workshop-template/#shell-linux\n\n\n\n\n\n\nConda (miniconda)\nInstall miniconda, not Anaconda.\nThis will also install Python, so if you wish to use a specific version of Python, you with want to specify that specific version when installing.\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://docs.conda.io/projects/conda/en/latest/user-guide/install/windows.html\n\n\nmacOS\nhttps://docs.conda.io/projects/conda/en/latest/user-guide/install/macos.html\n\n\nLinux\nhttps://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html\n\n\n\n\n\n\nGit\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://carpentries.github.io/workshop-template/#git-windows\n\n\nmacOS\nhttps://carpentries.github.io/workshop-template/#git-macos\n\n\nLinux\nhttps://carpentries.github.io/workshop-template/#git-linux\n\n\n\n\n\n\nJupyter\nI recommend installing through conda. See the conda install above first if you need to install conda, then follow the instructions below.\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://jupyter.org/install\n\n\nmacOS\nhttps://jupyter.org/install\n\n\nLinux\nhttps://jupyter.org/install\n\n\n\n\n\n\nPosit (formerly Rstudio)\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://posit.co/downloads/\n\n\nmacOS\nhttps://posit.co/downloads/\n\n\nLinux\nhttps://posit.co/downloads/\n\n\n\n\n\n\nPython\nPython will also come installed with conda (depending on the installer that is used, I think). Choose the Python version that most of your packages will need. If you are unsure, I would start with Python 3.\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://realpython.com/installing-python/#how-to-install-from-the-full-installer\n\n\nmacOS\nhttps://realpython.com/installing-python/#step-1-download-the-official-installer\n\n\nLinux\nhttps://realpython.com/installing-python/#how-to-install-on-ubuntu-and-linux-mint\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://rstudio-education.github.io/hopr/starting.html#how-to-download-and-install-r\n\n\nmacOS\nhttps://rstudio-education.github.io/hopr/starting.html#how-to-download-and-install-r\n\n\nLinux\nhttps://rstudio-education.github.io/hopr/starting.html#how-to-download-and-install-r\n\n\n\n\n\n\nSnakemake\nI recommend installing this through conda. See the conda install above to first install conda, then follow the instructions below. I also recommend installing through mamba if possible.\n\n\n\n\n\n\n\nOS\nInstructions\n\n\n\n\nWindows\nhttps://snakemake.readthedocs.io/en/stable/getting_started/installation.html\n\n\nmacOS\nhttps://snakemake.readthedocs.io/en/stable/getting_started/installation.html\n\n\nLinux\nhttps://snakemake.readthedocs.io/en/stable/getting_started/installation.html"
  },
  {
    "objectID": "learning-resources.html",
    "href": "learning-resources.html",
    "title": "Learning Resources",
    "section": "",
    "text": "While not exhaustive, we’ve pulled together a set of self-guided learning resources for readers beginning their computational biology journey. Included are learning-oriented tutorials, task-oriented how-to guides, and information-oriented references. The formats vary from YouTube courses and MOOCs to website-based books and cheat-sheets.\nSearch, sort, and filter the resources below :)\n\n\n\n\n\n\n\n\n\nExpand/Collapse All"
  },
  {
    "objectID": "0-The-Unix-Shell/bash-scripting.html",
    "href": "0-The-Unix-Shell/bash-scripting.html",
    "title": "Bash Scripting",
    "section": "",
    "text": "Scripts\nScripts are files that hold a series of commands that are to be interpreted and executed.\n\nStarting a Script\nBecause scripts can be written in any language, the computer needs to know which interpreter to use to interpret the commands. The hashbang, #! (or shebang), followed by the location, tells the computer where to find the interpreter for the specific language that is being used.\nThese are usually found in specific locations, but can vary slightly. The options below are worth trying.\n\n#!/bin/bash\n#!/usr/bin/env bash\n\n\n\n\n\n\n\nTip\n\n\n\nThe hashbang/shebang must the be first line of the script – otherwise the # will be seen as a commenting line.\n\n\n\n\nUsing a Script\nUsing any script is similar to running the commands we’ve learned.\n\nbash script.sh\n./script.sh – need to have permissions to run it this way\n\n\n\n\n\n\n\nTip\n\n\n\nWhile we won’t cover this today, we can create scripts that specify flags and take inputs as parameters/arguments to be used as variable values in the script.\n\n\n\n\n\n\nPutting this into practice – Processig RNA-seq Data\nLet’s put this into action with an example RNA-seq workflow.\n\nRNA-sequencing\nRNA-sequencing (RNA-seq) is a method that allows for the sequencing of complex mixtures of RNA. Different analyses can be peformed with these data, including assessing\n\ngene expression (changes over time, or differences between groups/treatments)\ntranscript splicing\npost-transcriptional modifications\ngene fusions\nand more\n\n\n\n\n\n\n\nTip\n\n\n\nFor a good introduction to RNA-seq analysis, visit RNA-seqlopedia\n\n\n\n\n\nGeneral Analysis Steps\nWhile there are variations to RNA-seq analyses, generally, the following steps are performed\n\nDemultiplex reads\nInitial read quality check\nFilter and trim sequencing reads\nNormalize sequencing reads\nDe novo assembly of transcripts (if a reference genome is not available)\nMap (align) sequencing reads to reference genome or transcriptome\nAnnotate transcripts assembled or to which reads have been mapped\nCount mapped reads to estimate transcript abundance\nPerform statistical analysis to identify differential expression (or differential splicing) among samples or treatments\nPerform multivariate statistical analysis/visualization to assess transcriptome-wide differences among samples\n\n\n\n\nTools/Software\nThere are MANY tools that can be used at each of these steps, each with their own pros and cons. For this lesson, we will use the following, stopping after quantification:\n\n\n\n\n\n\n\nStep\nTool\n\n\n\n\nDemultiplex\nPerformed already (usually using bcl2fastq)\n\n\nInitial read QC\nFastQC\n\n\nFilter and trim reads\nTrimGalore!\n\n\nAlignment\nSTAR\n\n\nAbundance quantification\nSubread\n\n\n\n\n\n\nSample Datasets\nOur dataset here sequencing data files (fastq files) from 6 samples, that are divided into 2 groups (1 and 2).\n\n\n\n\n\n\n\nSample Name\nGroup\n\n\n\n\nsample_01\n1\n\n\nsample_02\n1\n\n\nsample_03\n1\n\n\nsample_04\n2\n\n\nsample_05\n2\n\n\nsample_06\n2\n\n\n\n\n\n\n\nAnalysis\nWe’ll implement this analysis using bash scripts.\nI will walk through the initial step here, then we will work more hands-on in each step, building the scripts together.\n\nInitial Read QC\nOne of the first steps will be to check the quality of the sequencing reads with FastQC. The options we will be using are shown below.\n\n\n\nOption\nDescription\n\n\n\n\n-o\noutput directory\n\n\n-noextract\ndo not unzip (extract) the final output\n\n\n-f\nthe format of the input file is fastq\n\n\n-t\nuse this number of threads for processing\n\n\n[input files]\ninput file(s)\n\n\n\nThe following is how this command could be run at the command line for sample_01.\nNote: The \\ at the end of the line allows me to break up the command onto different lines, but the command in still interpreted as a single command.\n\nfastqc \\\n -o ~/Desktop/rnaseq \\\n --noextract \\\n -f fastq \\\n -t 4 \\\n sample_01_1.fastq\n\nHow would we put this into a bash script?\n\nput the command in a plain text file, saved with a suffix .sh\nspecify the interpreter with the hashbang\nadd in the code\ngeneralize if possibe, with variables, etc.\n\nTry to create a bash script for this first step.\n\n\n\n\n\n\nClick here for an answer\n\n\n\n\n\nIn the example below we\n\nset the interpreter\nset variables for the fastq directory location and the output qc directory location\nmake the output directory location\nperform the anlaysis in a loop\n\nIf we named this fastqc.sh we could run this by typing bash fastqc.sh\n\n#!/usr/bin/env bash\n\n#set variables\nFQ_DIR='/Users/csifuentes/Desktop/shell-lesson-data/simulated_reads/fastq/'\nQC_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/QC/'\n\n#make output directory\nmkdir -p ${QC_DIR}\n\n#fastqc on each file\nfor fq in ${FQ_DIR}*.fastq;\ndo fastqc \\\n    -o ${QC_DIR} \\\n    --noextract \\\n    -f fastq \\\n    -t 4 \\\n    ${fq};\ndone\n\n\n\n\n\n\n\nRead QC Trimming\nA common next step, should the FastQC analysis show a high-level of adapter content, or poor quality sequencing, would be to perform adapter trimming and read filtering or quality trimming. We’re going to pretend we need to trim and will be using TrimGalore!.\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\n-q\nquality value threshold for base calls, cuts bases with score below value\n\n\n--length\nremove reads that become shorter than this length\n\n\n--basename\nthe basename of the sample/file\n\n\n-o\noutput directory\n\n\n--paired\nif paired-end reads, the paired read files\n\n\n\nHow would we put this into a bash script?\n\n\n\n\n\n\nClick here for an answer\n\n\n\n\n\nIn the example below we\n\nset the interpreter\nset variables\nmake the output directory location\nperform the anlaysis in a loop, while grabbing the basename of each file using the basename command.\n\nIf we named this trim.sh we could run this by typing bash trim.sh\n\n#!/usr/bin/env bash\n\n#set variables\nFQ_DIR='/Users/csifuentes/Desktop/shell-lesson-data/simulated_reads/fastq/'\nQC_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/QC/'\nTRIM_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/TRIM/'\n\n#make output directory\nmkdir -p ${TRIM_DIR}\n\n#trimgalore! on each file\nfor fq in ${FQ_DIR}*_1.fastq;\ndo BASE=$(basename ${fq} '_1.fastq');\n    trim_galore \\\n    -q 30 \\\n    --length 20 \\\n    --basename ${BASE} \\\n    -o ${TRIM_DIR} \\\n    --paired ${FQ_DIR}${BASE}_1.fastq ${FQ_DIR}${BASE}_2.fastq;\ndone\n\n\n\n\n\n\n\nAligning Reads\nThe next step is to align filtered reads. We will use STAR for this, with the following options.\nNote: The trimming tool will output a specific file format of the sample name, followed by _val_, then the read, then end in .fq. This must be taken into account for the next step.\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\n-genomeDir\npath to the genome directory, with the index files\n\n\n--readFilesIn\nthe path to the reads files\n\n\n--sjdbGTFfile\nthe path to the GTF file associated with the genome file\n\n\n-outFileNamePrefix\noutput prefix, with directory in front\n\n\n--runThreadN\nnumber of threads to use, if possible\n\n\n--outSAMattributes\nalignment attributes to report\n\n\n--outSAMtype\nthe format to output (SAM/BAM, etc) and whether to sort\n\n\n\nHow would we put this into a bash script?\n\n\n\n\n\n\nClick here for an answer\n\n\n\n\n\nIn the example below we\n\nset the interpreter\nset variables\nmake the output directory location\nperform the anlaysis in a loop, while grabbing the basename of each file using the basename command.\n\nIf we named this star.sh we could run this by typing bash star.sh\n\n#!/usr/bin/env bash\n\n#set variables\nFQ_DIR='/Users/csifuentes/Desktop/shell-lesson-data/simulated_reads/fastq/'\nQC_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/QC/'\nTRIM_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/TRIM/'\nGENOME_FASTA='/Users/csifuentes/Desktop/shell-lesson-data/index/'\nGENOME_GTF='/Users/csifuentes/Desktop/shell-lesson-data/index/Homo_sapiens.GRCh38.103.gtf'\nALN_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/ALIGN/'\n\n#make output directory\nmkdir -p ${ALN_DIR}\n\n#star alignment on each file\nfor i in ${TRIM_DIR}*_val_1.fq;\ndo BASE=$(basename ${i} '_val_1.fq');\n    echo ${BASE};\n    STAR \\\n    --genomeDir ${GENOME_FASTA} \\\n    --readFilesIn ${TRIM_DIR}${BASE}_val_1.fq ${TRIM_DIR}${BASE}_val_2.fq \\\n    --sjdbGTFfile ${GENOME_GTF} \\\n    --outFileNamePrefix ${ALN_DIR}${BASE} \\\n    --runThreadN 4 \\\n    --outSAMattributes Standard \\\n    --outSAMtype BAM SortedByCoordinate \\\n    --outFilterMismatchNmax 999 \\\n    --alignSJoverhangMin 8 \\\n    --alignSJDBoverhangMin 1 \\\n    --outFilterMismatchNoverReadLmax 0.04 \\\n    --alignIntronMin 20 \\\n    --alignIntronMax 1000000 \\\n    --alignMatesGapMax 1000000 \\\n    --sjdbScore 1;\ndone\n\n\n\n\n\n\n\nQuantifying Expression\nIn the next step, we use featureCounts from Subread to quantify the expression of genes.\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\n-O\nassign reads to their overlapping features\n\n\n-p\ncount as fragments, with paired end reads\n\n\n-B\ncount only reads where both pairs align\n\n\n-C\ndo not count if reads map to different chromosomes or different strands\n\n\n-T\nthreads to use\n\n\n-s\nstrand-specific read counting\n\n\n-a\nannotation file (GTF, etc.)\n\n\n-o\noutput file name\n\n\n[file]\nthe format to output (SAM/BAM, etc) and whether to sort\n\n\n\nHow would we put this into a bash script?\n\n\n\n\n\n\nClick here for an answer\n\n\n\n\n\nIn the example below we\n\nset the interpreter\nset variables\nmake the output directory location\nperform the anlaysis in a loop\nclean the files, remove # and cutting specific columns\n\nIf we named this count.sh we could run this by typing bash count.sh\n\n#!/usr/bin/env bash\n\n#set variables\nGENOME_GTF='/Users/csifuentes/Desktop/shell-lesson-data/index/Homo_sapiens.GRCh38.103.gtf'\nALN_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/ALIGN/'\nSTRAND='0'\nCOUNTS_DIR='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/COUNTS/'\nANNOT_TMP='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/COUNTS/counts.tmp'\nANNOT_OUT='/Users/csifuentes/Desktop/shell-lesson-data/rnaseq/COUNTS/counts.txt'\n\n#make output directory\nmkdir -p ${COUNTS_DIR}\n\n#featureCounts on all files together\nfeatureCounts \\\n    -O \\\n    -p \\\n    -B \\\n    -C \\\n    -T 4 \\\n    -s ${STRAND} \\\n    -a ${GENOME_GTF} \\\n    -o ${ANNOT_TMP} \\\n    ${ALN_DIR}*Aligned.sortedByCoord.out.bam\n\n#clean file\nsed '/^#/d' ${ANNOT_TMP} | cut -f 1,7- > ${ANNOT_OUT}\n\n\n\n\n\nThese scripts used here, can be improved upon, by combining them, generalizing more, adding in extra sanity checks, and taking input from the commandline, etc.\nI encourage you to explore more, build and use these skills."
  },
  {
    "objectID": "0-The-Unix-Shell/series-introduction.html",
    "href": "0-The-Unix-Shell/series-introduction.html",
    "title": "Series Introduction",
    "section": "",
    "text": "Goals and Topics\nThis training series is intended for absolute beginners and focused on the basic usage of the Bash Shell. Concepts introduced in these sessions are foundational to the application of computational approaches and will enable more powerful and reproducible research.\nBy the end of the series, you should be able to\n\ndescribe the Unix file system structure\nnavigate the Unix file system from the command line\ncreate, view, and manipulate files and directories\nchain bash shell commands together\ncreate a basic Bash shell script to automate tasks\n\n\n\nCode of Conduct\nWe are dedicated to supporting a safe, productive, and harassment-free environment for everyone. Harassment includes offensive comments and behavior related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion, technology choices, sexual images, deliberate intimidation, stalking, or inappropriate or unwelcome sexual attention. All communication should be appropriate for a professional audience including people of many different backgrounds.\nIn general:\n\nBe kind to others.\nBe open, supportive, and constructive.\nDo not insult or put down others.\nBehave professionally.\nHarassment and sexist, racist, or exclusionary jokes are not appropriate and will not be tolerated.\n\nThank you for helping make this a welcoming, friendly community for all.\n\n\nSchedule\n\n\n\nSession\nLesson\nSlide Version\n\n\n\n\nSession 1\n\nIntroducing the Shell\nThe File System\n\n\nIntroducing the Shell\nThe File System\n\n\n\nSession 2\n\nPatterns, Filters, and Pipes\n\n\nPatterns, Filters, and Pipes\n\n\n\nSession 3\n\nVariables and Loops\n\n\nVariables and Loops\n\n\n\nSession 4\n\nBash Scripting\n\n\nBash Scripting\n\n\n\n\n\n\nCitations\n\nGabriel A. Devenyi (Ed.), Gerard Capes (Ed.), Colin Morris (Ed.), Will Pitchers (Ed.), Greg Wilson, Gerard Capes, Gabriel A. Devenyi, Christina Koch, Raniere Silva, Ashwin Srinath, … Vikram Chhatre. (2019, July). swcarpentry/shell-novice: Software Carpentry: the UNIX shell, June 2019 (Version v2019.06.1). Zenodo. http://doi.org/10.5281/zenodo.3266823\nComputational Foundations Workshop. (n.d.). Retrieved December 7, 2022, from https://umich-brcf-bioinf.github.io/2022-10-31-umich-computational-foundations/html/index.html\nLearn regular expressions - lesson 1: An introduction, and the abcs. RegexOne. (n.d.). Retrieved April 3, 2023, from https://regexone.com/\nNagarajan, V. (2018). Command line fundamentals: Learn to use the unix command-line tools and Bash Shell scripting. Packt Publishing.\nChadwick, R. (n.d.). Bash scripting tutorial - 1. what is a bash script? A collection of Technology Tutorials. Retrieved April 4, 2023, from <https://ryanstutorials.net/bash-scripting-tutorial/bash-script.php >\n\nNote: This series has been adapted from the Carpentries course entitles “The Unix Shell” [1] as well as the “Computational Foundations Workshop” [2], created by the University of Michigan Bioinformatics Core Workshop Team and inspired by or drawn on information from Regexone practice questions [3] as well as the very complete “Command line fundamentals” book by Vivek Nagaragan [4], and the “Bash scripting tutorial” developed by Ryan Chadwick [5]."
  },
  {
    "objectID": "0-The-Unix-Shell/slides/series-introduction-slides.html",
    "href": "0-The-Unix-Shell/slides/series-introduction-slides.html",
    "title": "Series Introduction",
    "section": "",
    "text": "Goals and Topics\nThis training series is intended for absolute beginners and focused on the basic usage of the Bash Shell. Concepts introduced in these sessions are foundational to the application of computational approaches and will enable more powerful and reproducible research.\nBy the end of the series, you should be able to\n\ndescribe the Unix file system structure\nnavigate the Unix file system from the command line\ncreate, view, and manipulate files and directories\nchain bash shell commands together\ncreate a basic Bash shell script to automate tasks\n\n\n\nCode of Conduct\nWe are dedicated to supporting a safe, productive, and harassment-free environment for everyone. Harassment includes offensive comments and behavior related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion, technology choices, sexual images, deliberate intimidation, stalking, or inappropriate or unwelcome sexual attention. All communication should be appropriate for a professional audience including people of many different backgrounds.\nIn general:\n\nBe kind to others.\nBe open, supportive, and constructive.\nDo not insult or put down others.\nBehave professionally.\nHarassment and sexist, racist, or exclusionary jokes are not appropriate and will not be tolerated.\n\nThank you for helping make this a welcoming, friendly community for all.\n\n\nSchedule\n\n\n\n\n\n\n\nSession\nLesson\n\n\n\n\nSession 1\n\nIntroducing the Shell\nThe File System\n\n\n\nSession 2\n\nPatterns, Filters, and Pipes\n\n\n\nSession 3\n\nLoops\nBash Scripting\n\n\n\nSession 4\n\nPutting it All Together\n\n\n\n\n\n\nCitations\n\nGabriel A. Devenyi (Ed.), Gerard Capes (Ed.), Colin Morris (Ed.), Will Pitchers (Ed.), Greg Wilson, Gerard Capes, Gabriel A. Devenyi, Christina Koch, Raniere Silva, Ashwin Srinath, … Vikram Chhatre. (2019, July). swcarpentry/shell-novice: Software Carpentry: the UNIX shell, June 2019 (Version v2019.06.1). Zenodo. http://doi.org/10.5281/zenodo.3266823\nComputational Foundations Workshop. (n.d.). Retrieved December 7, 2022, from https://umich-brcf-bioinf.github.io/2022-10-31-umich-computational-foundations/html/index.html\n\nNote: This series has been adapted from the Carpentries course entitles “The Unix Shell” [1] as well as the “Computational Foundations Workshop” [2], created by the University of Michigan Bioinformatics Core Workshop Team"
  },
  {
    "objectID": "0-The-Unix-Shell/patterns-filters-and-pipes.html",
    "href": "0-The-Unix-Shell/patterns-filters-and-pipes.html",
    "title": "Patterns, Filters, and Pipes",
    "section": "",
    "text": "Pattern Matching\nWildcards (special characters) can be used in several ways:\n\nStandard wildcards (globbing) – matching to work on a set of files\nRegular expressions – matching to work within files\n\n\n\nStandard Expansion Patterns\nStandard wildcards are used for globbing files – pulling together files to perform an action on them.\n\n\n\n\n\n\n\n\nWildcard\nRepresents\n\n\n\n\n*\n0 or more characters\n\na*e would match ae, a103e, apple\n\n\n\n?\nAny single character\n\na?e would match a1e, ape, are\n\n\n\n[]\nAny one of the characters within the brackets (comma separated list)\n\nm[a,3,n]s would match mas, m3s, mns\n[1-3]a would match 1a, 2a, 3a\n\n\n\n{}\nAny term within the brackets (comma separated list)\n\nls {*.doc, *.pdf} would list all files ending in .doc and .pdf\n\n\n\n[!]\nAnything except (negate) the character within the brackets (comma separated list)\n\nls *[!A,B].txt would match 123.txt, ZNEBF.txt, C.txt\n\n\n\n\\\n“Escapes” the following character, to treat it as a non-special character\n\nls *\\.*.txt would match this.file.txt, NOT this.txt\n\n\n\n\nLet’s try some examples in our shell-lesson-data directory.\n\nQ&A: How can we list all files in shell-lesson-data/north-pacific-gyre that end with .txt?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n# change into directory \ncd ~/Desktop/shell-lesson-data/north-pacific-gyre\n\n# use * wildcard to list all ending in .txt\nls *.txt\n\nNENE01729A.txt\nNENE01729B.txt\nNENE01736A.txt\nNENE01751A.txt\nNENE01751B.txt\nNENE01812A.txt\nNENE01843A.txt\nNENE01843B.txt\nNENE01971Z.txt\nNENE01978A.txt\nNENE01978B.txt\nNENE02018B.txt\nNENE02040A.txt\nNENE02040B.txt\nNENE02040Z.txt\nNENE02043A.txt\nNENE02043B.txt\nthis.file.txt\nthis.txt\n\n\n\n\n\n\n\nQ&A: List the files in shell-lesson-data/north-pacific-gyre that do not end with .txt.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n# change into directory \ncd ~/Desktop/shell-lesson-data/north-pacific-gyre\n\n# use ! to with the [] to negate all files ending in .txt\nls *[!.txt]\n\ngoodiff.sh\ngoostats.sh\n\n\n\n\n\n\n\nQ&A: List the files in shell-lesson-data/north-pacific-gyre with the last two positions before the suffix are a number lower than 5, followed by not Z.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n# change into directory \ncd ~/Desktop/shell-lesson-data/north-pacific-gyre\n\n# use ! to with the [] to negate all files ending in .txt\nls *[0-4][!Z].*\n\nNENE01751A.txt\nNENE01751B.txt\nNENE01812A.txt\nNENE01843A.txt\nNENE01843B.txt\nNENE02040A.txt\nNENE02040B.txt\nNENE02043A.txt\nNENE02043B.txt\n\n\n\n\n\n\n\n\n\nRegular Expressions (regex)\nA complex form of pattern matching that combines “wildcards” to create powerful patterns for text matching and manipulation in files.\n\n\n\n\n\n\nTip\n\n\n\nUsed with grep to search for text – which we’ll explain in a bit.\n\nregex symbols are interpreted by the commands above\n\n\n\n\n\nWhat makes a pattern?\nTo efficiently represent a pattern, we need to develop a language that specifies\n\natom – the actual character that we want to match\npositions – the location of this atom\nnumber of times – how many times we see the atom\ngroups – groups of matched atoms or non-matched\n\n\n\nRepresenting Atoms\nCharacter classes are used to represent atoms.\n\n\n\n\n\n\n\nCharacter class – Example\nMatches\n\n\n\n\nNon-special characters – a\na matches a\n\n\nDot – .\n. matches ANYTHING\n\n\nRange – [a-z]\n[a-z] matches any letter from a through z\n\n\nCharacter set – [abc]\n[abc] matches a, b, or c\n\n\nCharacter set – [[:alnum:]]\n[[:alnum:]] matches any alpha-numeric character\n\n\nCharacter set – [[:lower:]]\n[[:lower:]] matches any lowercase letter\n\n\nCharacter set – [[:space:]]\n[[:space:]] matches any whitespace\n\n\nCharacter set – [[:digit:]] | [[:digit:]] matches any digit |\n\n\nNegated character set – [^abc]\n[^abc] matches anything except a, b, or c\n\n\nWhitespace – \\s\n\\s matches any whitespace character\n\n\nNon-whitespace – \\S\n\\S matches any non-whitespace character\n\n\nWord – \\w\n\\w an entire word (continuous alpha-numeric or underscores)\n\n\nNon-word – \\W\n\\W not a word\n\n\nDigit – \\d\n\\d any digit\n\n\nNon-digit – \\D\n\\D not a digit\n\n\n\n\n\n\nPositions\nAnchors are used to specify the location of characters or set of characters – so the pattern will only match if the position also matches.\n\n\n\n\n\n\n\nAnchor\nExample(s)\n\n\n\n\nStart of line/string – ^\n^a matches the a in apple, but not sandal\n\n\nEnd of line/string – $\na$ matches the a in spa, but not space\n\n\n\n\n\n\nNumber of times\nQuantifiers are used to specify the number of times preceeding characters or sets of characters are repeated.\n\n\n\n\n\n\n\nQuantifier\nExample(s)\n\n\n\n\n0 or 1 time – ?\nre?d matches rd, red, NOT reed, read\n\n\n0 or more times – *\nre*d matches rd, red, reed, NOT read\n\n\n1 or more times – +\nre+d matches red, reed, NOT rd, read\n\n\nSpecified number of times – {}\nre{1}d matches red, NOT rd, reed, read\n\n\nRange of times – {1,3}\nre{1,3}d matches red, reed, NOT rd, read\n\n\nOr – |\nre(e|a)d matches reed, read, NOT rd, red\n\n\n\n\n\n\nGroups and Reference\nMatched atoms can be grouped together and referenced later.\n\n\n\n\n\n\n\nGrouping/Reference\nExample(s)\n\n\n\n\nCapture the group – ()\n(re)d groups re together\n\n\nReference the group – \\1\n\\1 references the first group captured\n\n\n\n\n\n\n\nPracticing with Regex\nLearning regex takes time and practice!\n\nQuestion 1:\nWhich expression will select only the in the following?\n“The great thing about learning is that the experience itself teaches you something, though it may not be the thing you wanted to learn.”\n\nthe\n(T|t)e\n[Tt]he\n*he\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nYes. This will match the.\nNo. This will also match The.\nNo. This will also match The.\nNo. This will also match The.\n\n\n\n\n\n\nQuestion 2:\nWhich expression will select all of the following?\nfoxes boxes loxes\n\n.oxes\n[fbl]oxes\n(f|b|l)oxes\n*oxes\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nYes. . will match anything for the first character.\nYes. Uses character set matching.\nYes. Uses or matching.\nNo. * is a quantifier and references nothing.\n\n\n\n\n\n\nQuestion 3:\nWhich expression will select all of the following?\nnd ned need\n\nne+d\nne?d\nne*d\nne.d\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nNo. + matches e 1 or more times.\nNo. ? matches e 0 or 1 times.\nYes. * matches e 0 or more times.\nNo. . matches anything one time exactly.\n\n\n\n\n\nFor more practice, I recommend RegexOne\n\n\n\n\n\nUsing regex with grep\nRegular expressions are most effective when used with specific commands.\n\ngrep – globally search a regular expression and print\nSearches for a pattern within a file and returns the line containing the pattern.\n\n\n\n\n\n\nTip\n\n\n\nBy default, grep returns the line containing the pattern and is case-sensitive.\nA few of the useful options are below:\n\nuse -i to peform case-insensitive matching\nuse -v to return the non-matching lines\nuse -w to return the word instead of the line that matches\nuse -A to return the line after the matching line\nuse -B to return the line before the matching line\nuse -E to use extended regular expressions\nuse -c to return the number of times a match is seen\nuse -n to output the line number that matches\n\n\n\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ngrep\nflags\npattern /path/to/file\n\n\n\nLet’s try this on a few files in our shell-lesson-data/exercise-data/creatures directory.\nIf we take a look at top 5 lines of each file (head command) we see:\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# print the first 5 lines each file \nhead -n 5 *\n\n==> basilisk.dat <==\nCOMMON NAME: basilisk\nCLASSIFICATION: basiliscus vulgaris\nUPDATED: 1745-05-02\nCCCCAACGAG\nGAAACAGATC\n\n==> minotaur.dat <==\nCOMMON NAME: minotaur\nCLASSIFICATION: bos hominus\nUPDATED: 1765-02-17\nCCCGAAGGAC\nCGACATCTCT\n\n==> unicorn.dat <==\nCOMMON NAME: unicorn\nCLASSIFICATION: equus monoceros\nUPDATED: 1738-11-24\nAGCCGGGTCG\nCTTTACCTTA\n\n\nUsing grep, let’s pull out the common names line of all of the creatures.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# grep COMMON NAME from all files ending in .dat \ngrep 'COMMON NAME' *.dat\n\nbasilisk.dat:COMMON NAME: basilisk\nminotaur.dat:COMMON NAME: minotaur\nunicorn.dat:COMMON NAME: unicorn\n\n\nUsing grep, let’s check how many times the CCC is seen in each creatures genomic sequence.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# grep COMMON NAME from all files ending in .dat \ngrep -c 'CCC' *.dat\n\nbasilisk.dat:22\nminotaur.dat:18\nunicorn.dat:22\n\n\nWhat if we want just the first line following the common name unicorn?\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# grep COMMON NAME from all files ending in .dat \ngrep -A 1 'unicorn' *.dat\n\nunicorn.dat:COMMON NAME: unicorn\nunicorn.dat-CLASSIFICATION: equus monoceros\n\n\nWhat if we wanted anything updates in the 1740’s? We need to use -E option to use the extended regular expressions we covered earlier.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\n# grep COMMON NAME from all files ending in .dat \ngrep -E '174\\d-\\d{2}-\\d{2}' *.dat\n\nbasilisk.dat:UPDATED: 1745-05-02\n\n\nAs we can see, grep and pattern matching is useful, but it becomes even more powerful it we combine it with filtering.\n\n\n\n\nFiltering\nIn unix, we can filter data in many ways. Here we’ll cover a few light, but useful commands to do so.\n\ncut – filtering data from each line, cutting columns/fields out\nFilter data (“cut”) based upon a separator.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ncut\nflags\nfile/input\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe cut command separates fields by tabs by default.\nSome useful flags are below:\n\nuse -d to set the delimeter between fields to another character\nuse -f to list the fields to cut (can create a list -f 2,3 cuts field 2 and 3. -f 3-5 cuts field 3 to 5.)\n\n\n\nLet’s take a look at the animals.csv file in shell-lesson-data/exercise-data/animal-counts.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data/exercise-data/animal-counts\n\n# look at file\nhead -n 3 animals.csv\n\n2012-11-05,deer,5\n2012-11-05,rabbit,22\n2012-11-05,raccoon,7\n\n\nLet’s keep only the animals and counts – fields 2 and 3 if we consider the comma as the field separator.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data/exercise-data/animal-counts\n\n# cut to keep the second field (-f), using comma as a field separator (-d)\ncut -f2,3 -d ',' animals.csv\n\ndeer,5\nrabbit,22\nraccoon,7\nrabbit,19\ndeer,2\nfox,4\nrabbit,16\nbear,1\n\n\n\n\n\nuniq – report or filter out repeated lines\nFilters out repeated ADJACENT lines, but also allows for counting them, or ignoring a specific number of them.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nuniq\nflags\ninput/file output/file\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe uniq command is case sensitive by default and removes all duplicated adjacent lines. Thus, sorting prior is recommended.\nSome useful flags are below:\n\nuse -c add the count of the number of times the line occurs\nuse -i to ignore case\n\n\n\nIf a file looked like this:\n\n$ cat animals.txt\nbear\ndeer\ndeer\nfox\nrabbit\nrabbit\nrabbit\nraccoon\n\nThen uniq, with counts would output\n\nuniq -c animals.txt\n   1 bear\n   2 deer\n   1 fox\n   3 rabbit\n   1 raccoon\n\n\n\n\nsort – order lines of a file\nSorts a file or input in a highly customizable way.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nsort\nflags\nfile/input\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe sort command is case sensitive by default sorts lexiconically\nSome useful flags are below:\n\nuse -t to specify the field separator\nuse -i to ignore case\nuse -c to check if a file is sorted\nuse -k to specify a field to sort on\nuse -u to keep unique lines\nuse -n to perform a numberic sort\n\n\n\nLet’s sort the animals file by the second field (-k), using the commma as the field separator (-t).\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data/exercise-data/animal-counts\n\n# cut to keep the second field (-f), using comma as a field separator (-d)\nsort -t , -k 2 animals.csv\n\n2012-11-07,bear,1\n2012-11-06,deer,2\n2012-11-05,deer,5\n2012-11-06,fox,4\n2012-11-07,rabbit,16\n2012-11-06,rabbit,19\n2012-11-05,rabbit,22\n2012-11-05,raccoon,7\n\n\n\n\n\ngrep – globally search a regular expression and print\nReturns filtered lines, can also negate lines.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ngrep\nflags\npattern /path/to/file\n\n\n\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data/exercise-data/animal-counts\n\n# give me the lines that do not have an animal that ends in r\ngrep -Ev ',\\w+r,' animals.csv\n\n2012-11-05,rabbit,22\n2012-11-05,raccoon,7\n2012-11-06,rabbit,19\n2012-11-06,fox,4\n2012-11-07,rabbit,16\n\n\n\n\n\n\nPipes\nPipes (|) are used to quickly connect unix commands by “piping” output of one command to the input of another.\ncommand1 | command2 | command3\n\nDownload the gtf\nWe will download the file with wget or curl.\nIn the terminal, type which wget, and which curl.\n\nIf you see a path returned when you type one of those commands and press enter, then you have that command.\n\n\n#check for wget\nwhich wget\n\n#check for curl\nwhich curl\n\n/Users/csifuentes/miniconda3/bin/wget\n/Users/csifuentes/miniconda3/bin/curl\n\n\n\nYou can download the file as below, depending on the command you want to use.\n\nwgetcurl\n\n\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# wget file (using capital -O as the flag to create a gzipped file named example.gtf.gz)\nwget -O example.gtf.gz ftp://ftp.ensemblgenomes.org/pub/release-39/fungi/gtf/fungi_basidiomycota1_collection/cryptococcus_neoformans_var_grubii_h99/Cryptococcus_neoformans_var_grubii_h99.CNA3.39.gtf.gz\n\n\n\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# wget file (using lowercase -o as the flag to create a gzipped file name example.gtf.gz)\ncurl -o example.gtf.gz ftp://ftp.ensemblgenomes.org/pub/release-39/fungi/gtf/fungi_basidiomycota1_collection/cryptococcus_neoformans_var_grubii_h99/Cryptococcus_neoformans_var_grubii_h99.CNA3.39.gtf.gz\n\n\n\n\nYou can unzip the file as below, depending on the command you want to use.\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# gunzip file\ngunzip example.gtf.gz\n\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# view it\nhead example.gtf\n\n#!genome-build CNA3\n#!genome-version CNA3\n#!genome-date 2015-11\n#!genome-build-accession GCA_000149245.3\n#!genebuild-last-updated 2015-11\n1   ena gene    100 5645    .   -   .   gene_id \"CNAG_04548\"; gene_source \"ena\"; gene_biotype \"protein_coding\";\n1   ena transcript  100 5645    .   -   .   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\";\n1   ena exon    5494    5645    .   -   .   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\"; exon_id \"AFR92135-1\";\n1   ena CDS 5494    5645    .   -   0   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\"; protein_id \"AFR92135\"; protein_version \"1\";\n1   ena start_codon 5643    5645    .   -   0   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\";\n\n\nGTF files contain the following information, as columns (fields)\n\nchromosome name\nannotation source\nfeature-type\ngenomic start\ngenomic end\nscore\nstrand\ngenomic phase\nadditonal information (gene_id, etc.)\n\n\n\n\nAnalysis\nUsing the commands we’ve learned thus far, let’s explore the example.gtf file to answer the following:\n\nHow many chromosomes does the organism have?\nHow many unique gene ids does the organism have?\nWhich chromosome has the most genes?\n\n\nHow many chromosomes does the organism have?\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the first column (chromosomes)\n# sort the chromosomes numerically, removing duplicates\ncat example.gtf | grep -v '^#' | cut -f1 | sort -nu \n\nMt\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\nThis organism has 14 + Mt chromosomes.\n\n\nHow many genes does the organism have?\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the third column (biotype)\n# sort values\n# keep unique values, specifying counts of each unique value\ncat example.gtf | grep -v '^#' | cut -f3 | sort | uniq -c\n\n49063 CDS\n52036 exon\n6923 five_prime_utr\n8497 gene\n7860 start_codon\n3167 stop_codon\n7034 three_prime_utr\n9348 transcript\n\n\nThis organism has 8497 genes.\n\n\nWhich chromosome has the most genes?\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the first and third columns (chromosome, biotype)\n# sort values\n# keep unique values, specifying counts of each unique value to get totals of biotypes by chromosome\n# pull out gene biotype totals\ncat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep 'gene'\n\n1033 1  gene\n 474 10 gene\n 663 11 gene\n 326 12 gene\n 322 13 gene\n 417 14 gene\n 706 2  gene\n 725 3  gene\n 503 4  gene\n 812 5  gene\n 640 6  gene\n 641 7  gene\n 639 8  gene\n 554 9  gene\n  42 Mt gene\n\n\nChromosome 1 has the most genes, 1033. Mt has the least, 42.\nAs we can see, piping commands together allows us to easily perform analyses as a set of commands. In the next lesson, we’ll learn about how we can use loops and scripts to do this even more efficiently."
  },
  {
    "objectID": "0-The-Unix-Shell/introducing-the-shell.html",
    "href": "0-The-Unix-Shell/introducing-the-shell.html",
    "title": "Introducing the Shell",
    "section": "",
    "text": "What is the shell?\nThe shell (also known as the command-line) is a program that allows us to tell the computer what to do by giving it a “command” Figure 1a.\n\n\n\n\n\n\nTip\n\n\n\nOther names for the shell are terminal, Bash, UNIX command line, and more.\n\n\nAnother common way we tell the computer what to do is through the use of a “point and click” graphical user interface (GUI) approach Figure 1b.\n\n\n\n\n\n\n\n(a) Command Line Interface (CLI)\n\n\n\n\n\n\n\n(b) Graphical User Interface (GUI)\n\n\n\n\nFigure 1: Different ways to interact with a computer\n\n\n\n\n\nWhy use the shell?\nIsn’t pointing and clicking easier? Imagine you had the following task:\n\n\n\n\n\n\nYou have a directory with 10 .txt files.\nPull the first line from each file into a single new file. You should end up with a list of all of the first lines.\n\n\n\nTake a look below to see the process for GUI and CLI.\n\nGUI StepsCLI Code\n\n\n1. Create new file\n2. Open file 1, copy line 1, paste into new file, close file 1.\n3. Open file 2, copy line 1, paste into new file, close file 2.\n4. Repeat 7 more times\n\n\nhead -n1 -q *.txt > new-file.txt\n\n\n\nFor this task, the GUI was tedious, time-consuming, and error-prone while the CLI was a single-command, quick, and relatively error proof.\n\n\n\nAccessing the Shell\nLet’s start using the shell. Open the shell (terminal) on your computer. Select the appropriate instructions below, based on your operating system.\n\nWindows InstructionsmacOS Instructions\n\n\n\nGo the the Start menu and select “All Apps”.\nScroll down the list of applications and select the Git option.\nFrom the drop-down menu, select Git Bash.\nA terminal should open up.\n\n\n\n\nOpen Finder and go to the Applications tab.\nScroll down the list of applications and select Utilities.\nSelect Terminal.\nA terminal should open up.\n\n\n\n\n\n\n\nUsing the shell\nOnce we open our terminal, the $ shows us that shell is ready for input.\nLet’s see what day it is using the ls command.\n\nls stands for list\nlists the objects in a location\n\nIn your terminal, type ls and press enter.\n\nls\n\ncount.sh\nexample.gtf\nexercise-data\nfastqc.sh\nindex\nmetadata.txt\nnorth-pacific-gyre\nrnaseq\nrnaseq.sh\nsimulated_reads\nstar.sh\nthesis\ntrim.sh\n\n\nBefore we learn more commands, let’s learn about the structure of commands.\n\n\n\nCommand syntax\nCommands follow a general syntax\ncommand option/flag argument\n\ncommand – the main command\noption/flag – modifies the behavior of the command, often optional\nargument – the source and/or target of the command, sometimes optional\n\n\n\n\n\n\n\nTip\n\n\n\n\nOptions use either - or -- to signal their usage.\nArguments can be either a target (as in the ls command) or both a source and target (as in the mv command)\n\n\n\n\nAlter Command Behavior\nLet’s change the way ls command behaves by providing a value for the option.\nIn your terminal, type ls -F and press enter.\n\nls -F\n\ncount.sh\nexample.gtf\nexercise-data/\nfastqc.sh\nindex/\nmetadata.txt\nnorth-pacific-gyre/\nrnaseq/\nrnaseq.sh\nsimulated_reads/\nstar.sh\nthesis/\ntrim.sh\n\n\nThis -F option/flag returns the output in a different format, with a / following directories and @ preceeding symbolic links.\n\n\n\n\nGetting help\nTo better understand command usage and their options we can use the following (depending on the command).\n\n\n\n\n\n\n\n\nMethod of getting help\nDescription\nExample\n\n\n\n\n--help or -h option/flag\nDisplays help menu for the command/program\nls --help\n\n\nman command\nDisplays the manual for the command/program in-depth\nman ls\n\n\n\n\n\n\n\n\n\n\n(a) Using the --help flag\n\n\n\n\n\n\n\n(b) Using the man command\n\n\n\n\nFigure 2: Different ways to get help with a command.\n\n\n\n\n\nMaking sense of errors\nThe shell provides (usually) helpful and informative error messages.\nFor example, if you look closely at the ls --help example above, you’ll see that the usage of --help actually resulted in an error (see below).\nQ&A: What is the error telling us?\n\nls: unrecognized option `--help'\nusage: ls [-@ABCFGHILOPRSTUWabcdefghiklmnopqrstuvwxy1%,] [--color=when] [-D format] [file ...]\n\n\nQ&A: What is the error above telling us?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n--help is an unrecognized option\n\nThe correct usage and options for ls"
  },
  {
    "objectID": "0-The-Unix-Shell/installation.html",
    "href": "0-The-Unix-Shell/installation.html",
    "title": "Installation and Resources",
    "section": "",
    "text": "Software\nBash Shell For this series, you will need access to the Bash shell. Linux and macOS users will have access to this already and should not need to install anything.\nWindows users will need to do some extra work.\n\nInstall Git for Windows, which will provide acess to Bash shell and Git by following the instructions here.\n\nRNA-seq processing workflow\nIn the final lesson, we will use miniconda to control in installation of several tools. Follow the steps below.\n\nInstall miniconda using the appropriate directions from here: https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html\nAfter closing and re-opening the terminal, the conda base environment should be enabled. To check this, make sure you see (base) to the left of your user name in the terminal prompt.\n(base) user: $\nCreate a conda environment called rnaseq while installing the needed tools/software – enter “y” when prompted.\nconda activate base\nconda create -n rnaseq -c bioconda fastqc trim-galore subread star\n\n\n\nData\nIntroductory Files These data are zipped and should begin downloading once the link below is clicked.\n\nClick here to download the data.\nMove the shell-lesson-data.zip file from your Downloads to your Desktop.\nUnzip the file to extract the data. You should end up with a shell-lesson-data directory on your Desktop.\n\nRNA-seq similated data/files For the last lesson, you will need simulated reads, fasta files, index files, etc.\n\nClick here to download the data.\nMove the directory to your Desktop if possible."
  },
  {
    "objectID": "0-The-Unix-Shell/variables-and-loops.html",
    "href": "0-The-Unix-Shell/variables-and-loops.html",
    "title": "Variables and Loops",
    "section": "",
    "text": "Storing and Using Values – Variables\nValues can be temporarily stored into items called variables. This is very useful in looping and scripting, particularly when we may not know or be able to keep track of values.\nInterestingly, we use diffent syntax when assigning/unsetting and using variables.\n\nsetting variables – use variable=value\nusing variables – use $variable\nunsetting variables – use unset variable\n\n#create a variable named file_type and assign it a value of fastq\nfile_type=\"fastq\"\n\n#call the file_type variable, print it to the screen\necho \"the value after setting:\" $file_type\n\n#unset (or remove) the variable assignment\nunset file_type\n\n#check for the value of file_type\necho \"the value after unsetting:\" $file_type \n\nthe value after setting: fastq\nthe value after unsetting:\n\n\n\n\n\n\n\n\n\nTips and Tricks with Variables\n\n\n\n\nWhen setting, no spaces around the = – variable = value will not do what we want.\nUsing quotes when calling variables prevents weird issues – command \"$variable\" prevents issues when variable values have spaces, etc.\nCommand output can be stored using $() – variable=$(command x) stores the output of command x as variable.\nSuffixes can be added by using ${variable} – \"${file_type}1\" from above would be fastq1\n\n\n\n\nVariables – Checking Understanding\n\nQ&A: Which of the following correctly assigns the value of fastq to a variable named file_suffix?\n\nfastq=$file_suffix\nfastq = $file_suffix\nfastq=file_suffix\nfile_suffix=fastq\nfile_suffix=$fastq\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nfastq=$file_suffix – No. Refers to a variable that doesn’t exist and wrong order.\nfastq = $file_suffix – No. The added space tries to call a command named fastq. Also, this is the wrong order.\nfastq=file_suffix – No. This is the wrong order and would create a variable called fastq.\nfile_suffix=fastq – Yes.\nfile_suffix=$fastq – No. Refers to a variable that doesn’t exist.\n\n\n\n\n\n\nQ&A: Which of the following correctly assigns the value of trt to a variable named var1?\nCorrect order, spacing and quotes/brackets\n\nvar1=${trt}\nvar1 =trt\nvar1=trt\nvar1=$trt\nvar1=\"trt\"\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nvar1=${trt} – No. Refers to variable that doesn’t exist.\nvar1 =trt – No. The added space tries to call a command named var1.\nvar1=trt – Yes.\nvar1=$trt – No. Refers to a variable that doesn’t exist.\nvar1=\"trt\" – Yes.\n\n\n\n\n\n\nQ&A: How can I save the value of the directory that I am in, as a variable named start_dir?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nstart_dir=\"$(pwd)\" and start_dir=$(pwd)\n\n\n\n\n\nQ&A: What would the value of out_var=$\"(ls)\" be?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n(ls). Why not the command output?\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$file1${ext1}\n\necho \"${name1}\"\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n.txt\nThe value of name1 begins with $file1, which is not a variable name, so it has no value. The only value assigned comes from ext1, references as ${ext1}.\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$base1$\"ext1\"\n\necho $name1\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nsampleXext1\nThe value of name1 begins with $base1, which is correctly referenced and holds the value of \"sampleX\". This is followed by $\"ext1\". There is no variable named \"ext1\", the variable is actually named ext1, which would be referenced by $ext1, or ${ext1}, or \"$ext1\", or \"${ext1}\". By having $ before the quotes, we’re really just adding in a string value at the end.\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$base1\"${ext1}\"\n\necho $name1\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nsampleX.txt\nThe value of name1 begins with $base1, which is correctly referenced and holds the value of \"sampleX\". This is followed by \"${ext1}\", which is correctly references and holds the value of .txt.\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$base1\"${ext1}\"\nunset $name1\n\necho $name1\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nsampleX.txt\nThe value of name1 begins with $base1, which is correctly referenced and holds the value of \"sampleX\". This is followed by \"${ext1}\", which is correctly references and holds the value of .txt. To unset, we need to pass the variable name (name1), not a reference to the variable ($name1).\n\n\n\n\n\nQ&A: What would the final output be after running the following in a terminal?\n\nbase1=\"sampleX\"\next1=.txt\nname1=$base1\"${ext1}\"\nunset name1\n\necho $name1\".otherstuff\"\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n.otherstuff\nThe value of name1 is unset right before we reference it, so it holds not value. The last line, we print $name1, followed by a string \".otherstuff\".\n\n\n\n\n\n\n\nUse Case\nLet’s see how we can use variables, combined with previous commands/methods in a quick analysis.\nFrom the example.gtf file (downloaded and used in the previous lesson), which chromosome has the highest number of genes? What about exons?\nA reminder, the initial structure is below, with the chromosome name in the first field, and the feature type in the third field.\n\n# cd to ~/Desktop/shell-lesson-data\ncd ~/Desktop/shell-lesson-data\n\n# view first few lines of the file\nhead example.gtf\n\n#!genome-build CNA3\n#!genome-version CNA3\n#!genome-date 2015-11\n#!genome-build-accession GCA_000149245.3\n#!genebuild-last-updated 2015-11\n1   ena gene    100 5645    .   -   .   gene_id \"CNAG_04548\"; gene_source \"ena\"; gene_biotype \"protein_coding\";\n1   ena transcript  100 5645    .   -   .   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\";\n1   ena exon    5494    5645    .   -   .   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\"; exon_id \"AFR92135-1\";\n1   ena CDS 5494    5645    .   -   0   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\"; protein_id \"AFR92135\"; protein_version \"1\";\n1   ena start_codon 5643    5645    .   -   0   gene_id \"CNAG_04548\"; transcript_id \"AFR92135\"; exon_number \"1\"; gene_source \"ena\"; gene_biotype \"protein_coding\"; transcript_source \"ena\"; transcript_biotype \"protein_coding\";\n\n\nFrom last time, we remember that we need to remove the leading lines of the file to make it easier to work with, using grep -v '^#', then we can cut the fields that we need, sort and count the total genes with sort | uniq -c | grep 'gene'. This gives us the following output.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the first and third columns (chromosome, biotype)\n# sort values\n# keep unique values, specifying counts of each unique value to get totals of biotypes by chromosome\n# pull out gene biotype totals\ncat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep 'gene'\n\n1033 1  gene\n 474 10 gene\n 663 11 gene\n 326 12 gene\n 322 13 gene\n 417 14 gene\n 706 2  gene\n 725 3  gene\n 503 4  gene\n 812 5  gene\n 640 6  gene\n 641 7  gene\n 639 8  gene\n 554 9  gene\n  42 Mt gene\n\n\nWe’re not quite there yet. Let’s capture the output as a variable, named chr_n, to use for later.\nNote: We’re introducing awk here, a language the is quite useful in parsing text, to print out the second column $2.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# print the file to the screen to pipe it into grep\n# remove the lines with #! because they'll get in the way\n# cut to keep the first and third columns (chromosome, biotype)\n# sort values\n# keep unique values, specifying counts of each unique value to get totals of biotypes by chromosome\n# pull out gene biotype totals\n# grab the first line\n# use awk to print the 2nd column\nbiotype_gene=\"gene\"\nbiotype_exon=\"exon\"\nchr_n_gene=$(cat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep $biotype_gene | head -n 1 | awk '{print $2;}')\nchr_n_exon=$(cat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep $biotype_exon | head -n 1 | awk '{print $2;}')\n\necho \"The chromosome with the most \"$biotype_gene\" is: \"$chr_n_gene\necho \"The chromosome with the most \"$biotype_exon\" is: \"$chr_n_exon\n\nThe chromosome with the most gene is: 1\nThe chromosome with the most exon is: 1\n\n\nThe option to capture values and use them in further commands is really evident when we get into loops.\n\n\n\n\nPerforming Actions, Repetitively\nLoops allow us to perform a command (or set of commands) on each item in a list.\n\nFor Loop Syntax\nBash for loops follow a specific syntax.\n\n\n\nFigure 1: The syntax of a bash for loop.\n\n\nKey components of the syntax\n\nkeywords for, in, do, done – tell bash when portions of the loop are coming\nitem – a variable that holds the value of an item from the list for an iteration of the loop\nlist – a set of items (list or array) to iterate over\ncommands – the command(s) performed with each item in the list or array\n\n\nLet’s work through an example from our sample data in ~/Desktop/shell-lesson-data/exercise-data/creatures, by printing out the first two lines of each file.\nWalking through the 4 lines, line-by-line.\n\nFirst lineSecond lineThird lineFourth line\n\n\n\nThe keyword for tells the computer we are entering a loop.\nA variable named filename is created, which is initially empty.\nThe keyword in tells the computer to create an empty list.\nbasilisk.dat, minotour.dat, and unicorn.dat are added to the list.\n\n\n#cd to ~/Desktop/shell-lesson-data/\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\nfor filename in basilisk.dat minotaur.dat unicorn.dat\ndo\n  head -n 2 $filename\ndone\n\n\n\n\nThe keyword do tells the computer to listen for the following commands perform on each item in the list.\n\n\n#cd to ~/Desktop/shell-lesson-data/\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\nfor filename in basilisk.dat minotaur.dat unicorn.dat\ndo\n  head -n 2 $filename\ndone\n\n\n\n\nThe computer the commands to perform on the value held by the variable $filename.\n\n\n#cd to ~/Desktop/shell-lesson-data/\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\nfor filename in basilisk.dat minotaur.dat unicorn.dat\ndo\n  head -n 2 $filename\ndone\n\n\n\n\nThe keyword done tells the computer that the loop is over.\n\n\n#cd to ~/Desktop/shell-lesson-data/\ncd ~/Desktop/shell-lesson-data/exercise-data/creatures\n\nfor filename in basilisk.dat minotaur.dat unicorn.dat\ndo\n  head -n 2 $filename\ndone\n\n\n\n\nIn the example above, there are 3 iterations of the loop. Notice how the value of filename changes with each iteration.\n\n\n\n\n\n\n\n\nIteration\nfilename\nlist\n\n\n\n\n1\nbasilisk.dat\nbasilisk.dat minotaur.dat unicorn.dat\n\n\n2\nminotaur.dat\nbasilisk.dat minotaur.dat unicorn.dat\n\n\n3\nunicorn.dat\nbasilisk.dat minotaur.dat unicorn.dat\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe variable could be named anything – in the example above, we can say\nfor x in basilisk.dat minotaur.dat unicorn.dat instead.\n\n\n\n\n\nWhile Loop Syntax\nA while loop is another useful type of loop in bash and follows a specific syntax.\n\n\n\nFigure 2: The syntax of a bash while loop.\n\n\nKey components of the syntax\n\nkeywords while, do, done – tell bash when portions of the loop are coming\ncondition – a condition to be met for the loop to continue (“while true”)\ncommands – the command(s) performed with each item in the list or array\n\nLet’s see an example where we print out numbers less than or equal to 7 (-le).\nNote: We can increment num by 1 each time by reassigning the value of num, num=$(($num+1)).\n\nnum=1\n\nwhile [ $num -le 7 ]\ndo\n  echo $num\" is less than or equal to 7.\"\n  num=$(($num+1))\ndone\n\n1 is less than or equal to 7.\n2 is less than or equal to 7.\n3 is less than or equal to 7.\n4 is less than or equal to 7.\n5 is less than or equal to 7.\n6 is less than or equal to 7.\n7 is less than or equal to 7.\n\n\n\n\n\nUsing Variables in Loops\nLet’s return to our earlier example with the gtf file. Using a loop, we can now identify the chromosomes with the most of several biotypes.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\nfor bt in gene exon transcript CDS start_codon\ndo \n chr_n=$(cat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep $bt | head -n 1 | awk '{print $2;}')\n echo \"The chromosome with the most \"$bt\" is: \"$chr_n\ndone\n\nThe chromosome with the most gene is: 1\nThe chromosome with the most exon is: 1\nThe chromosome with the most transcript is: 1\nThe chromosome with the most CDS is: 1\nThe chromosome with the most start_codon is: 1\n\n\nWe can take this futher and capture all of the types of biotypes as an array to pass to the loop as a variable.\nNote: An item at position x in an array can be accessed via array[x]. In a loop, we use ${array[@]} to access the item.\n\n# cd to directory\ncd ~/Desktop/shell-lesson-data\n\n# capture the types of biotypes as an array\nbtype_array=$(cat example.gtf | grep -v '^#' | cut -f3 | sort | uniq)\n\nfor bt in ${btype_array[@]}\ndo \n chr_n=$(cat example.gtf | grep -v '^#' | cut -f1,3 | sort | uniq -c | grep $bt | head -n 1 | awk '{print $2;}')\n echo \"The chromosome with the most \"$bt\" is: \"$chr_n\ndone\n\nThe chromosome with the most CDS is: 1\nThe chromosome with the most exon is: 1\nThe chromosome with the most five_prime_utr is: 1\nThe chromosome with the most gene is: 1\nThe chromosome with the most start_codon is: 1\nThe chromosome with the most stop_codon is: 1\nThe chromosome with the most three_prime_utr is: 1\nThe chromosome with the most transcript is: 1\n\n\n\n\n\nLoops – Checking Understanding\n\nQ&A: Write a loop that would print out the months of the year. Create an array that holds the months.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nmonths_array=(january february march april may june july august september october november december)\n\nfor month in ${months_array[@]}\ndo\n  echo ${month}\ndone\n\njanuary\nfebruary\nmarch\napril\nmay\njune\njuly\naugust\nseptember\noctober\nnovember\ndecember\n\n\n\n\n\n\n\nQ&A: Look at the following code and output.\n\n$ ls\ncubane.pdb  ethane.pdb  methane.pdb octane.pdb  pentane.pdb propane.pdb\n\nWhat would be the output of the following code?\n\n$ for filename in c*\n  do \n    ls $filename\n  done\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\ncubane.pdb. The list that is iterated over is any file that startes with c.\n\n\n\n\nHopefully you’ve seen how helpful variables and loops can be. Next, we’ll put things together with bash scripts."
  },
  {
    "objectID": "0-The-Unix-Shell/the-file-system.html",
    "href": "0-The-Unix-Shell/the-file-system.html",
    "title": "The File System",
    "section": "",
    "text": "A Common Structure\nThe file system manages and organizes our files and directories using a common structure defined by:\n\nParent-child relationships\nA “family tree” (more like a root system) of “parent” and “child” relationships (Figure 1a).\nDirectionality\nParent items are at the top/up; child items are at the bottom/ down (Figure 1a).\nDifferent ways to access\nAccessible via command-line (Figure 1b) and GUI (Figure 1c).\n\n\n\n\n\n\n\n\n(a) A representative file system with parent-child relationships shown.\n\n\n\n\n\n\n\n\n\n(b) Accessing the file system via the command-line.\n\n\n\n\n\n\n\n(c) Accessing the file system via graphical interface.\n\n\n\n\nFigure 1: A representative file system.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe top-most directory is called the root directory and is shown with the /.\n\n\n\n\n\nPaths\nThe directories, files, and subdirectories of a file system are connected by paths. Paths also describe the locations within the file system.\n\n\n\nFigure 2: The absolute path from / to mouse.gtf, highlighted in red.\n\n\n\nAbsolute and Relative Paths\nThere are two types of paths:\n\nAbsolute path\nThe path taken from the top-most directory (root, /), to the specified file or directory. The absolute path always starts with /.\nRelative path\nThe path taken from the present working directory to the specified file or directory.\n\nExample paths to a few items from Figure 1a are shown below.\n\n\n\n\n\n\n\n\nTarget\nAbsolute Path\nRelative Path (from the /bin directory)\n\n\n\n\nplot.R\n/bin/plot.R\nplot.R\n\n\nconda\n/bin/conda\nconda\n\n\n\n\n\n., .., and ~ aliases\nThe characters ., .. and ~ have special meaning in the unix shells.\n\n. – Current directory\n.. – Parent directory\n~ – Users home directory\n\nFor example the following code means to do_the_thing in the current directory.\n\ndo_the_thing ./\n\nThe code below means to do_the_thing two directories above our current directory.\n\ndo_the_thing ../../\n\nFinally, the code below means to do_the_thing in the user’s home directory.\n\ndo_the_thing ~\n\n\nQ&A: If we are in the /tmp directory, what are the absolute and relative paths of the genome.fa file?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n\n\n\n\n\n\n\nTarget\nAbsolute Path\nRelative Path\n\n\n\n\ngenome.fa\n/data/genome.fa\n../data/genome.fa\n\n\n\n\n\n\n\n\n\n\n\nNavigating the File System\nLet’s learn a few useful commands for moving around the file system.\n\npwd – print working directory\nPrints out our current location, called our “working directory”.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\npwd\n\n\n\n\n\nRun the pwd command in your terminal.\n\npwd\n\n/Users/csifuentes/Desktop/shell-lesson-data\n\n\n\nQ&A: Is the path returned an absolute or relative path?\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\nAbsolute, the path starts with /. Also, pwd will always return the absolute path (from the root directory).\n\n\n\n\n\n\n\nls – list\nLists the items in a directory.\nWithout a target, the command defaults to the current directory (./)\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nls\nflags\npath/to/directory\n\n\n\nIn terminal, type ls and press enter/return.\n\nls\n\nexercise-data\nnorth-pacific-gyre\n\n\nItems in your home directory is listed, alphabetically. Flags/options can make the output more useful, a few are shown below.\n\n\n\n\n\n\n\nFlag\nDescription\n\n\n\n\n-l\nReturns the results in a long format, which provides information about\n\nthe item type (- for file, d for directory, l for link)\nitem permissions\nthenumber of links or files inside that item\nthe item owner\nthe item group\nthe time the item was created\nitem size\nitem name\n\n\n\n-h\nReturns the results with a human-readible size value\n\n\n-a\nIncludes entries beginning with a ., which are not shown by default\n\n\n\nLet’s use these 3 flags together. Type the ls -lha into your terminal.\n\nls -lha\n\ntotal 16\ndrwxrwxr-x@  5 csifuentes  staff   160B Mar  2 11:54 .\ndrwx------@  6 csifuentes  staff   192B Feb 27 13:35 ..\n-rw-r--r--@  1 csifuentes  staff   6.0K Feb 27 18:00 .DS_Store\ndrwxrwxr-x@  7 csifuentes  staff   224B Sep 16  2021 exercise-data\ndrwxrwxr-x@ 21 csifuentes  staff   672B Sep 16  2021 north-pacific-gyre\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe . is also used to hide items.\n\n\n\n\n\ncd – change directory\nChanges our location in the file system.\nNote: Without a target directory, cd will default to the user home directory.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ncd\n\npath/to/directory\n\n\n\n\nQ&A: Change your current working directory to be one directory above the current directory, then check the new working directory location and list it’s contents.\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\ncd ..\npwd\nls -lha\n\n/Users/csifuentes/Desktop\ntotal 920\ndrwx------@  6 csifuentes  staff   192B Feb 27 13:35 .\ndrwxr-xr-x+ 73 csifuentes  staff   2.3K Mar  2 11:54 ..\n-rw-r--r--@  1 csifuentes  staff   6.0K Feb 17 11:08 .DS_Store\n-rw-r--r--   1 csifuentes  staff     0B Sep 22  2020 .localized\ndrwxrwxr-x@  5 csifuentes  staff   160B Mar  2 11:54 shell-lesson-data\n-rw-r--r--@  1 csifuentes  staff   450K Feb 24 15:42 shell-lesson-data.zip\n\n\n\n\n\n\nNow let’s move back into the shell-lesson-data directory.\n\ncd ~/Desktop/shell-lesson-data\n\n\n\n\nmkdir – make directory\nCreates new directories.\nNote: The -p flag will create the directory and any required intermediate directories.\n\n\n\n\n\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nmkdir\nflags\npath/to/directory path/to/additional/directory\n\n\n\nLet’s pretend we want to create a directory structure for our thesis work. We need the following:\n\nA top-level directory.\nSeparate directories for each chapter (we have 5).\nDirectories for images, data, and text of each chapter.\n\nWe’ll do this using only the commands we’ve learned thus far (except for my use of tree to easily view directory structures). Later, we’ll learn quicker ways to do this.\nMake a top-level directory.\n\n# let's first change into our shell-lesson-data directory\ncd ~/Desktop/shell-lesson-data\n\n# make the directory\nmkdir -p thesis\n\n# look at the structure of thesis\ntree thesis\n\nthesis\n\n0 directories, 0 files\n\n\nCreate a directory for each chapter.\n\n# create all of the directories at one time\nmkdir -p thesis/chapter_1 thesis/chapter_2 thesis/chapter_3 thesis/chapter_4 thesis/chapter_5\n\n# look at the structure of thesis\ntree thesis\n\nthesis\n├── chapter_1\n├── chapter_2\n├── chapter_3\n├── chapter_4\n└── chapter_5\n\n5 directories, 0 files\n\n\nCreate a directory for each subsection of each chapter.\n\n# create sub-directories in each chapter\nmkdir -p thesis/chapter_1/images thesis/chapter_1/data thesis/chapter_1/text\nmkdir -p thesis/chapter_2/images thesis/chapter_2/data thesis/chapter_2/text\nmkdir -p thesis/chapter_3/images thesis/chapter_3/data thesis/chapter_3/text\nmkdir -p thesis/chapter_4/images thesis/chapter_4/data thesis/chapter_4/text\nmkdir -p thesis/chapter_5/images thesis/chapter_5/data thesis/chapter_5/text\n\n# look at the structure of thesis\ntree thesis\n\nthesis\n├── chapter_1\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_2\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_3\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_4\n│   ├── data\n│   ├── images\n│   └── text\n└── chapter_5\n    ├── data\n    ├── images\n    └── text\n\n20 directories, 0 files\n\n\n\n\n\n\n\n\nGood file and directory names\n\n\n\nComplicated names make it difficult when working on the CL\n\nDo not use spaces – bash reads these a separate arguments\nDo not begin with a dash, “-” – bash reads these a options\nUse alpha-numeric, ., -, and _\n\nIf you need refer to a file/directory that contains a space, put the entire thing in ” ”\n\"/root/subdir/file with spaces\"\n\n\n\n\n\n\nWorking in the File System\nNow let’s learn some useful ways to work in the file system.\n\nText Editors\nAllow one to create and edit text files\n\nusing plain characters only, unlike MS Word and Google Docs\nvarying easy of use and capability of the text editors\ncan use in-terminal (in the shell) or GUI (external)\n\n\n\n\nIn-Terminal Examples\nGUI Examples\n\n\n\n\npico, nano\nnotepad, notepad++\n\n\nemacs, Vim\nAtom, Visual Studio Code\n\n\n\n\n\n\n\n\n(a) In-terminal Editor – nano\n\n\n\n\n\n(b) GUI Editor – Visual Studio Code\n\n\nFigure 3: In-live vs GUI text editors\n\n\nContinuing with our thesis work, let’s create a README.txt file to keep track of each chapter directory.\n\n\nnano – in-line text editor\nOpens the editor into a file (or new file if it doesn’t exist).\nNote: Creates the target file if it does not already exist. Flags and arguments are optional here.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nnano\nflags\npath/to/file\n\n\n\nLet’s create the README.txt file in our thesis directory.\n\nnano ~/Desktop/shell-lesson-data/thesis/README.txt\n\nA file will open in the editor. Follow the directions in Figure 4 below.\n\n\n\nFigure 4: Edit and save the file as README.txt using the nano editor.\n\n\nLooking in thesis, we see our new file.\n\nls ~/Desktop/shell-lesson-data/thesis\n\nREADME.txt\nchapter_1\nchapter_2\nchapter_3\nchapter_4\nchapter_5\n\n\n\n\n\ncp – copy\nCopies and pastes items with a single command.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\ncp\nflags\npath/to/source path/to/destination\n\n\n\nIt might be nice to have a README in each chapter directory. Let’s use the cp command to do this.\n\n# copy to each chapter directory\ncp thesis/README.txt thesis/chapter_1/\ncp thesis/README.txt thesis/chapter_2/\ncp thesis/README.txt thesis/chapter_3/\ncp thesis/README.txt thesis/chapter_4/\ncp thesis/README.txt thesis/chapter_5/\n\n# view the structure of thesis\ntree thesis\n\nthesis\n├── README.txt\n├── chapter_1\n│   ├── README.txt\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_2\n│   ├── README.txt\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_3\n│   ├── README.txt\n│   ├── data\n│   ├── images\n│   └── text\n├── chapter_4\n│   ├── README.txt\n│   ├── data\n│   ├── images\n│   └── text\n└── chapter_5\n    ├── README.txt\n    ├── data\n    ├── images\n    └── text\n\n20 directories, 6 files\n\n\nThis was tedious. Don’t worry, we’ll learn more efficient ways to do this.\n\n\n\nmv – move and rename\nMoves and renames items, including files and directories. Note that the last argument is the destination.\n\n\n\n\n\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nmv\nflags\npath/to/source path/to/other/source path/to/destination\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe mv command will overwrite a files without warning!\n\nuse the -n flag to prevent overwriting existing files\nuse the -i flag to prompt for confirmation before overwriting existing files\n\n\n\nLet’s rename the README.txt file in the chapter 1 directory so that it contains the chapter number.\n\n# rename the file\nmv thesis/chapter_1/README.txt thesis/chapter_1/README_1.txt\n\n# list files in chapter 1\nls thesis/chapter_1\n\nREADME_1.txt\ndata\nimages\ntext\n\n\n\n\n\nrm – remove\nDeletes the specified target.\n\n\n\nCommand\nOptions/Flags\nArguments\n\n\n\n\nrm\nflags\npath/to/target\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nUnlike in the GUI, rm deletes items permanently!\n\nuse the -r flag to remove files and directories recursively\nuse the -i flag to prompt for confirmation before deleting each item\n\n\n\nFor fun, let’s remove the thesis directory.\n\n# remove the items (files and directories) recursively\nrm -r thesis\n\n# list items in shell-lesson-data\nls\n\nexercise-data\nnorth-pacific-gyre\n\n\n\n\n\n\nIntroducing Wildcards\nWildcards represent 0 or more characters and are used for pattern matching.\n\n* – 0 or more characters\n\n? – exactly 1 character\n\nLet’s see some examples with of each. From our shell-lesson-data/exercise-data/proteins.\nListing all files.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/proteins\n\n# list all files in proteins\nls \n\ncubane.pdb\nethane.pdb\nmethane.pdb\noctane.pdb\npentane.pdb\npropane.pdb\n\n\nListing files ending in ethane.pdb, using *. Note that we use the * at the end becuase all files have the same .pdb ending, so this is faster.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/proteins\n\nls *ethane.*\n\nethane.pdb\nmethane.pdb\n\n\nListing files ending in ethane.pdb with a preceeding character, using ?.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/proteins\n\nls ?ethane.*\n\nmethane.pdb\n\n\nAs shown above, wildcards can be used together and combined in different ways to form complex patterns.\nFor example, we can use ???ane.pdb together to indicate any 3 characters followed by ane.pdb.\n\n# cd into the directory\ncd ~/Desktop/shell-lesson-data/exercise-data/proteins\n\n# list all files with 3 characters followed by ane.pdb\nls ???ane.pdb\n\ncubane.pdb\nethane.pdb\noctane.pdb\n\n\n\n\n\nQuiz Time\n\nQuestion 1:\nStarting from /Users/amanda/data, which command(s) whould take Amanda to her home directory (/Users/amanda)?\n\n\n\n\n\n\na.) cd .\n\n\n\n\n\nNO, will be in the same place\n\n\n\n\n\n\n\n\n\nb.) cd /\n\n\n\n\n\nNO, will be in root\n\n\n\n\n\n\n\n\n\nc.) cd /home/amanda\n\n\n\n\n\nNO, not where we want to be\n\n\n\n\n\n\n\n\n\nd.) cd ../..\n\n\n\n\n\nNO, will be in /Users\n\n\n\n\n\n\n\n\n\ne.) cd ~\n\n\n\n\n\nYES, ~ is an alias for the user’s home directory\n\n\n\n\n\n\n\n\n\nf.) cd home\n\n\n\n\n\nNO, not a thing\n\n\n\n\n\n\n\n\n\ng.) cd\n\n\n\n\n\nYES, without input cd will take you to the home directory\n\n\n\n\n\n\n\n\n\nh.) cd ..\n\n\n\n\n\nYES\n\n\n\n\n\nQuestion 2:\nWith the file system shown, if pwd displays Users/thing, what will ls -F ../backup display?\nNote: -F adds a / to the end of directories.\n\n\n../backup: No such file or directory\n2012-12-01 2013-01-08 2013-01-27\n2012-12-01/ 2013-01-08/ 2013-01-27/\noriginal/ pnas_final/ pnas_sub/\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n../backup/ refers to /Users/backup\n\n\n\n\n\n\nQuestion 3:\nWith the file system below, if pwd displays /Users/backup and ls -r displays items in reverse order, what command(s) will result in the following output?\npnas_sub/ pnas_final/ original/\n\n\nls pwd\nls -r -F\nls -r -F /Users/backup\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nYES.\nYES.\n\n\n\n\n\n\nQuestion 4:\nChris runs the following commands and realizes that sucrose.dat and maltose.dat should be in the raw/ directory.\n\n$ ls -F\n analyzed/ raw/\n$ ls -F analyzed\nfructose.dat glucose.dat maltose.dat sucrose.dat\n$ cd analyzed\n\nComplete the command below to move these files into the raw/ directory.\n\n$ mv sucrose.dat maltose.dat _____/____\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n$ mv sucrose.dat maltose.dat ../raw\n\n\n\n\n\n\nQuestion 5:\nChris gave you a file named file.txt, which contains a list of his favorite animals. You want to rename it to why_do_i_need_this.txt. Which of the following commands would do the trick?\n\ncp file.txt why_do_i_need_this.txt\nmv file.txt why_do_i_need_this.txt\nmv file.txt .\ncp file.txt .\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nNo. This creates a new file instead of renaming the old file.\nYES. This renames the file.\nNo. This moves the file to the current directory with no new file name – would throw an error.\nNo. This copies the file to the current directory with no new file name – would throw an error.\n\n\n\n\n\n\nQuestion 6:\nWhat is the output of the final ls command in the sequence shown below?\n\n$ pwd\n /Users/jamie/data\n$ ls \n proteins.dat\n$ mkdir recombined\n$ mv proteins.dat recombined/\n$ cp recombined/proteins.dat ../proteins-saved.dat\n$ ls\n\n\nproteins-saved.dat recombined\nrecombined\nproteins.dat recombined\nproteins-saved.dat\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nrecombined\n\n\n\n\n\n\nQuestion 7:\nChris accidentally removed a file named important_file.txt. How can the file be retrieved?\n\nrm --undo\n“^Z”, control+Z\nRestore from the “Trash” bin\nIt can’t.\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nIt can’t. Be very careful when removing files/directories.\n\n\n\n\n\n\nQuestion 8:\nWhen run the in proteins/ directory, which command(s) will produce the output below?\nethane.pdb methane.pdb\n\nls *t*ane.pdb\nls *t?ne.*\nls *t??ne.pdb\nls ethane.*\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\nNo. Would give ethane.pdb methane.pdb octane.pdb pentane.pdb\nNo. Would give octane.pdb pentane.pdb\nYES.\nNo. Would give ethane.pdb\n\n\n\n\n\n\nQuestion 9:\nSam has the following diretory structure.\n\n.\n├── 2015-10-23-calibration.txt\n├── 2015-10-23-dataset1.txt\n├── 2015-10-23-dataset2.txt\n├── 2015-10-23-dataset_overview.txt\n├── 2015-10-26-calibration.txt\n├── 2015-10-26-dataset1.txt\n├── 2015-10-26-dataset2.txt\n├── 2015-10-26-dataset_overview.txt\n├── 2015-11-23-calibration.txt\n├── 2015-11-23-dataset1.txt\n├── 2015-11-23-dataset2.txt\n├── 2015-11-23-dataset_overview.txt\n├── backup\n│   ├── calibration\n│   └── datasets\n└── send_to_bob\n    ├── all_datasets_created_on_a_23rd\n    └── all_november_files\n\nSam uses the following commands to create a backup directory and another directory to send to her collaborator, Bob.\n\n$ cp *dataset* backup/datasets\n$ cp ____calibration____ backup/calibration\n$ cp 2015-____-____ send_to_bob/all_november_files/\n$ cp ____ send_to_bob/all_datasets_created_on_a_23rd/\n\nHelp Sam by filling in the blanks so that the resulting structure looks like this.\n\n.\n├── 2015-10-23-calibration.txt\n├── 2015-10-23-dataset1.txt\n├── 2015-10-23-dataset2.txt\n├── 2015-10-23-dataset_overview.txt\n├── 2015-10-26-calibration.txt\n├── 2015-10-26-dataset1.txt\n├── 2015-10-26-dataset2.txt\n├── 2015-10-26-dataset_overview.txt\n├── 2015-11-23-calibration.txt\n├── 2015-11-23-dataset1.txt\n├── 2015-11-23-dataset2.txt\n├── 2015-11-23-dataset_overview.txt\n├── backup\n│   ├── calibration\n│   │   ├── 2015-10-23-calibration.txt\n│   │   ├── 2015-10-26-calibration.txt\n│   │   └── 2015-11-23-calibration.txt\n│   └── datasets\n│       ├── 2015-10-23-dataset1.txt\n│       ├── 2015-10-23-dataset2.txt\n│       ├── 2015-10-23-dataset_overview.txt\n│       ├── 2015-10-26-dataset1.txt\n│       ├── 2015-10-26-dataset2.txt\n│       ├── 2015-10-26-dataset_overview.txt\n│       ├── 2015-11-23-dataset1.txt\n│       ├── 2015-11-23-dataset2.txt\n│       └── 2015-11-23-dataset_overview.txt\n└── send_to_bob\n    ├── all_datasets_created_on_a_23rd\n    │   ├── 2015-10-23-dataset1.txt\n    │   ├── 2015-10-23-dataset2.txt\n    │   ├── 2015-10-23-dataset_overview.txt\n    │   ├── 2015-11-23-dataset1.txt\n    │   ├── 2015-11-23-dataset2.txt\n    │   └── 2015-11-23-dataset_overview.txt\n    └── all_november_files\n        ├── 2015-11-23-calibration.txt\n        ├── 2015-11-23-dataset1.txt\n        ├── 2015-11-23-dataset2.txt\n        └── 2015-11-23-dataset_overview.txt\n\n\n\n\n\n\n\nClick here for the answer\n\n\n\n\n\n\n$ cp *calibration.txt backup/calibration\n$ cp 2015-11-* send_to_bob/all_november_files/\n$ cp *-23-dataset* send_to_bob/all_datasets_created_on_a_23rd/"
  }
]